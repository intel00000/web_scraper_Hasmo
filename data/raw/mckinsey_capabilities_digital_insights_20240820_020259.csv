title,description,url,image_url,date,article_text,summary
From legacy to cloud: Lessons learned,"The journey to cloud is complex, demanding leadership, careful planning, and an agile approach to the unexpected.",https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/from-legacy-to-cloud-lessons-from-the-trenches,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/from%20legacy%20to%20cloud%20lessons%20from%20the%20trenches/thumb-klaczak-kumar-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-03-11T12:00:00Z,"From legacy to cloud: Lessons learned This interview has been updated to acknowledge external contributors. Modernizing legacy systems and platforms can drive significant business value by enabling faster innovation, greater agility, and lower costs. Organizations take a variety of approaches to modernization, typically based on their specific situation, such as the current state of their investments, their risk appetite, and their time horizon. In this interview, we highlight one such approach, where Lincoln Financial Group transitioned its sizable legacy footprint to cloud within two years. Rob Klaczak, senior vice president and divisional CIO for life, annuities, and distribution, and Satyendra Kumar, vice president and executive sponsor and program lead, discuss Lincoln Financial Group’s transformative journey from decades-old legacy platforms to a dynamic cloud-based architecture, the lessons learned on the way, and their advice for others with similar goals. McKinsey: What prompted you to undertake this transformation? Rob Klaczak: Lincoln Financial’s primary goals for migrating its legacy footprint (for example, assembler code, COBOL-based systems, highly customized system configurations) to the cloud focused on three objectives: reducing overall operating costs, addressing the high expenses associated with certain specialized software licensing, and transitioning to a more modern and flexible environment. The need for modernization and the desire to move away from our fixed-cost legacy setup have been the crucial drivers of this migration. In the context of an insurance company like us, whether managing a million policies or just a few policies, the costs associated with our legacy platforms were largely fixed, posing a financial challenge. We undertook our program to address these challenges, which were complex due to the nature of our business; the large scope of the modernization, which included 120 complex systems; and an accelerated time frame of less than two years to complete the entire program. Satyendra Kumar: Another key objective was to move the decision-making power from IT to the business side by implementing a model that put a price on the consumption of technology services. Now each line of business has the discretion to increase or reduce its spending in alignment with its business goals. McKinsey: How were you able to get senior management’s support and buy-in? Rob Klaczak: The decision to transition to a cloud-based system—and getting senior management’s support for it—was based on a strategic blend of three things. First was grounding technology investments in a cost-benefit analysis aligned with the organization's commitment to efficiency and cost effectiveness. We positioned the cloud transition as a significant expense-saving measure with tangible business benefits. Second, the transition involved managing 12 to 15 policy administration engines critical to Lincoln Financial’s core operations in life, annuity, and retirement. Confidence in the success of the transition was contingent on a comprehensive risk-mitigation strategy. Recognizing the inherent high-risk nature of the program, we put together a robust risk-mitigation plan. Third, the team's execution strategy has focused on maintaining flawless operations throughout the transition. Despite an accelerated timeline, the emphasis has been on ensuring a high-quality product to avoid disruptions to internal businesses and external customer experiences. Our planning included meticulous checking, multiple validation processes, business acceptance testing, and parallel production runs undertaken by the team to guarantee a seamless transition. McKinsey: How did you assemble the team to pull this off? Rob Klaczak: The success of our effort came from a combination of strong leadership, adaptive planning, thorough due diligence, and effective organizational design. Satyendra's leadership style, technical acumen, and commitment have been central to driving the program's success. Our operating model also emphasizes leadership alignment, building organizational support, and implementing an agile approach to overcome the complexities of the transition process. A significant aspect of the transition strategy involves adaptive planning. Traditional program management office (PMO) approaches are inadequate for dealing with the complexities of systems that have been in place for over 50 years. We therefore adopted an iterative approach, emphasizing frequent assessments, replanning, and agile responses to evolving requirements. Gaining support and alignment across all levels of the organization has been critical. Transparency in decision making, involvement of diverse stakeholders, and clear objectives have contributed to building confidence among senior management and the broader team. Designing robust organizational operating and engagement models is paramount. The hub-and-spoke model, where the core team (hub) is connected to various parts of the business and IT (spokes), ensures effective communication, information flow, and collective engagement. The emphasis is on avoiding isolation and fostering a collaborative environment to address challenges and celebrate successes collectively. Cloud by McKinsey Insights McKinsey: How did you approach overall planning for such a significant migration? Satyendra Kumar: There were a number of key areas we focused on. First, we adopted a multiprovider, multipartner strategy for the transition. And the necessity of bringing partners together early on and encouraging collaboration beyond organizational boundaries was critical. Security was also a key consideration, and we worked closely with all key partners to ensure that we understood the nuances of security in a legacy system and met current standards in the target state. The creation of a comprehensive, Wikipedia-style playbook democratized data collection and information sharing across the organization. We prioritized applications based on business needs, considering factors like processing times and application sensitivity, and took a dynamic approach to planning, blending automation and manual processes. Lincoln Financial's success in executing an agile approach, despite initial challenges with shifting dates, was due to the agile mindset, which was essential for adapting to unknowns, building confidence, and consistently delivering results. We also drew inspiration from Navy SEAL strategies, emphasizing preparation for the unknown and the ability to quickly readjust plans. Leadership played a critical role in instilling confidence through successful deliveries and a transparent, agile approach. Positive feedback from business leaders highlighted the program’s success with minimal disruptions. Building and executing a robust cloud operating model was also essential in gaining support across the organization, and we empowered the team with decision-making authority, which helped us avoid “analysis paralysis” and become comfortable with short-term tactics. We also closely engaged stakeholders and leadership for interfacing applications so that their own feature release schedules were in sync with the migration schedule to ensure a seamless experience for the business users. McKinsey: What were the major technical or nontechnical challenges? Rob Klaczak: With a program like this, one should expect lots of challenges, and the only way forward is to work through them. A few of them included legacy security measures—authentication without authorization posed a significant challenge. Early engagement with the chief information security officer (CISO) and fostering a strong relationship with the CISO’s team were crucial for navigating security complexities. We also focused on the need for a fundamental shift in mindset, from creating multiple environments in the legacy footprint to optimizing for cost efficiency in a cloud-based, consumption-driven structure. Emphasis on thought leadership and adapting to a more efficient approach in orchestrating processes was necessary. Satyendra Kumar: This program is very exciting for technology professionals but posed significant challenges to senior management because there were so many unknowns related to more than 100 million lines of code, diverse old technologies, and fundamental changes in the underlying data structures and formats. Solutions involved conducting equivalency tests, securing data, and leveraging compression and decompression technologies. Underestimating the time required for moving large volumes of data became a significant challenge. Migrating data across extensive policy engine platforms presented time-consuming hurdles. We also faced challenges related to code conversion, especially in technologies tied to specific partners, which demanded expertise in certain niche languages. The search for source code and addressing gaps in applications that lacked source code added complexity. Identifying and dealing with technology blind spots, where certain technologies and functionalities are outdated, was also difficult. McKinsey: How is the performance in the target state? Satyendra Kumar: While the organization has not yet accumulated sufficient volume to comprehensively assess efficiency, there are early positive indicators. Parameters such as environment stability, meeting service levels, and running at optimized costs have shown promising results. Initial anecdotal evidence suggests improved performance for both external customers and internal business users. The cloud environment, despite its complexity, is more efficient, thanks to advancements in cloud technologies. Notable improvements in cycle times, with a reported enhancement of 20 to 30 percent, and affirmation of reliability, scalability, and performance of the cloud-based systems, have been the highlights so far. McKinsey: What are the key lessons learned, and do you have any advice for others? Satyendra Kumar: Careful and detailed planning, along with a SWAT team approach to identify and resolve unknowns, is critical to success. You also need to bring the whole organization along and clearly lay out the role each team needs to play. Communicate effectively and extensively within the organization and with vendor partners to create awareness and build a highly engaging team. Rob Klaczak: An effort like this needs unwavering support from senior management. We also acknowledge the dedication of team members and partners and their enthusiasm and eagerness to contribute to this challenging and exciting initiative. The unifying goal attached to the program and the collective effort of a thousand individuals have been instrumental in overcoming obstacles and achieving success. Rob Klaczak is senior vice president and divisional CIO for life, annuities, and distribution at Lincoln Financial Group, where Satyendra Kumar is vice president and executive sponsor and program lead. This interview was conducted by Colin Gunter , a partner in McKinsey’s Atlanta office; Sanjay Kaniyar , a partner in the Boston office; Yash Rajyaguru , a principal lead for cloud delivery in the Washington, DC, office; and Mayukh Samajder , a principal architect in the Stamford office. The authors wish to thank Chris Cahill, Navnith Jayaram, and Alan Lin from Lincoln Financial Group for their contributions to this interview. Explore a career with us Related Articles What every insurance leader should know about cloud In search of cloud value: Can generative AI transform cloud ROI? Getting ahead in the cloud","Lincoln Financial Group successfully transitioned from legacy systems to cloud architecture in under two years, driven by goals of cost reduction, flexibility, and improved decision-making. Key lessons include careful planning, strong leadership, effective communication, and unwavering senior management support, resulting in"
Embracing digital transformation with a digital factory,"In this interview, Alinma Bank's chief digital officer discusses the importance of a digital factory to the bank’s overall transformation journey.",https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/embracing-digital-transformation-with-a-digital-factory,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/embracing%20digital%20transformation%20with%20a%20digital%20factory/thumb-sami-thumb-1536x1536-v2.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-03-28T12:00:00Z,"Embracing digital transformation with a digital factory When Saudi Arabia’s Alinma Bank decided to embark on a digital transformation, it built a digital factory. This approach is one way companies can incubate innovation and model agile ways of working that can then provide a foundation for spreading these practices throughout the organization. At Alinma Bank, leadership focused on building digital capabilities that have allowed them to deliver disruptive digital solutions to a variety of customer segments. Sami Al-Rowaithey, Alinma Bank’s chief digital officer (CDO), discusses with McKinsey partner Sonia Wedrychowicz the value of adopting agile, attracting diverse talent, and putting the customer at the heart of everything. What follows are edited highlights from their conversation. Building a digital factory Sonia Wedrychowicz: Can you describe what a digital factory is and what it means to Alinma Bank? Sami Al-Rowaithey: Essentially, it’s a platform to power up and deliver digital transformation. It’s a space to foster innovation, embrace new ways of working, promote transparency, encourage teamwork, and adopt agile ways of working, with the ultimate objective of rapidly delivering on our aspirations. Alinma’s digital factory was established a little more than one year ago and is responsible for spearheading the bank’s digital transformation. It’s responsible for managing the entire digital structure and its associated strategies, business development, product innovation, experience management, performance management, and digital profitability. Sonia Wedrychowicz: How did you go about establishing the digital factory? Sami Al-Rowaithey: It was an exciting journey. We were contemplating different approaches in terms of how and where to start. We ultimately decided to start small and scale fast to minimize resistance and ease the adoption of new practices within the organization. We started with a small team working on one project, and then looked at building a relevant operating model suitable for what we wanted to do—and for the organization as a whole. We determined how the team would operate, the composition and structure of squads (teams), how the tribes (groups of related squads) were defined, and what practices and tools they needed. We started with one initiative and one tribe. One year later, we now have four tribes and around eight squads operating within the factory, independently delivering projects for various customer segments. Another important consideration was how this digital factory would interact with the wider organization, such as IT, marketing, business, and other functions. The third point we addressed was sponsorship, which is key, since we needed to be supported from the top of the organization to drive this massive transformation. So, we spent a lot of time communicating the values, objectives, and advantages of creating a digital factory to the whole organization. Finally, and most important, are our people. We looked for talent from different industries to inject new DNA into the bank that can champion this transformation. Putting the customer at the heart of everything Sonia Wedrychowicz: Digital factories often can feel different from other parts of an organization. How did you approach establishing an operating model that has allowed you to successfully innovate? Sami Al-Rowaithey: We’ve embraced practices around empowerment and enablement and have encouraged our people to experiment and make mistakes. We want them to know that it’s OK to learn from mistakes and move on. Transparency is key as well, so we always encourage our people not to shy away from speaking up. This gives us better visibility into what is happening on the ground and what support employees need from us to achieve their goals. Transparency also applies to customers, because it’s crucial to understand customers deeply to give them what they want, not what we think they want. So, in order to develop propositions and solutions that resonate with customers, we’ve created a beta community to test our journeys, experiences, and products. Putting the customer at the heart of everything we do and always putting our people first are the two main ingredients for success. Spreading innovation throughout the institution Sonia Wedrychowicz: Do you think this new focus on delivering value to customers has radiated outside of the digital factory? Sami Al-Rowaithey: In fact, yes, and very quickly. The technologies and tools we’ve embraced within the factory are now being adopted by the bank’s wider IT organization. And our marketing department is already working on establishing something similar to our beta community. We created squads to bring all our people together in one space, on one floor, working as one team to deliver on products and objectives in agile ways of working. Now we’re seeing that model spread to other departments, like IT, retail, and corporate. Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI The importance of diversity in the digital factory Sonia Wedrychowicz: You’ve introduced a diversity transformation within the digital factory. Why was that important, and how have you achieved it? Sami Al-Rowaithey: Let me explain our recruitment strategy. We wanted to start small but fast. So, we launched two parallel tracks, the first of which relied on vendors and contractors, to ramp up quickly. We also launched a parallel track looking for people to recruit within the bank, so we managed to scale up very quickly, in just a few months. Because we also looked for talent outside the bank, we attracted people from different industries, like fintechs, start-ups, government, and telcos, to create diversity. In addition, we also looked at diversity in terms of background and nationality to stimulate creative thinking. We are always looking for the most qualified people, and I’m proud to say that we have a lot of talented women in the digital factory. They comprise around 30 percent of our team. Starting small and scaling quickly Sonia Wedrychowicz: You said you started small but grew quickly. How did the digital factory approach enable you to roll out multiple projects at the same time? Sami Al-Rowaithey: It was a big task. But we developed a digital-transformation strategy touching every vertical in the bank and covering the entire spectrum, be it digitizing customer experiences, improving multichannel delivery, enhancing our digital sales, maximizing the contribution of digital to the bottom line, or improving customer satisfaction. Then we looked at venturing into new businesses, leapfrogging via innovation, and creating propositions to attract and acquire specific customer segments. We asked ourselves, “How do we go beyond normal banking? How do we embrace open banking? How do we build ecosystems? How do we leverage the external ecosystem to accelerate our digitalization agenda?” Many of these aspirations have already been translated into initiatives. We have an ambitious vision, to be the fastest and most convenient bank in Saudi Arabia, so we needed to fundamentally change how we run our business and create an engine that constantly challenges the status quo by asking how business is conducted, how processes are defined, how experiences are reimagined, and how quickly we can deliver. Since we needed to scale up quickly, one important principle we kept in mind was always to focus on delivering incremental value to customers while building the foundations. That’s why we managed to scale quickly and deliver on multiple initiatives in our road map. Overcoming challenges around talent, mindset, and culture Sonia Wedrychowicz: What kind of challenges did the digital-factory initiative face? Sami Al-Rowaithey: I would pinpoint two main items. The first challenge was the search for talent, which is crucial, because without it, we couldn’t accomplish anything. We’re seeing a talent scarcity across the globe and found it difficult both to recruit and to retain people with the right skill sets. The second challenge was basically one of mindset and culture. As you can imagine, it’s not easy changing the mindset within a large bank in a short period of time. That’s why it took a lot of time aligning with the wider organization to make them feel part of our success. So we brought them into the digital factory, collaborated with them, took their feedback seriously, and engaged and iterated with them. That eased the adoption of the digital factory within the larger organization, minimized resistance, and made people more comfortable with us—because at the beginning, the rest of the bank viewed us as a threatening department here to take their jobs. But that’s all in the past now, and the organization-wide perception of the digital factory is extremely positive. Advice for others on the journey Sonia Wedrychowicz: What advice would you give to others embarking on a digital transformation? Sami Al-Rowaithey: The first thing I would say is to not spend a lot of time trying to figure out all the details of the journey. It’s important to start quick, learn as you go, be flexible, modify, and move on. Secondly, you need to be resilient and persistent. The journey will be full of challenges, but you’ll manage as long as you always keep the final goal in mind. If there’s a will, there’s a way. Finally, it’s important to maintain autonomy, but don’t fall into the trap of isolating yourself within the organization. Always keep your stakeholders engaged and aligned while preserving the flexibility and autonomy to deliver and move fast on shared goals. Sonia Wedrychowicz: What is the future of the digital factory for Alinma Bank? Sami Al-Rowaithey: I’d be lying if I said I know what the future holds, but I believe in our road map. We have a pipeline of initiatives and propositions for specific customer segments on multiple fronts. We also want to focus more on propagating the values, practices, and principles of the digital factory throughout the organization. Finally, we will continue to scale up. When we were moving into the digital factory space a year ago, it seemed very spacious. When you go through the corridors today, there are hardly any spaces left. We've got a lot of engaged people, a lot of movement, a lot of energy, and a lot of passion. And finally, from a personal perspective, I strongly believe that fostering advanced digital talent and offering solutions enabling individuals to make informed financial decisions can significantly benefit society. Watch the full interview here . Sami Al-Rowaithey is the chief digital officer of Alinma Bank. Sonia Wedrychowicz is a partner in McKinsey’s Dubai office. Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement. Explore a career with us Related Articles Welcome to the Digital Factory: The answer to how to scale your digital transformation In digital and AI transformations, start with the problem, not the technology Rewired to outcompete","Alinma Bank established a digital factory to drive its digital transformation by fostering innovation, agile practices, and diverse talent. This initiative allows for rapid delivery of customer-centric solutions, encourages collaboration within the wider organization, and aims to scale up continuously while overcoming"
What it takes to rewire a CPG company to outcompete in digital and AI,Answering six specific questions holds the key to successful digital and AI transformations for CPG companies.,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-it-takes-to-rewire-a-cpg-company-to-outcompete-in-digital-and-ai,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/what%20it%20takes%20to%20rewire%20a%20cpg%20company%20to%20outcompete%20in%20digital%20and%20ai/thumb-gettyimages-1457743520.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-06-12T12:00:00Z,"What it takes to rewire a CPG company to outcompete in digital and AI There’s a race on to capture value from digital and AI, and consumer packaged goods (CPG) companies are in danger of falling behind both retailers and consumers. It’s not for lack of trying. Like most sectors, CPG companies have been on some form of digital and AI transformation journey. But most of them are stuck in the pilot purgatory stage characterized by plenty of subscale activity and little at-scale value. Our analysis of digital and AI maturity has shown that CPG companies are among the poorest performers, while retailers are near the top (Exhibit 1). 1 The scores are based on Digital Quotient (DQ) and AI Quotient (AIQ) assessments that measure digital and AI maturity across core capabilities and management practices essential to capturing value. The DQ and AIQ gap between leaders and laggards was 10.3 percentage points in the period from 2016–19; the gap increased to 16.3 percentage points in the period from 2020–22. This halting progress is all the more frustrating and worrisome in view of the huge value at stake. We analyzed the potential of digital and AI transformations to drive top- and bottom-line impact along the full value chain. 2 Analysis based on McKinsey’s CPG digital and AI impact calculator tool (latest version June 2023), which consists of a repository of more than 60 digital and AI use cases across 11 domains in front (precision revenue growth management; data-driven marketing; sales and in-store excellence; portfolio innovation and design; e-commerce and direct to consumer), middle (autonomous planning; plant of the future; digital logistics; digital procurement and supply management and supplier collaboration), and back (talent analytics; general and administrative services). Our analysis revealed a potential 6 to 10 percent incremental revenue uplift and corresponding growth of 3 to 5 percentage points in EBITDA over three to five years, depending on the subcategory. Furthermore, the increased adoption of generative AI (gen AI) could increase the economic impact of traditional AI by 15 to 40 percent , unlocking an additional $160 billion to $270 billion annually in profit (measured in EBITDA) for CPG companies globally. 3 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. The CPG sector faces some unique challenges. The proliferation of data, for example, and its complexity—sources are scattered across retailers, suppliers, manufacturers, and consumers—have created massive issues in terms of harnessing the data to find, track, and capture value. At its core, the reason for this low success rate is that companies fail to perform the deep organizational surgery required to affect the broad-based change that’s needed. It’s never “just tech” when it comes to successful digital and AI transformations. Companies need to rewire how they work . 4 Eric Lamarre, Kate Smaje, and Rodney Zemmel, “ Rewired to outcompete ,” McKinsey, June 20, 2023. But even while CPG as a sector performs poorly, some companies are high performers, as Exhibit 1 shows. One beverage company that embarked on a digital and AI transformation unlocked 18 percent EBITDA uplift over two years. It was able to make and sustain these improvements by being comprehensive in the scale of, and commitment to, the change needed. A committee of senior leaders started by prioritizing domains that had significant growth opportunities and were feasible, given their capabilities. They then developed a detailed road map and established more than 50 cross-functional pods—joint teams spanning markets, regions, and enterprises—with specific goals and the autonomy to deliver necessary solutions. They put in place a centralized stage-gate process with clear decision rights to track, advance, and fund solutions to help maintain momentum. To support the technology solutions, they moved aggressively into cloud to help create more scale and flexibility to use in building modular, customized applications. They also invested in a data lake and a governance model with clear areas of responsibility. For example, IT defined and managed the data architecture while the business defined use cases for data products. Realizing talent was an acute issue, they upskilled their own people through tailored learning curricula that included on-the-job learning, formal training sessions, and individual coaching. Six questions to help outcompete with digital and AI In working with more than 200 large companies across industries, including 25 of the top 30 CPG companies, we found that six enterprise capabilities are critical for companies to rewire themselves and achieve sustainable competitive advantage from digital and AI (Exhibit 2). In rewiring how they work, CPG companies need to answer six key questions. 1. Where is the value? Making sure that a digital and AI transformation delivers meaningful value starts with prioritizing and focusing efforts on domains where meaningful value exists. While the distribution of value varies across CPG sectors, our analysis shows that the greatest payoff for most sectors is concentrated heavily in two areas: consumer insights and demand creation, and customer and channel management (Exhibit 3). There is one notable exception: the beauty industry, where the direct-to-consumer area takes center stage. New technologies can have a big impact on that interaction model, as well as on the e-commerce process and fulfillment management. In general, these are the domains CPG companies should prioritize for their transformation programs. As CPG companies assess the value, they will need to be thoughtful about understanding gen AI’s impact. McKinsey analysis identified just four areas—customer operations, marketing and sales, software engineering, and research and development—that could account for approximately 75 percent of the total annual value from gen AI use cases . 5 “ The economic potential of generative AI ,” June 14, 2023. The majority of that value comes from increased productivity in the form of, for example, better and faster issue resolution in customer service, more personalized communications, and more-effective product discovery. Gen AI could increase the productivity of the marketing function, with a value between 5 and 15 percent of total marketing spending . 6 “ The economic potential of generative AI ,” June 14, 2023. One consumer company, for example, implemented a gen AI large language model (LLM) to improve the manual process of financial planning and analysis (FP&A) research. An initial proof of concept showed a reduction of up to 30 percent in time spent on research. Some companies are already actively educating their organizations, especially leadership, about gen AI, the capabilities it unlocks, and its applications in business. In fact, since the second quarter of 2023, almost all CPGs we analyzed have had an immersion session on AI for C-level executives. Creating value beyond the hype 2. Are leaders from the business side actively part of the transformation? CPG companies often underestimate the role of business functions in a successful digital and AI transformation, relegating the initiative to IT. Case in point: At a large food manufacturer, the supply chain domain was one of the company’s most successful domains, in part because the leadership, including the COO and CFO, made supply chain a priority. The business dedicated a senior director as product owner for not only the build but also rollout and adoption, and these business leaders joined biweekly sprint reviews, engaging with the supply chain digital leader and the working team in designing a completely new way to optimize customer service. Top business talent should act as product owners of the transformation for their given product, working closely with technology leaders to define the road map of solutions, managing the pipeline of use cases to build the solution, influencing technology infrastructure decisions, governing data, and being the voice of the transformation to their wider teams. The core operational unit is the agile “squad.” Comprised generally of five to eight people across business, data, technology, and design functions, these teams are responsible for building the solutions on the road map (Exhibit 4). They are crucial for scaling. Acting autonomously based on clear guidelines, these agile squads are the only way companies can enable hundreds or even thousands of teams to deliver transformational change. 3. Are you an attractive long-term employer for digital talent? Without top in-house technical talent, CPG companies will struggle with their transformation. Having a hiring strategy and competitive compensation will only get you so far in attracting and retaining digital talent, especially when you are competing with digital natives. The core issue is that work at CPG companies often doesn’t attract top tech talent. Companies will need to offer meaningful missions, learning opportunities, and an environment where tech talent can thrive. A good place to start is upskilling leaders to better understand how tech creates value. P&G instituted a reverse-mentoring program in which junior tech people worked with senior leaders to help them understand how to use tech. 7 “How P&G’s 4D culture helps with successful digital transformation,” Human Resources Online, May 12, 2020. Leaders also went to leading digital businesses to observe operations and speak with leaders to understand what skills are important to bring into an organization. It’s important to focus on hiring talent with some proficiency in relevant areas. Competent developers are significantly more productive than inexperienced ones, and that trend carries over into gen AI as well . 8 “ The economic potential of generative AI ,” June 14, 2023. To find the right talent, CPGs should look to suppliers or retailers who are already progressing on their digital journey. Adjacent sectors such as hospitality and telecom can also be sources of expert talent with broader skills that are transferable to CPG companies. Offering promotions and compensation based on skills mastery and establishing engineering-specific career tracks can also help in retaining your top people. A large beverage CPG knew it needed to upgrade its talent if it wanted its digital and AI transformation to succeed. But established recruiting practices were slow and not geared to the leading technical talent the business needed. A talent win room came together with a new plan. First, they invested in developing clear new role descriptions, tailored to the specific skills required. Second, they focused on identifying new recruiting sources rather than turning to more general jobs and networking venues. Third, they sped up the evaluation process with coding tests, which allowed them to quickly narrow down more than 7,500 initial applicants to high-potential candidates. And fourth, they put in place batch days organized around the full set of decision makers, which allowed them to make decisions on candidates and extend an offer within 24 hours. Over this time, the talent win room had a set of KPIs that they referred to often to track their progress and correct any issues quickly. In 90 days, they were able to fill the 25 critical digital and analytics roles they needed—a tenfold increase in the speed of hiring. 4. Are you deploying your technology investments to optimize for reuse? Many CPG companies have key elements of a core infrastructure in place—such as cloud, data lakes, and planning software—but they are often not set up to operate at scale. This situation is largely the result of a complex tech stack where systems are built to support a specific function or market. This makes it challenging to share data and reuse solutions, leading to costly replication of applications and difficulty in scaling. Enabling solutions that serve multiple domains has significant benefits, such as allowing a company to use a broader range of data to make better revenue growth management (RGM) decisions. Getting to this state requires companies to develop a modular architecture (Exhibit 5). For this approach to work in practice, companies need a global strategy and a team made up of experts from central IT (including enterprise architects, cloud developers, and engineers) and leaders from target markets to design the system together. They should focus on creating modules to support three to five market archetypes (for example, hypermarkets in the United States and more-traditional trade stores in Latin America), develop a road map for building them, and then test them in the market. Typically, this process includes making key decisions, such as what domain tools to deploy, what cloud infrastructure to develop, and whether to build or buy specific technologies. Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI 5. Are you developing data products? Data in the CPG industry is notoriously fragmented across retailers, distributors, consumers, syndicated data providers, marketing platforms, contract manufacturers, third-party logistics providers, and more. This issue has become even more acute with generative AI, with the introduction of huge amounts of unstructured data. Without a centralized, well-coordinated data strategy, teams end up using raw data for their one-off needs, wasting data scientist and engineering capacity on creating inconsistent data sets that can’t be accessed by other teams or systems. To redress this issue, companies need to focus on three things: A global CPG was able to rapidly transform its RGM domain end-to-end in just two years by building modular technology components that enabled it to scale solutions across its more than 30 category/market combinations. Instead of building pricing and promotions analytics around the data available for a particular region/category, for example, the company built a standardized RGM data product that teams could easily use. Each market category only had to input its own data into the product to take advantage of the underlying analytics engine. Because the data product was modular, specific local factors, such as currencies and units of measure, could easily be swapped in. 6. Are you anticipating and preparing for the most critical scaling challenges? The fragmentation in CPG companies—accounts, categories, brands, geographies, and functions—makes adoption and scaling technology challenging. Too often, companies have to redo a lot of work to tailor solutions to local environments. While the adoption of technology relies on many factors, in practice it is most crucial to involve potential future users early in solutions development; give end users incentives to use the technology; minimize the effort required of them, by building solutions into existing tools, for example; and track their uptake over time. The key to tackling scaling is to “assetize” solutions by packaging them as modular assets that teams can easily reuse. The focus should be on technologies, such as APIs; processes, such as solution rollouts, operational guidelines, and training; and support, such as subject-matter experts who understand how to deploy the solution and adapt it to different environments. A digital and AI transformation is a complex journey. But for CPG companies willing to make the commitment to change at scale, the value can be transformative and a competitive necessity. Abdul Wahab Shaikh is a partner in McKinsey’s Atlanta office, Shruti Lal is a partner in the Chicago office, Hannah Mayer is an associate partner in the Bay Area office, and Spurthi Gummadala is a consultant in the Seattle office. The authors wish to thank Roger Roberts for his contributions to this article. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles Rewired and running ahead: Digital and AI leaders are leaving the rest behind Rewired to outcompete A generative AI reset: Rewiring to turn potential into value in 2024","Consumer packaged goods (CPG) companies are struggling to leverage digital and AI effectively, often stuck in pilot phases. To succeed, they must prioritize value areas, involve business leaders, attract digital talent, optimize technology investments, develop cohesive data strategies, and"
Generative AI in healthcare: Adoption trends and what’s next,"Surveyed healthcare leaders say their organizations are eager to use generative AI to help enhance how healthcare stakeholders work and operate, but some are still adopting a wait-and-see approach.",https://www.mckinsey.com/industries/healthcare/our-insights/generative-ai-in-healthcare-adoption-trends-and-whats-next,https://www.mckinsey.com/~/media/mckinsey/industries/healthcare%20systems%20and%20services/our%20insights/generative%20ai%20in%20healthcare%20adoption%20trends%20and%20whats%20next/generative-ai-in-healthcare-845813466-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-07-25T12:00:00Z,"Generative AI in healthcare: Adoption trends and what’s next The transformative power of generative AI (gen AI) will likely reshape the healthcare industry over time, and organizations are beginning to take action. In our Q1 2024 survey, more than 70 percent of respondents from healthcare organizations—including payers, providers, and healthcare services and technology (HST) groups—say that they are pursuing or have already implemented gen AI capabilities (see sidebar, “Research methodology”). Research methodology To better understand how healthcare organizations are thinking about generative AI (gen AI) use, McKinsey launched a research effort to gather insights from leaders in payer, provider, and healthcare services and technology (HST) groups. We surveyed US healthcare stakeholders about a number of topics, including their plans to use gen AI solutions, how they expect to adopt gen AI tools, their ROI measurements, their expectations for areas that will benefit the most from gen AI, and the roadblocks to scaling gen AI. These surveys are not meant to be a comprehensive or an exhaustive view of all healthcare stakeholders or to predict their actions in the future. Instead, the surveys are meant to provide early insights into the potential of gen AI. The most recent survey included 100 respondents and was in the field for one week during March 2024. Among respondents, 33 percent were C-level executives, and 31 percent belonged to organizations with greater than $10 billion in revenue. The first survey was fielded during one week in December 2023 and included leaders from 40 payers, 40 provider organizations, and 20 HST companies. The Q1 2024 survey, which included 100 US healthcare leaders, was conducted in March and comes after the Q4 2023 survey of 100 US leaders, which was conducted in December 2023. As we look at the responses across these populations in both surveys, a few themes emerge. Integration and intentions In the Q1 2024 survey, a majority of respondents say that their organizations are either already using gen AI tools or are testing them out. Most of the surveyed respondents are in the proof-of-concept stage with gen AI, as stakeholders contemplate trade-offs among returns, risks, strategic priorities, governance, maturity, and other factors. Yet despite the industry’s general interest in using AI, there is still a consistent portion of respondents without any plans to pursue gen AI or who are maintaining a wait-and-see approach. Partner or pioneer Among those surveyed who are implementing gen AI, 59 percent are already partnering with third-party vendors to develop customized solutions, and 24 percent report plans to build solutions in-house, while only 17 percent expect to buy off-the-shelf gen AI products. Among those who haven’t yet implemented gen AI, 41 percent say they intend to buy gen AI products, which may be driven by this population’s concerns with risk (57 percent are not pursuing gen AI, because of risk considerations) and technology needs (29 percent). The ROI for gen AI As with any investment, it’s critical for stakeholders to be able to realize the value that gen AI promises. A measurable positive impact serves as strong reinforcement for continued and expanded use and investment. While the number of respondents who have implemented gen AI is small, among those who have, most have not yet calculated the ROI or are waiting on measurable results. But about 60 percent of those who have implemented gen AI solutions are either already seeing a positive ROI or expect to. Gen AI’s vast scope Gen AI may create tremendous value in areas that could fundamentally improve patient experience and streamline operations. Specifically, clinician and clinical productivity is viewed by most respondents as an area where gen AI may have the highest value. Furthermore, expectations for gen AI’s potential in applications to improve patient and member engagement and experience, administrative efficiency and effectiveness, and quality of care and delivery indicate a diffusion of gen AI interest beyond clinical uses into areas that improve overall patient care interactions. Hurdles to scale up Risk concerns and considerations top the list of scale-up challenges faced by surveyed leaders, regardless of whether they work at a payer, provider, or HST company. This is likely due to the untested nature of the technology, the investment needed to build capabilities, and uncertainty around regulations. It signals the importance of governance and mitigation strategies to tackle the range of risk issues—from privacy to clinical outcomes—to ensure regulatory compliance and excellence in care. After risks, the next most prevalent roadblocks indicated by respondents are insufficient capability, data and tech infrastructure, and proof of value. This demonstrates healthcare organizations’ limited tech readiness to deploy gen AI solutions and also to validate its capabilities. After gen AI entered the global stage at the end of 2022, we now see the healthcare industry more actively considering its strategy for using this technology. While these surveys are small and do not represent an exhaustive view of all healthcare stakeholders, they are meant to provide early insights into gen AI’s potential. As the survey results show, many healthcare leaders have begun pursuing plans to more broadly adopt the technology, which has in part been enabled by strategic partnerships . Given the complexities regarding technical implementation and integration across a business, cross-functional collaborations allow organizations to bring in outside talent while taking advantage of building flexible and customizable gen AI solutions, compared with buying off-the-shelf solutions. Yet depending on an organization’s tech maturity or how straightforward a use case is, buying publicly available gen AI products may offer a viable alternative to tap into the technology’s value proposition. Direct purchases may make sense, particularly for functional uses that have matured faster, such as for customer service applications. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. As gen AI deployment progresses, many surveyed leaders share that their organizations are focused on initially using this technology to support clinically adjacent applications, with clinical and administrative efficiency and patient/member engagement surfacing as areas believed to gain the most from gen AI. However, as organizations develop strong competencies in governance and risk management, we expect additional focus on core clinical applications as well, further improving the overall patient/member experience. Despite gen AI’s promise, the path to responsible usage is not without its hurdles . Risks such as inaccurate outputs and biases are particularly critical in healthcare when dealing with patients . As organizations introduce this new technology into workflows, AI risks seem to be top of mind for many surveyed healthcare leaders. Risks will need to be proactively mitigated, which starts with a concerted focus on establishing governance processes, frameworks, and guardrails to anticipate, identify, and manage risks. By doing so, healthcare organizations can use gen AI to help ensure that benefits are realized in line with regulatory expectations without compromising ethics or safety. Jessica Lamb is a partner in McKinsey’s New York office; Greg Israelstam is a consultant in the Chicago office, where Shashank Bhasker is an expert associate partner; and Rahul Agarwal is a senior expert in the New Jersey office. The authors wish to thank Anna Dirksen, Valen Piotrowski, and Xuan Chai for their contributions to this article. This article was edited by Querida Anderson, a senior editor in the New York office. Explore a career with us Related Articles Public health’s inflection point with generative AI The AI opportunity: How payers can capture it now Tackling healthcare’s biggest burdens with generative AI","Over 70% of healthcare organizations are pursuing generative AI (gen AI) solutions, with many in the proof-of-concept stage. Key areas for improvement include clinician productivity and patient engagement. However, concerns about risks, technology readiness, and ROI"
The big product and platform shift: Five actions to get the transformation right,"To succeed, incumbent organizations need to take five actions as they scale their product and platform model transformations.",https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-big-product-and-platform-shift-five-actions-to-get-the-transformation-right,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20big%20product%20and%20platform%20shift%20five%20actions%20transformation/thumb-gettyimages-509278849.jpg?cq=50&mw=767&car=16:9&cpy=Center,2023-06-09T12:00:00Z,"The big product and platform shift: Five actions to get the transformation right Many incumbent organizations across industries and sectors want to become more like tech companies: fast, agile, and dominant. They’re doing so to remain competitive at a time when B2B and B2C customers have high and rapidly changing expectations and digital disruptors are upending the business landscape. About the authors This article is a collaborative effort by Rushabh Gala, Naufal Khan , Ling Lau , Gautam Lunawat , and Anindita Pal, representing views from McKinsey Digital. The key to making this change lies in adopting a technology operating model based on products and platforms . This model organizes technology around user-facing products, to facilitate end-user journeys or experiences (ordering, bill paying, and loyalty programs, for example), and the underlying platforms that enable them, such as customer relationship management (CRM) and marketing technology (MarTech). The benefits of this product and platform model have been well established. The product and platform model ensures that technology delivery is aligned to the strategy and related priorities. In our experience, it can generate significant business value, spur innovation, improve customer and employee experience, decrease time to market by up to three times, reduce product defects by 50 to 70 percent, improve brand and image perception, and increase operating margins and total shareholder returns. A recent McKinsey survey revealed that at nearly three-quarters of top-performing companies, the most-senior tech leaders are highly involved in shaping company strategy. 1 “ Prioritizing technology transformations to win ,” McKinsey, March 24, 2022. About our Operating Model Index The impact of shifts in the operating model on an organization’s performance has been studied and quantified in our Operating Model Index research. The research gathers insights from more than 400 organizations across industries and analyzes the correlation between operating model maturity and business outcomes, such as innovation, operating margin, total returns to shareholders, brand and image perception, and customer engagement. We will review the results and their implications for organizations in our upcoming article series. The issue, however, is that many companies that want to develop a product and platform model struggle to do so. We analyzed more than 50 organizations across industries and geographies undergoing product and platform operating model transformations. (See sidebar “About our Operating Model Index.”) Although a few companies have met or exceeded their objectives, the efforts of a significant number either have stalled (for various reasons) or were unable to scale following initial progress. What do the few get right that eludes the many? Our analysis revealed five actions that are critical for transitioning successfully to a product and platform operating model: getting the design of products right, prioritizing platform redesign, partnering with the business, rethinking tech governance, and transforming software engineering practices. 1. Build product teams around the end-user experience In a product and platform operating model, “products” are the technology-enabled offerings—tools, services, or experiences—that allow customers and employees to engage in activities that create value. These might include “search” for a retailer, for example, or “financial planning and analysis” for a finance team. These products can be grouped around a variety of organizing principles, each with a specific team to serve the needs of the end user, deliver on the goals of the business, and align with the organization’s market position or digital maturity. For example, a market leader whose main concern is providing an omnichannel experience will set up multidisciplinary teams organized around products, such as ordering, and provide these products through multiple channels. Platform teams provide and maintain services that product teams consume (such as CRM and authentication). An effective organizational approach has often been to build product teams around stages of the customer experience surrounding a purchase, from search to payment, or adjacent capabilities, such as loyalty programs or billing functions. Teams might also be organized around the employee experience, from recruitment to onboarding. In these approaches, the emphasis is on models that can be broadly applied and reused. Key considerations when creating product teams There are a number of questions that leaders should ask themselves when setting up their product teams: Each product team will have a mission and be accountable for business outcomes. The teams must be small enough to be effective, yet contain all the cross-functional skills required for the team to function autonomously. It is critical to keep the number of teams manageable. Too many can strain resources while blurring accountability and adding bureaucracy. (See sidebar “Key considerations when creating product teams.”) A global telco ran into several challenges when it rolled out its digital transformation prior to shifting to a product and platform design for its entire organization. In some product areas (such as promotions and trade-in), multiple business leaders claimed ownership of the same part of the design, and IT struggled to staff and resource them all. This led to a need for increased coordination, which affected the company’s ability to prioritize work and capture value from the transformation. Eventually, the telco paused the scale-up, designed a full product and platform model that addressed skill needs and talent allocations, aligned all stakeholders, and ensured the business assigned a single owner to each product. Only then did it resume scaling the transformation. Would you like to learn more about McKinsey Technology ? 2. Don’t forget the platforms When embarking on the transformation, companies often assume that simply reorganizing around products will be sufficient. That is rarely the case; indeed, it often results in greater technical debt . Platform teams focus on making a company’s core systems more accessible, reusable, and better able to support products. Platforms develop and manage the underlying core systems (such as identity and access management and order management) and backbone (such as storage, aggregation, analysis, and provision of data) on which products are built. Products consume the services that platforms develop through APIs and microservices. When designing and operationalizing platforms, companies should focus on three elements: Invest time in equipping your people for the change A key for scaling this operating model transformation is building the necessary new capabilities to ensure that everyone is on the same page and understands the role they play in the transformation. A global telco, for instance, created large-scale academies to train more than 1,000 employees with key product roles on product, agile, and DevOps concepts. The company first focused on pilot participants before scaling to the entire organization. It also designed and developed new career paths, incentives, and performance-management systems to support the effort. A well-defined product and platform design can function as the de facto organizational structure (Exhibit 1). Our experience suggests that, since strategic priorities shift from year to year, organizations can anticipate that the design of their products and platforms may also shift by 10 to 15 percent in order to align with strategy. (See sidebar “Invest time in equipping your people for the change.”) The approach to developing a platform capability can vary. An Asia-based bank created large platform teams across business units and geographies with joint business and technology leadership and accountability. Their efforts included developing persistent resourcing, shared performance objectives, and dedicated business processes and technical assets. This approach sped up platform modernization and rapidly increased the autonomy of product teams. A global retailer, on the other hand, had the product and platform groups working together, because the architecture was highly coupled in a few core systems, such as e-commerce platforms. The product and platform leaders committed to working together to modernize the platforms and eventually make them consumable via APIs. 3. Reinvent tech funding to make product and platform teams autonomous Providing product and platform teams with reasonable autonomy requires a flexible but disciplined governance model. The first step is to define accountability to manage demand across different products. For example, all product enhancements and ideas for new features should flow to the leader of the respective product category or senior product owner, who oversees multiple product teams and helps with decisions on prioritization and resource allocation. That person regularly (perhaps quarterly) updates a central portfolio team to provide transparency on progress. This approach decentralizes decision making, eliminates duplicate responsibilities in the organization, and nourishes a collaborative and outcome-based culture. This shift begins by funding product areas so that each product and platform leader has the autonomy to make and adjust funding decisions for their teams. Product leaders should have a single prioritized backlog (building features, fixing errors, remediating technical debt) and secure capital and operating expenditures to keep consistent product teams in place. Functions such as design and agile coaching are often funded through earmarked operating budgets. The quid pro quo of providing more autonomy to product and platform teams is that the teams commit to clear OKRs linked to outcomes and aligned with the goals of the company. Organizations using OKRs to track progress and dynamically reallocate investments based on performance increase financial accountability, improve control of end-to-end product expenses, and can ultimately capture more value. We have seen organizations using this approach reduce the time required for annual budgeting by more than 60 percent and the time spent on management reporting by 20 to 30 percent. At most companies today, some areas—especially for large existing programs—may maintain project-oriented governance for one to two years, while other areas (such as customer journeys) can move more quickly to product-based governance. It is important to be disciplined in finding the right balance while maintaining progress. Products and platforms: Is your technology operating model ready? 4. Establish joint accountability between tech and the business The main goal of a product and platform transformation is to generate the biggest impact for the business. That requires the IT function to work much more closely with the business and include all functional stakeholders—sales, marketing, supply chain, and customer service. A clear baseline of existing capabilities and a clear blueprint for progress are useful artifacts for aligning tech with the business. From there, companies can establish a mechanism to sustain business involvement in the transformation. That can come from ensuring that a business leader joins each product team, sometimes as the product owner; has a guidance role on platform teams; and shares joint accountability with corresponding tech leads for delivering on the OKRs. Where broad business support for the product and platform transformation exists, a larger scale-up of the operating model and structural changes to it can happen relatively quickly. In other cases, however, initial business champions and early adopters should launch a few teams to start. Even a small group that quickly demonstrates business value can have a big impact on building support in the business, including for more substantial structural changes (Exhibit 2). A regional bank and a global retailer both opted to use a two-in-a-box model, in which a business leader and a tech leader jointly led a product team. This established clear joint accountability for business and technology performance objectives. This model helped the bank and the retailer develop the confidence to push decision making down to the product team level. Another global retailer, meanwhile, took a slightly different approach, opting for a three-in-a-box model that embedded product, design, and engineering leadership in each team. The company replicates this triad at every level (product group, product, team) to ensure that the right capabilities and effective decision making are available at every stage of the journey. 5. Commit to creating a great developer experience Committing to engineering excellence is about more than hiring great engineers. It’s about creating an environment where engineers can thrive by doing work of the highest value, using advanced tools and relying on automation across software development to reduce toil. At its root, this commitment to creating an advanced engineering environment is about focusing on the developer experience . Advanced tooling includes providing on-demand access to self-service environments for testing, a fully automated and secure continuous integration/continuous delivery (CI/CD) pipeline (feature flag of issues, canary release techniques, and zero downtime), and automated life cycle management that makes it easy to observe and trace issues so teams can rapidly address them. Delivering on these capabilities requires a commitment to decoupled architecture, automating security and integrating it into the development process ( DevSecOps ), and tracking the performance of engineering modernization initiatives. These measures enable developers to seamlessly spin up a platform in minutes, easily consume platform services with multiple consumption models (APIs or GitOps), and rapidly make improvements to platforms through an open-source approach (aka InnerSource) to manage code contribution. Creating this kind of work environment requires a commensurate shift in the work that engineers do. Companies should consider allocating 10 to 30 percent of developer capacity to building new engineering and automation capabilities and upgrading skills through tailored learning programs. These capabilities are essential not only to retaining top engineers but also to enabling product and platform teams to rapidly develop quality software. A global telco invested in the developer experience by setting up an enterprise-wide DevSecOps program that ran in lockstep with the product-model transformation. The program had five key pillars: a modern decoupled architecture, CI/CD practices, operational resiliency, security integrated into development, and tech delivery linked to business outcomes. The company supplemented the program by rolling out a central measurement platform to assess both the maturity and adoption of modern engineering practices through a real-time dashboard. The DevSecOps program ran in parallel with an aggressive migration to the public cloud. The program increased innovation, speed, the reliability and quality of code, and cost savings. Transitioning to a product and platform operating model is no small undertaking. But by taking the five actions outlined in this article, organizations can put themselves in a stronger position to capitalize on the benefits of this operating model—not only spurring innovation and developing better products faster but also improving customer experience and increasing total shareholder returns. It’s an effort worth getting right the first time. Rushabh Gala is an associate partner in McKinsey’s Chicago office, where Naufal Khan is a senior partner and Anindita Pal is a consultant; Ling Lau is a partner in the New Jersey office; and Gautam Lunawat is a partner in the Bay Area office. The authors wish to thank Stephane Bout, Leorizio D'Aversa, Nicolas de la Flor, Martin Harrysson, James Kaplan, Eric Lamarre, Megha Sinha, Phil Tuddenham, and Belkis Vasquez-McCall for their contributions to this article. Explore a career with us Related Articles The ERP platform play: Cheaper, faster, better The Tech: Forward recipe for a successful technology transformation The platform play: How to operate like a tech company","Incumbent organizations are shifting towards a product and platform operating model to enhance agility and competitiveness. To succeed, they should focus on five key actions: designing effective product teams, prioritizing platform redesign, reinforcing tech-business collaboration, rethinking tech governance,"
Rewired to outcompete,Six signature moves led by the C-suite can build organizations that will outperform in the age of digital and AI.,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/rewired-to-outcompete,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/rewired%20to%20outcompete/qweb-rewired-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,2023-06-20T12:00:00Z,"Rewired to outcompete How companies navigate the technology world to achieve sustainable competitive advantage is the defining business challenge of our time. To be fair, this challenge isn’t new. But it’s an increasingly pressing one, with deep implications for how companies navigate a world where digital and AI are fundamentally reshaping how we work and live. Companies understand they need to meet the challenge, but most of them are struggling. McKinsey research shows that while 90 percent of companies have launched some flavor of digital transformation, only a third of the expected revenue benefits, on average, have been realized . 1 “ Three new mandates for capturing a digital transformation’s full value ,” McKinsey, June 15, 2022. Yet it’s also a challenge with enormous potential for the companies that get it right. In the banking sector, for example, where digital and AI transformations have been under way for the past decade, compelling empirical data shows that digitally transformed banks outperform their peers. We leveraged a unique data set, Finalta by McKinsey, to analyze 20 digital leaders and 20 digital laggards in retail banking between 2018 and 2022. The results were startling. Digital leaders improved their return on tangible equity, their P/E ratio, and their total shareholder returns materially more than digital laggards (Exhibit 1). Digital excellence is translating into financial outperformance. This outperformance was propelled by a deeper integration of technology across end-to-end core business processes. This, in turn, drove higher digital sales and lower costs in branches and operations. How did the digital leaders accomplish this? By bringing business, technology, and operations more closely together to digitally innovate; by upskilling their organizations; and by building a distributed technology and data environment to empower hundreds if not thousands of teams to digitally innovate, day in, day out. This gets at the nub of why digital and AI transformations are so difficult—companies need to get a lot of things right. Clearly, for digital and AI to deliver on their business transformation potential, the top team needs to be ready and willing to undertake the organizational “surgery” required to become a digitally capable enterprise. There are no quick fixes. You can’t simply implement a system or a technology and be done. Instead, success means having hundreds of technology-driven solutions (proprietary and off the shelf) working together that you continually improve to create great customer and employee experiences, lower unit costs, and generate value. But creating, managing, and evolving these solutions at enterprise scale requires a fundamental rewiring of how a company operates. That means getting thousands of people across different units of the organization working together and working differently to digitally innovate, constantly. Creating value beyond the hype The lessons learned from our work with more than 200 large companies across multiple industries show that capturing this kind of value from digital and AI requires building six critical enterprise capabilities (Exhibit 2). These allow rewired companies to integrate new technologies, such as generative AI, and harness them to create value. While companies may understand this at a high level, they struggle with how to build these capabilities successfully and ensure that they work together across the enterprise. Our new book, Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI , is all about the how . This article is adapted from that book and delineates the core aspects of what it takes for leaders to spur transformation across all six capabilities. Before we go into detail, it’s worth highlighting two key findings. First, no digital and AI transformation can be successful without building a baseline of competence across all six capabilities. Second, these elements are interconnected and need to be managed that way: a good operating model, for example, can’t work without the right talent. Similarly, great technology won’t make much of an impact if users don’t adopt it. You do not have to be a tech company to achieve excellence in digital and AI. Large, established companies can outcompete and capture value, but only when they are willing to commit to the hard work of rewiring their enterprise. This is a job for the entire C-suite, not just the CEO or the chief information officer (CIO). The cross-functional nature of a digital and AI transformation requires an unparalleled level of collaboration across the C-suite, with everyone having an important part to play in building these enterprise capabilities. Rewiring the business is an ongoing journey of improvement, not a destination. Let’s dig into the details of that journey. Align the C-suite around a business-led road map When evaluating stalled digital and AI transformations, we find that many of the issues that impede a program’s success can be traced back to insufficient planning and alignment. Misunderstanding among leadership at the strategic-planning stage will invariably lead to muddled execution in a company’s transformation. Because digital and AI transformations affect so many parts of the business, investing the necessary time to help make the transformation a success pays significant dividends in terms of clarity and unified action. The best companies make sure to get three early moves right. Inspire and align the top team. Take the time to establish a common digital language, learn from other companies that are further along the journey, develop a shared vision among the C-suite, and explicitly agree on a set of commitments that match your ambitions. Consider the example of DBS Bank, one of the world’s most successful digitally transformed banks . CEO Piyush Gupta and his top leaders visited and learned from top tech companies around the globe and used those lessons to shape a vision around “Making Banking Joyful” and to commit to making DBS a tech leader. This kind of leadership alignment is crucial to ensuring a successful digital and AI transformation. Get the ‘bite’ size right: business domains. Some companies struggle from the start of their digital and AI transformation by getting the scope of the change wrong. They start too small—believing that implementing a few use cases will lower risk—or they spread bets and resources too thinly across an uncoordinated set of initiatives. Both approaches typically produce little value. Successful companies, on the other hand, focus their efforts on a few important business domains, such as a production process or the customer journey, and transform them from end to end. As many as 80 percent of successful interventions in struggling digital and AI transformations are based on reanchoring the scope to spur a concerted effort against a few well-defined domains. Commit to a contract with the C-suite. Effective rewiring requires companies to tie the transformation outcomes of each business domain to specific improvements in operational KPIs, such as reduction in customer churn or improvements in process yield. The team builds a road map where the digital solutions that underpin these KPI improvements are sequenced in a way to produce meaningful value in the short term (say, 12 to 18 months) and transformational value in the medium term (three to five years, for example). The plan explicitly accounts for the build-out of enterprise capabilities, such as hiring digital talent or modernizing data architecture. C-suite leaders commit to these KPI improvements, and the expected benefits are baked into their business objectives. Our rule of thumb is that a robust digital road map should deliver EBIT improvement of
20 percent or more. When business leaders define an ambitious yet realistic transformation of their business domains with technology, they set in motion the flywheel of digital change. The resulting digital road map is their signature move and effectively acts as a contract that they commit to implementing. When business leaders define an ambitious yet realistic transformation of their business domains with technology, they set in motion the flywheel of digital change. Build your talent bench No company can outsource its way to digital excellence. Being digital means having your own bench of digital talent—product owners, experience designers, cloud engineers, software developers, and so on—working side by side with your business colleagues. Digital transformations are, first and foremost, people transformations. The following are three actions that digital leaders take. Create a cleansheet for your talent. Most companies have digital technologists, but many still face the hard work of reskilling their technology and IT organization. The aspiration should be to have 70 to 80 percent of your digital talent in-house, with 20 to 30 percent coming from outside the company and focused on specialized skills, flexibility, or both. Your talent pyramid should shift to a diamond shape, with more competent technologists and fewer novices. That’s because there is a step change in productivity from more experienced technologists. You should also have a healthy ratio of hands-on-keyboard technologists versus managerial roles. Rewired leaders target a 4:1 ratio (or better) of engineers to managers, versus the 1:1 found at many companies. Get religion about skills. Rewired companies develop very granular skill progression grids supported by credentials. For example, Big Tech companies have up to ten levels of data engineers, each with different skill levels and compensation ranges. Without a precise calibration of skills, it becomes difficult to recognize distinctive technologists and compensate them accordingly. Skill progression also gets built into expert-based career tracks and in learning and development programs. In short, the whole digital-talent model revolves around fostering excellence in people devoted to their craft. Build the team that will build your digital bench. Many HR organizations are hampered by slow recruiting and onboarding processes, rigid compensation frameworks, and outdated learning and development programs for digital talent. But transforming your entire HR organization and underlying HR processes to make them digital ready may not be practical. Setting up a special team focused on adapting current HR processes to win digital talent is the most pragmatic—and successful—way forward. We call this designated team the Talent Win Room (TWR). The primary mission of a TWR is to find technologists with the right skills and to build and continually improve all facets of both the candidate and employee experience. These shifts in talent practices are not simple, but they are fundamental to becoming rewired with the right talent. While every C-suite executive will have a part to play in this talent reinvention, this is often the chief human resources officer’s signature contribution to the enterprise’s digital transformation. Adopt a new operating model that can scale Most companies have succeeded in standing up a handful of cross-functional agile teams. But scaling up so that hundreds or even thousands of teams work that way, as rewired businesses do, is a daunting challenge. Developing the right operating model to bring business, technology, and operations closer together is perhaps the most complex aspect of a digital and AI transformation because it touches the core of the organization and how people work. Developing the right operating model to bring business, technology, and operations closer together is perhaps the most complex aspect of a digital and AI transformation. Three leading models have emerged: digital factory, product and platform, and enterprise-wide agile. Each of these models is built on two core ideas. The first is that small, multidisciplinary agile teams, or pods, are the most effective and efficient way to develop software. Second, pods work together most effectively when some are focused on directly improving a customer or user experience (generally called product pods, although they can also be called experience or journey pods) while others focus on creating reusable services to accelerate the work of all pods (called platform pods). Examples of such services could include a customer-360 data set or an easy way for teams to provision compute and storage capacity. The implementation of a new operating model is, in our opinion, one of the most significant pivots a company can make to become a rewired enterprise. There are two key moves to getting this right. Select an operating model that supports your strategy. The digital factory is a separate organizational unit where people work together to build digital solutions for the business units or functions that fund the digital factory. Companies often initially select the digital-factory model because it is a self-contained operating unit and can be implemented relatively quickly (typically 12 to 18 months before it’s fully operational, though it can get started in a matter of weeks). BHP and Scotiabank, for example, have implemented this model. The product and platform model is a more evolved version of the digital factory. While the digital factory might contain 20 to 50 pods, the product and platform model will typically have a few hundred pods, sometimes thousands for large companies. When companies move to a product and platform model, they are making a major strategic decision to realign large parts of the organization to better exploit technology in their core business. Amazon, Google, Itaú Unibanco, and JPMorgan Chase have all implemented this model. Finally, the enterprise-wide agile model builds on the product and platform model and extends the benefit of agile to the entire business, not just the technology-intensive areas. For example, key account sales and R&D can also benefit from working in small, cross-functional teams. Companies adopt this model when they believe that customer centricity, collaboration, and flexible resource deployment are key performance differentiators across the entire enterprise. ING and Spark New Zealand have successfully implemented this model. Professionalize product management. A crucial difference between tech companies and their peers in other sectors is the degree to which they have embedded product management capabilities in their operating models. This capability, in our opinion, makes or breaks the implementation of a new operating model. Some 75 percent of business leaders in a McKinsey survey responded that product management best practices aren’t being adopted at their companies, that product management is a nascent function within their organizations, or that it doesn’t exist at all. 2 Chandra Gnanasambandam, Martin Harrysson, Jeremy Schneider, and Rikki Singh, “ What separates top product managers from the rest of the pack ,” McKinsey, January 20, 2023. That’s a problem. It’s also hard to recruit great product managers because understanding the industry and the company context matters. Most companies end up reskilling and building new career tracks for this rare talent, but this requires substantial investments to ensure good results. The shift to a new operating model is the signature move of CEOs in rewiring the company. Only they can catalyze such large-scale organizational change. Technology for speed and distributed innovation The main purpose of technology within a rewired company is to make it easy for hundreds, if not thousands, of pods to constantly develop and release digital innovations. This requires a distributed technology environment where every pod can access the software development tools, data, and applications they need. While leaders hoping to create that environment have a raft of decisions to make, three priorities stand out. Kit out a technology toolbox. Just like woodworkers, surgeons, or plumbers, software developers need the proper tools to do their work. As an organization scales from five agile pods to 100, or even more than 1,000, it doesn’t make sense for pod members to be calling IT every time they have a basic request, such as additional storage capacity or access to a collaboration tool. Leading companies build a developer platform: a self-service portal that makes it easy to access and use all the standardized and company-approved tools. Use APIs without exception. Once developers have their tools, they need access to data and existing app functionalities to build their solutions. Application programming interfaces (APIs) do that by systematically minimizing dependencies in the architecture by making application functionalities and data easily accessible. Without it, pods will constantly find themselves depending on other pods. Amazon’s Jeff Bezos was so adamant about using APIs that he wrote a famous memo about it, which fundamentally changed Amazon and the world of software. The memo essentially said that all teams were expected to expose their data and functionality through service interfaces (that is, APIs) and to communicate with one another through only these interfaces. No other form of inter-process communication would be allowed. No exceptions. Automate software delivery. Have you ever wondered how an app on your phone can be upgraded so frequently? That seamless functionality is made possible by software delivery automation, also known as CI/CD: continuous integration and continuous delivery. This is the method for systematically automating all steps, including quality checks, testing, packaging (that is, containerization), and staged deployment of the solution to the user. With CI/CD, updates that used to take weeks or months can now be completed in minutes, allowing pods to release incremental improvements weekly or even daily and thus unleash much faster innovation cycles. You won’t be able to achieve distributed digital and AI innovation if pods aren’t able to release code to a production environment quickly and easily. This fixation on automation needs to carry over to AI and machine-learning (ML) models. These models are like living organisms—they need to be constantly recalibrated as new data accumulate and then monitored in real time for drift and biases. When this doesn’t happen, AI/ML models fail to transition to full-scale production. Solving for this has required a specialized type of automation called machine learning operations (MLOps). For example, Vistra, a leading energy company, built MLOps automation to support more than 400 AI/ML models deployed to optimize different parts of its power plant operations. Most CIOs have started their companies’ journey to build a robust developer platform, decouple the components of the architecture from one another through APIs, and automate their software delivery pipeline. But we know very few companies that have scaled this across their enterprise. The change management efforts are significant, and the software engineering talent required is in short supply. Creating a technology environment that enables distributed digital and AI innovations is a cornerstone capability of rewired enterprises and a signature contribution by the CIO, the chief data officer (CDO), or both. Embed data everywhere In established companies, data is often a source of frustration. As much as 70 percent of the effort involved in developing AI-based solutions can be attributed to wrangling and harmonizing data. Unless data is thoughtfully sorted and organized for easy consumption and reuse, scaling solutions can be a big challenge. The ability to constantly improve customer experience and drive down unit cost depends on giving each digital and AI team (near) real-time access to data. Companies can focus on three areas to achieve this. Turn to reusable building blocks: data products. Data products are the secret sauce for scaling AI. They help deliver data-intensive applications as much as 90 percent faster, at 30 percent lower cost, and with a reduced risk and data governance burden. A data product delivers a high-quality, ready-to-use set of data in a way that people and applications across the organization can easily access and consume. For example, a data product could provide a 360-degree view of an important entity, such as customers, employees, product lines, or stores. Companies can prioritize building data products that have the broadest application, that are critical for teams developing priority solutions, and that are unique. Building data products requires dedicated teams and investments. Install the data architecture ‘plumbing.’ Data architecture is the system of “pipes” that deliver data from where it is stored to where it is used. When implemented well, data architecture hastens a company’s ability to build reusable and high-quality data products and to put data within reach of any team in the organization. We have seen very rapid technological progress in this field. The emergence of new architectural patterns such as the “data lakehouse” (an innovation that combines the capabilities of a data lake and a data warehouse into a single, integrated platform) makes it easier for companies to solve for both their business intelligence and their AI needs. Federate data governance. Data touches all aspects of an organization, so its governance needs to account for that complexity. Rewired companies deploy a federated model where a central function (that is, a data management office) sets policies and standards and provides support and oversight, while business units and functions manage activities such as developing data products and building data pipelines to enable consumption. A data environment that allows for easy data consumption by hundreds of distributed teams is another signature move of the CIO in collaboration with the CDO. It enables data-driven decisions, feeds real-time decision-making systems, and propels faster continuous-improvement loops. Unlocking adoption and scaling Developing a good digital solution can be complex and difficult. But getting customers or business users to adopt that solution as part of their day-to-day activities and then scaling that solution across the enterprise are often the biggest challenges. Successful companies concentrate on the following three moves. Focus equally on adoption and development. User adoption starts with developing great technology solutions that offer an excellent customer experience. But companies often underestimate all the additional elements of the business model that need to be changed to secure adoption. For instance, an insurance company that developed analytic solutions to help agents upsell customers on policies also needed to make changes to pricing algorithms, sales force incentives, distribution and customer engagement models, and metrics and performance indicators. That end-to-end system approach, with a focus on the people side of the equation, is what differentiates digital leaders. They achieve this by making the business accountable for the end-to-end transformation of the domain. As a rule, for every $1 spent on developing digital and AI solutions, plan to spend at least another $1 to ensure full user adoption and scaling across the enterprise. Scale with ‘assetizing.’ Replicating the adoption of a solution in different environments, such as a network of plants, or in different geographic markets, customer segments, or organizational groups is challenging. Companies often find themselves redoing a lot of work and struggling to tailor solutions to local environments. All this extra work is a scale killer, and that’s why 72 percent of companies stall at this stage. Digital leaders solve this by “assetizing” solutions, which typically allows 60 to 90 percent of a digital and AI solution to be reused, leaving just 10 to 40 percent in need of local customization. Track what matters. No one will debate the need to measure the progress of a digital transformation. But the question is what to measure and how. Performance tracking that is poorly designed and lacking the right supporting tools can quickly crumble under its own weight. Rewired companies take the pods responsible for objectives and key results and link them to operational KPIs, tracking the progression of each pod in a disciplined stage gate review process. The ability to capture the full economic potential of digital innovations is a core differentiator between digital leaders and laggards. Building this capability is the signature move of business unit and function leaders. The capabilities we have laid out for a successful digital and AI transformation present a rich “how to” agenda. You may be wondering where to start your rewiring journey. Why not start where we began this article: by bringing the top team together and having them reflect on your journey thus far? A digital and AI transformation is ultimately an exercise in constant evolution and improvement. If you accept this premise, it will change your perspective on how you approach this critical challenge. To borrow Jeff Bezos’s expression to Amazon shareholders about the importance of operating like a digital native: it’s always day one for digital and AI transformation. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles Rewired Author Talks: What is the key to unlocking digital transformation? Three new mandates for capturing a digital transformation’s full value","Companies face the challenge of navigating digital transformation to achieve sustainable competitive advantage, yet many struggle to realize benefits. Successful transformation requires integrating technology, upskilling talent, and adopting a new operating model. Collaboration across the C-suite is essential, with ongoing improvements"
Technology’s generational moment with generative AI: A CIO and CTO guide,CIOs and CTOs can take nine actions to reimagine business and technology with generative AI.,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/technologys-generational-moment-with-generative-ai-a-cio-and-cto-guide,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/technologys%20generational%20moment%20with%20generative%20ai%20a%20cio%20and%20cto%20guide/thumb-gettyimages-1470777844.jpg?cq=50&mw=767&car=16:9&cpy=Center,2023-07-11T12:00:00Z,"Technology’s generational moment with generative AI: A CIO and CTO guide Hardly a day goes by without some new business-busting development related to generative AI surfacing in the media. The excitement is well deserved— McKinsey research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion of value annually. 1 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. About the authors This article is a collaborative effort by Aamer Baig , Sven Blumberg , Eva Li, Douglas Merrill, Adi Pradhan, Megha Sinha, Alexander Sukharevsky , and Stephen Xu, representing views from McKinsey Digital. CIOs and chief technology officers (CTOs) have a critical role in capturing that value, but it’s worth remembering we’ve seen this movie before. New technologies emerged—the internet, mobile, social media—that set off a melee of experiments and pilots, though significant business value often proved harder to come by. Many of the lessons learned from those developments still apply, especially when it comes to getting past the pilot stage to reach scale. For the CIO and CTO, the generative AI boom presents a unique opportunity to apply those lessons to guide the C-suite in turning the promise of generative AI into sustainable value for the business. A quick primer on key terms Generative AI is a type of AI that can create new content (text, code, images, video) using patterns it has learned by training on extensive (public) data with machine learning (ML) techniques. Foundation models (FMs) are deep learning models trained on vast quantities of unstructured, unlabeled data that can be used for a wide range of tasks out of the box or adapted to specific tasks through fine-tuning. Examples of these models are GPT-4, PaLM 2, DALL·E 2, and Stable Diffusion. Large language models (LLMs) make up a class of foundation models that can process massive amounts of unstructured text and learn the relationships between words or portions of words, known as tokens. This enables LLMs to generate natural-language text, performing tasks such as summarization or knowledge extraction. Cohere Command is one type of LLM; LaMDA is the LLM behind Bard. Fine-tuning is the process of adapting a pretrained foundation model to perform better in a specific task. This entails a relatively short period of training on a labeled data set, which is much smaller than the data set the model was initially trained on. This additional training allows the model to learn and adapt to the nuances, terminology, and specific patterns found in the smaller data set. Prompt engineering refers to the process of designing, refining, and optimizing input prompts to guide a generative AI model toward producing desired (that is, accurate) outputs. Through conversations with dozens of tech leaders and an analysis of generative AI initiatives at more than 50 companies (including our own), we have identified nine actions all technology leaders can take to create value, orchestrate technology and data, scale solutions, and manage risk for generative AI (see sidebar, “A quick primer on key terms”): Creating value beyond the hype 1. Determine the company’s posture for the adoption of generative AI As use of generative AI becomes increasingly widespread, we have seen CIOs and CTOs respond by blocking employee access to publicly available applications to limit risk. In doing so, these companies risk missing out on opportunities for innovation, with some employees even perceiving these moves as limiting their ability to build important new skills. Instead, CIOs and CTOs should work with risk leaders to balance the real need for risk mitigation with the importance of building generative AI skills in the business. This requires establishing the company’s posture regarding generative AI by building consensus around the levels of risk with which the business is comfortable and how generative AI fits into the business’s overall strategy. This step allows the business to quickly determine company-wide policies and guidelines. Once policies are clearly defined, leaders should communicate them to the business, with the CIO and CTO providing the organization with appropriate access and user-friendly guidelines. Some companies have rolled out firmwide communications about generative AI, provided broad access to generative AI for specific user groups, created pop-ups that warn users any time they input internal data into a model, and built a guidelines page that appears each time users access a publicly available generative AI service. 2. Identify use cases that build value through improved productivity, growth, and new business models CIOs and CTOs should be the antidote to the “death by use case” frenzy that we already see in many companies. They can be most helpful by working with the CEO, CFO, and other business leaders to think through how generative AI challenges existing business models, opens doors to new ones, and creates new sources of value. With a deep understanding of the technical possibilities, the CIO and CTO should identify the most valuable opportunities and issues across the company that can benefit from generative AI—and those that can’t. In some cases, generative AI is not the best option. McKinsey research , for example, shows generative AI can lift productivity for certain marketing use cases (for example, by analyzing unstructured and abstract data for customer preference) by roughly 10 percent and customer support (for example, through intelligent bots) by up to 40 percent. 2 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. The CIO and CTO can be particularly helpful in developing a perspective on how best to cluster use cases either by domain (such as customer journey or business process) or use case type (such as creative content creation or virtual agents) so that generative AI will have the most value. Identifying opportunities won’t be the most strategic task—there are many generative AI use cases out there—but, given initial limitations of talent and capabilities, the CIO and CTO will need to provide feasibility and resource estimates to help the business sequence generative AI priorities. Providing this level of counsel requires tech leaders to work with the business to develop a FinAI capability to estimate the true costs and returns on generative AI initiatives. Cost calculations can be particularly complex because the unit economics must account for multiple model and vendor costs, model interactions (where a query might require input from multiple models, each with its own fee), ongoing usage fees, and human oversight costs. 3. Reimagine the technology function Generative AI has the potential to completely remake how the tech function works. CIOs and CTOs need to make a comprehensive review of the potential impact of generative AI on all areas of tech, but it’s important to take action quickly to build experience and expertise. There are three areas where they can focus their initial energies: 4. Take advantage of existing services or adapt open-source generative AI models A variation of the classic “rent, buy, or build” decision exists when it comes to strategies for developing generative AI capabilities. The basic rule holds true: a company should invest in a generative AI capability where it can create a proprietary advantage for the business and access existing services for those that are more like commodities. The CIO and CTO can think through the implications of these options as three archetypes: Each archetype has its own costs that tech leaders will need to consider (Exhibit 1). While new developments, such as efficient model training approaches and lower graphics processing unit (GPU) compute costs over time, are driving costs down, the inherent complexity of the Maker archetype means that few organizations will adopt it in the short term. Instead, most will turn to some combination of Taker, to quickly access a commodity service, and Shaper, to build a proprietary capability on top of foundation models. 5. Upgrade your enterprise technology architecture to integrate and manage generative AI models Organizations will use many generative AI models of varying size, complexity, and capability. To generate value, these models need to be able to work both together and with the business’s existing systems or applications. For this reason, building a separate tech stack for generative AI creates more complexities than it solves. As an example, we can look at a consumer querying customer service at a travel company to resolve a booking issue (Exhibit 2). In interacting with the customer, the generative AI model needs to access multiple applications and data sources. For the Taker archetype, this level of coordination isn’t necessary. But for companies looking to scale the advantages of generative AI as Shapers or Makers, CIOs and CTOs need to upgrade their technology architecture. The prime goal is to integrate generative AI models into internal systems and enterprise applications and to build pipelines to various data sources. Ultimately, it’s the maturity of the business’s enterprise technology architecture that allows it to integrate and scale its generative AI capabilities. Recent advances in integration and orchestration frameworks, such as LangChain and LlamaIndex, have significantly reduced the effort required to connect different generative AI models with other applications and data sources. Several integration patterns are also emerging, including those that enable models to call APIs when responding to a user query—GPT-4, for example, can invoke functions—and provide contextual data from an external data set as part of a user query, a technique known as retrieval augmented generation. Tech leaders will need to define reference architectures and standard integration patterns for their organization (such as standard API formats and parameters that identify the user and the model invoking the API). There are five key elements that need to be incorporated into the technology architecture to integrate generative AI effectively (Exhibit 3): In evolving the architecture, CIOs and CTOs will need to navigate a rapidly growing ecosystem of generative AI providers and tooling. Cloud providers provide extensive access to at-scale hardware and foundation models, as well as a proliferating set of services. MLOps and model hub providers, meanwhile, offer the tools, technologies, and practices to adapt a foundation model and deploy it into production, while other companies provide applications directly accessed by users built on top of foundation models to perform specific tasks. CIOs and CTOs will need to assess how these various capabilities are assembled and integrated to deploy and operate generative AI models. 6. Develop a data architecture to enable access to quality data The ability of a business to generate and scale value, including cost reductions and improved data and knowledge protections, from generative AI models will depend on how well it takes advantage of its own data. Creating that advantage relies on a data architecture that connects generative AI models to internal data sources, which provide context or help fine-tune the models to create more relevant outputs. In this context, CIOs, CTOs, and chief data officers need to work closely together to do the following: McKinsey launches new product suite to help clients scale AI 7. Create a centralized, cross-functional generative AI platform team Most tech organizations are on a journey to a product and platform operating model . CIOs and CTOs need to integrate generative AI capabilities into this operating model to build on the existing infrastructure and help to rapidly scale adoption of generative AI. The first step is setting up a generative AI platform team whose core focus is developing and maintaining a platform service where approved generative AI models can be provisioned on demand for use by product and application teams. The platform team also defines protocols for how generative AI models integrate with internal systems, enterprise applications, and tools, and also develops and implements standardized approaches to manage risk, such as responsible AI frameworks. CIOs and CTOs need to ensure that the platform team is staffed with people who have the right skills. This team requires a senior technical leader who acts as the general manager. Key roles include software engineers to integrate generative AI models into existing systems, applications, and tools; data engineers to build pipelines that connect models to various systems of record and data sources; data scientists to select models and engineer prompts; MLOps engineers to manage deployment and monitoring of multiple models and model versions; ML engineers to fine-tune models with new data sources; and risk experts to manage security issues such as data leakage, access controls, output accuracy, and bias. The exact composition of the platform team will depend on the use cases being served across the enterprise. In some instances, such as creating a customer-facing chatbot, strong product management and user experience (UX) resources will be required. Realistically, the platform team will need to work initially on a narrow set of priority use cases, gradually expanding the scope of their work as they build reusable capabilities and learn what works best. Technology leaders should work closely with business leads to evaluate which business cases to fund and support. 8. Tailor upskilling programs by roles and proficiency levels Generative AI has the potential to massively lift employees’ productivity and augment their capabilities. But the benefits are unevenly distributed depending on roles and skill levels, requiring leaders to rethink how to build the actual skills people need. Our latest empirical research using the generative AI tool GitHub Copilot, for example, helped software engineers write code 35 to 45 percent faster. 5 “ Unleashing developer productivity with generative AI ,” June 27, 2023. The benefits, however, varied. Highly skilled developers saw gains of up to 50 to 80 percent, while junior developers experienced a 7 to 10 percent decline in speed. That’s because the output of the generative AI tools requires engineers to critique, validate, and improve the code, which inexperienced software engineers struggle to do. Conversely, in less technical roles, such as customer service, generative AI helps low-skill workers significantly, with productivity increasing by 14 percent and staff turnover dropping as well, according to one study. 6 Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work , National Bureau of Economic Research (NBER) working paper, number 31161, April 2023. These disparities underscore the need for technology leaders, working with the chief human resources officer (CHRO), to rethink their talent management strategy to build the workforce of the future. Hiring a core set of top generative AI talent will be important, and, given the increasing scarcity and strategic importance of that talent, tech leaders should put in place retention mechanisms, such as competitive salaries and opportunities to be involved in important strategic work for the business. Tech leaders, however, cannot stop at hiring. Because nearly every existing role will be affected by generative AI, a crucial focus should be on upskilling people based on a clear view of what skills are needed by role, proficiency level, and business goals. Let’s look at software developers as an example. Training for novices needs to emphasize accelerating their path to become top code reviewers in addition to code generators. Similar to the difference between writing and editing, code review requires a different skill set. Software engineers will need to understand what good code looks like; review the code created by generative AI for functionality, complexity, quality, and readability; and scan for vulnerabilities while ensuring they do not themselves introduce quality or security issues in the code. Furthermore, software developers will need to learn to think differently when it comes to coding, by better understanding user intent so they can create prompts and define contextual data that help generative AI tools provide better answers. Beyond training up tech talent, the CIO and CTO can play an important role in building generative AI skills among nontech talent as well. Besides understanding how to use generative AI tools for such basic tasks as email generation and task management, people across the business will need to become comfortable using an array of capabilities to improve performance and outputs. The CIO and CTO can help adapt academy models to provide this training and corresponding certifications. The decreasing value of inexperienced engineers should accelerate the move away from a classic talent pyramid, where the greatest number of people are at a junior level, to a structure more like a diamond, where the bulk of the technical workforce is made up of experienced people. Practically speaking, that will mean building the skills of junior employees as quickly as possible while reducing roles dedicated to low-complexity manual tasks (such as writing unit tests). 9. Evaluate the new risk landscape and establish ongoing mitigation practices Generative AI presents a fresh set of ethical questions and risks, including “hallucinations,” whereby the generative AI model presents an incorrect response based on the highest-probability response; the accidental release of confidential personally identifiable information; inherent bias in the large data sets the models use; and high degrees of uncertainty related to intellectual property (IP). CIOs and CTOs will need to become fluent in ethics, humanitarian, and compliance issues to adhere not just to the letter of the law (which will vary by country) but also to the spirit of responsibly managing their business’s reputation. Addressing this new landscape requires a significant review of cyber practices and updating the software development process to evaluate risk and identify mitigation actions before model development begins, which will both reduce issues and ensure the process doesn’t slow down. Proven risk-mitigation actions for hallucinations can include adjusting the level of creativity (known as the “temperature”) of a model when it generates responses; augmenting the model with relevant internal data to provide more context; using libraries that impose guardrails on what can be generated; using “moderation” models to check outputs; and adding clear disclaimers. Early generative AI use cases should focus on areas where the cost of error is low, to allow the organization to work through inevitable setbacks and incorporate learnings. To protect data privacy, it will be critical to establish and enforce sensitive data tagging protocols, set up data access controls in different domains (such as HR compensation data), add extra protection when data is used externally, and include privacy safeguards. For example, to mitigate access control risk, some organizations have set up a policy-management layer that restricts access by role once a prompt is given to the model. To mitigate risk to intellectual property, CIOs and CTOs should insist that providers of foundation models maintain transparency regarding the IP (data sources, licensing, and ownership rights) of the data sets used. Generative AI is poised to be one of the fastest-growing technology categories we’ve ever seen. Tech leaders cannot afford unnecessary delays in defining and shaping a generative AI strategy. While the space will continue to evolve rapidly, these nine actions can help CIOs and CTOs responsibly and effectively harness the power of generative AI at scale. Aamer Baig is a senior partner in McKinsey’s Chicago office; Sven Blumberg is a senior partner in the Düsseldorf office; Eva Li is a consultant in the Bay Area office, where Megha Sinha is a partner; Douglas Merrill is a partner in the Southern California office; Adi Pradhan and Stephen Xu are associate partners in the Toronto office; and Alexander Sukharevsky is a senior partner in the London office. The authors wish to thank Stephanie Brauckmann, Anusha Dhasarathy, Martin Harrysson, Klemens Hjartar, Alharith Hussin, Naufal Khan, Sam Nie, Chandrasekhar Panda, Henning Soller, Nikhil Srinidhi, Asin Tavakoli, Niels Van der Wildt, and Anna Wiesinger for their contributions to this article. Explore a career with us Related Articles Unleashing developer productivity with generative AI The economic potential of generative AI: The next productivity frontier What every CEO should know about generative AI","Generative AI could add $2.6 to $4.4 trillion in annual value, presenting CIOs and CTOs with opportunities to drive innovation. To harness this potential, tech leaders should adopt strategic actions, including establishing generative AI policies,"
Cloud by McKinsey,"The cloud is revolutionizing how businesses create value, but only when tech organizations, and the business, understand how...",https://www.mckinsey.com/capabilities/mckinsey-digital/cloud/cloud-insights/all-insights,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/cloud%20by%20mckinsey/overview/standard-capturing-value-in-cloud.jpg?cq=50&mw=767&car=16:9&cpy=Center,No date found,"Cloud Insights Featured Insights Building an engineering culture and resilient technology Ending the confusion in cloud transformations: The dashboards and metrics everyone needs The state of cloud computing in Europe: Increasing adoption, low returns, huge potential From legacy to cloud: Lessons learned The Middle East public cloud: A multibillion-dollar prize waiting to be captured Featured podcast Getting ahead in the cloud There is $3 trillion worth of business value at stake for companies that successfully use cloud technology—yet many are still in a fog. Here’s a clear path toward cloud adoption. Featured collection Cloud Value Radio Three elements for capturing value Featured videos Security as code: How to embrace the cloud securely Insights to impact Cloud value in cash management Establishing the next-generation infrastructure organization to support hybrid cloud Top cloud myths debunked More Insights Lessons from a successful cloud journey: Empathy, community, and a smart approach to value Africa’s leap ahead into cloud: Opportunities and barriers Building the cloud-ready enterprise network In search of cloud value: Can generative AI transform cloud ROI? Cloud-powered technologies for sustainability It’s time for cloud tech to meet operational tech at industrial sites Cloud as the ultimate digital enabler The new era of resiliency in the cloud Banks’ core technology conundrum reaches an inflection point A cloud migration in wartime Focusing on developer experience and embedded security for cloud Migrating two banks to the cloud after a merger Bringing data platforms to cloud Projecting the global value of cloud: $3 trillion is up for grabs for companies that go beyond adoption More for less: Five ways to lower cloud costs without destroying value Five learnings from CTOs and tech leaders on their cloud strategies The future of automotive computing: Cloud and edge What every insurance leader should know about cloud Three big moves that can decide a financial institution’s future in the cloud What is cloud computing? Getting the most from cloud services and containers Cloud in China: The outlook for 2025 The cloud as a strategic ecosystem for innovation and growth Cloud economics and the six most damaging mistakes to avoid It’s cloud time for boards—in seven charts Cloud foundations: Ten commandments for faster—and more profitable—cloud migrations The business value of innovation in the cloud Six practical actions for building the cloud talent you need The benefits of being a cloud trailblazer Boards and the cloud The case for cloud in life sciences Cloud 2030: Capturing Poland’s potential for accelerated digital growth Cloud-migration opportunity: Business value grows, but missteps abound Cloud cost-optimization simulator Fast forward: How cloud computing could transform risk management Security as code: The best (and maybe only) path to securing cloud applications and systems What payers and providers can learn from successful cloud transformations in other industries Lessons from a high-ROI cloud transformation journey Four ways boards can shape the cloud agenda SaaS, open source, and serverless: A winning combination to build and scale new businesses Five Fifty: Cloudy with a chance of billions Building a cloud-ready operating model for agility and resiliency Cloud’s trillion-dollar prize is up for grabs Clearing the air on cloud: How industrial companies can capture cloud technology’s full business value McKinsey acquires Candid Partners, a leader in cloud consulting Agile’s next level: ABN AMRO’s hybrid cloud–DevSecOps transformation Unlocking value: Four lessons in cloud sourcing and consumption How public-sector tech leaders can speed up the journey to the cloud Debunking seven common myths about cloud Making the cloud pay: How industrial companies can accelerate impact from the cloud How CIOs and CTOs can accelerate digital transformations through cloud platforms Three actions CEOs can take to get value from cloud computing How the cloud has moved advanced analytics from exclusive to accessible Deutsche Börse unlocks the benefits of moving to the cloud Unlocking business acceleration in a hybrid cloud world Making a secure transition to the public cloud Connect with Cloud by McKinsey","The content discusses insights and strategies for successful cloud adoption, highlighting the significant business value at stake, the challenges faced by companies, and lessons learned from various industries. It emphasizes the importance of building a resilient infrastructure and maximizing cloud technology's potential for innovation and"
Enterprise software’s growing reach,"With software transforming so many industries, knowing what it takes to succeed in the dynamic sector is becoming critical for...",https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/enterprise-softwares-growing-reach,https://www.mckinsey.com/~/media/mckinsey/industries/technology%20media%20and%20telecommunications/high%20tech/our%20insights/enterprise%20softwares%20growing%20reach/thumb-gettyimages-939787416.jpg?cq=50&mw=767&car=16:9&cpy=Center,No date found,"Enterprise software’s growing reach How efficient growth can fuel enduring value creation in software Anaplan CEO: How decision excellence drives enterprise performance Navigating the generative AI disruption in software The growing importance of software product marketing managers Turning consumer and retail companies into software-driven innovators Software excellence How generative AI could accelerate software product time to market MLOps so AI can scale What’s driving the Nordic countries’ software export surge? Yes, you can measure software developer productivity From product-led growth to product-led sales: Beyond the PLG hype Where could $374 billion in dry powder go? Six themes to watch Unleashing developer productivity with generative AI The art of software pricing: Unleashing growth with data-driven insights Private equity turns to resiliency strategies for software investments What separates top product managers from the rest of the pack The digital reinvention of enterprise tech go-to-market Responsible product management: The critical tech challenge Reversal of fortune: How European software can play to its strengths SaaS and the Rule of 40: Keys to the critical value creation metric The next software disruption: How vendors must adapt to a new era How quote-to-cash excellence can fuel growth for B2B subscription businesses The product management talent dilemma Advanced analytics in software pricing: Enabling sales to price with confidence Introducing customer success 2.0: The new growth engine Product managers for the digital world Software transformation Taking industrial sector tech from cost center to competitive edge From start-up to centaur: Leadership lessons on scaling Embedded finance: The choices and trade-offs for US banks The generative AI opportunity in airline maintenance Five considerations for software private equity in 2024 Thoughtful M&A strategies are key to growth in tech, media, and telecom Tech talent in transition: Seven technology trends reshaping telcos Every company is a software company: Six ‘must dos’ to succeed Leadership lessons: Becoming a software company The SaaS factor: Six ways to drive growth by building new SaaS businesses Debugging the software talent gap in aerospace and defense Winning in software for industrial companies Reaching excellence in software procurement Moving beyond agile to become a software innovator Four myths about building a software business Hardware’s business-model shift: Finding a new path forward Developer Velocity at work: Key lessons from industry digital leaders When code is king: Mastering automotive software excellence Developer Velocity: How software excellence fuels business performance The case for an end-to-end automotive-software platform Executive voices Ya Xu on building AI and machine learning products The promise and the reality of gen AI agents in the enterprise Kareem Yusuf on building sustainability products for your customers Creating a European AI unicorn: Interview with Arthur Mensch, CEO of Mistral AI Thomas Dohmke on improving engineering experience using generative AI Alex Hardiman on product outside of pure technology companies Unlocking autonomous-vehicle development: TIER IV’s open-source blueprint Pali Bhat on building intelligent products Talking innovation in video games with Electronic Arts Gokul Rajaram on product thinking and the future of innovation The power of pace in technology Miro’s Andrey Khusid: Product-led growth in tech and beyond Making product inclusion and equity a core part of tech ‘Find the smartest technologist in the company and make them CEO’ Giving developers a leading role in cybersecurity Building a “digital operating rhythm” with OKR software Leading from the heart: How Freshworks’ CEO built a global tech unicorn Box’s Aaron Levie on navigating SaaS’ several stages of growth Net retention and customer success: Gainsight CEO Nick Mehta on winning at SaaS Turning India into a SaaS power Recovering from ransomware: a conversation with Veritas CEO Greg Hughes Managing growth and value creation in SaaS: An interview with a software leader Unleashing developers’ full talents: An interview with Twilio’s CEO Software and the next normal: A talk with Workday’s cofounder and co-CEO Talent and capabilities The human side of generative AI: Creating a path to productivity Attracting and retaining tech talent to sustain mobility’s growth HR rewired: An end-to-end approach to attracting and retaining top tech talent Cracking the code on digital talent How to close the Black tech talent gap Mining for tech-talent gold: Seven ways to find and keep diverse talent Overcoming the fear factor in hiring tech talent Tech talent tectonics: Ten new realities for finding, keeping, and developing talent Repairing the broken rung on the career ladder for women in technical roles Risk The cyber clock is ticking: Derisking emerging technologies in financial services Software bill of materials: Managing software cybersecurity risks Security as code: The best (and maybe only) path to securing cloud applications and systems Securing software as a service","The content discusses various aspects of enterprise software, including growth strategies, the impact of generative AI, software product management, developer productivity, and the importance of effective pricing. It emphasizes the evolving role of software in businesses and highlights key challenges and opportunities in"
The Rise of Quantum Computing,"Accelerating technological breakthroughs, increasing investment flows, start-up proliferation, and promises of capable quantum...",https://www.mckinsey.com/featured-insights/the-rise-of-quantum-computing,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/the%20rise%20of%20quantum%20computing/1287074793-white-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,No date found,"The Rise of Quantum Computing Steady progress in approaching the quantum advantage Understanding quantum control’s role in scaling quantum computing Quantum sensing: Poised to realize immense potential in many sectors Blocking out the noise: An interview with a quantum computing expert Industry perspectives Quantum technology use cases as fuel for value in finance Gearing up for mobility’s future with quantum computing Pursuing quantum in pharma with purpose: An interview with Boehringer Ingelheim’s CTO Pharma’s digital Rx: Quantum computing in drug research and development More Insights Quantum computing: The time to act is now Bringing quantum computing to data centers Potential and challenges of quantum computing hardware technologies Early value: An introduction to quantum optimizers Is winter coming? Quantum computing’s trajectory in the years ahead Shooting for the moon: How PsiQuantum forged its own path Quantum technology sees record investments, progress on talent gap Five lessons from AI on closing quantum’s talent gap—before it’s too late From basic research to market: Why the recent Nobel Prize in physics matters Quantum computing funding remains strong, but talent gap raises concern How quantum computing can help tackle global warming Quantum computing just might save the planet When—and how—to prepare for post-quantum cryptography Shaping the long race in quantum communication and quantum sensing A quantum wake-up call for European CEOs Quantum computing use cases are getting real—what you need to know Separating the wheat from the chaff: Quantum technology in an era of hype The path forward for quantum computing The current state of quantum computing: Between hype and revolution How quantum computing could change financial services Will quantum computing drive the automotive future? Quantum computing is coming: How can your company prepare? A game plan for quantum computing The next big thing? Quantum computing’s potential impact on chemicals","Quantum computing is advancing rapidly, showing potential in various sectors like finance, pharmaceuticals, and mobility. Despite strong funding, the industry faces a talent gap. Key interviews and insights highlight the urgency for companies to prepare for quantum's transformative impact, while addressing challenges"
Digital transformation: Rewiring for digital and AI,Explore our collection of insights on how to drive successful digital transformations.,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/leadership-and-digital-transformation,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/leadership%20and%20digital%20transformation/standard-digital-transformation-page.jpg?cq=50&mw=767&car=16:9&cpy=Center,No date found,"Digital transformation: Rewiring for digital and AI Featured Insights What it takes to rewire a CPG company to outcompete in digital and AI Implementing generative AI with speed and safety A generative AI reset: Rewiring to turn potential into value in 2024 Rewired and running ahead: Digital and AI leaders are leaving the rest behind Ten unsung digital and AI ideas shaping business Industry perspectives Freeport-McMoRan turns data into value On the brink: Realizing the value of analytics in insurance Clearing data-quality roadblocks: Unlocking AI in manufacturing Unlocking the industrial potential of robotics and automation Digital transformations in energy retail: A shift toward advanced platforms Getting digital transformation right in resource-heavy industries Interviews Embracing digital transformation with a digital factory The power of pace in technology What really works when it comes to digital and AI transformations? Digital transformation to achieve operational excellence How LEGO plays with data: An interview with chief data officer Orlando Machado Digital transformation on the CEO agenda The Committed Innovator: An interview with Anjali Sud, CEO of Vimeo Using ecosystems to reach higher: An interview with the co-CEO of Ping An How the CEO of Samsung SDS sets a course for ‘humble and speedy’ Building a digital New York Times: CEO Mark Thompson Transformation and resilience: An interview with Best Buy’s executive chairman Hubert Joly Make a digital vision real by learning and adapting along the way More insights Choose the right transformation ‘bite size’ MLOps so AI can scale The bottom-line benefit of the product operating model Rewired for value: Digital and AI transformations that work The rewired enterprise: How five companies built to outcompete Rewired to use AI’s superpower Rewired to outcompete What is digital transformation? The EU digital strategy: The impact of data privacy on global business Women in tech: The best bet to solve Europe’s talent shortage Digital transformations: The five talent factors that matter most Generative AI is here: How tools like ChatGPT could change your business Every company is a software company: Six ‘must dos’ to succeed The digital-value guardian: CEOs and digital transformations Scaling AI like a tech native: The CEO’s role How boards can help digital transformations How do you measure success in digital? Five metrics for CEOs The CEO’s new technology agenda A CEO guide for avoiding the ten traps that derail digital transformations","The content discusses the necessity of digital transformation and AI integration for CPG companies to stay competitive. It highlights various insights, interviews, and strategies for effective implementation, emphasizing the importance of data utilization, overcoming challenges, and the CEO's role in fostering successful"
A data leader’s technical guide to scaling gen AI,The emergence of gen AI is forcing data and AI leaders to revisit their data platforms. Companies that move now can position...,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-data-leaders-technical-guide-to-scaling-gen-ai,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/a%20data%20leaders%20technical%20guide%20to%20scaling%20gen%20ai/thumb-gettyimages-1746213675.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-07-08T12:00:00Z,"A data leader’s technical guide to scaling gen AI Data and AI leaders have been working feverishly on generative AI (gen AI) use cases for more than a year. Their experience has provided promising glimpses of the considerable value at stake in gen AI but has also exposed a variety of challenges in getting to scale. Managing data remains one of the main barriers to value creation from gen AI. In fact, 70 percent of top performers in a recent McKinsey survey said they have experienced difficulties integrating data into AI models, ranging from issues with data quality, defining processes for data governance, and having sufficient training data. 1 “ The state of AI in early 2024: Gen AI adoption spikes and starts to generate value ,” McKinsey, May 30, 2024. About the authors This article is a collaborative effort by Asin Tavakoli , Carlo Giovine , Joe Caserta , Jorge Machado , and Kayvaun Rowshankish , with Jon Boorstein and Nathan Westby, representing views from McKinsey Digital and QuantumBlack, AI by McKinsey. In our experience, organizations have been held back by a still maturing understanding of both how to evolve data capabilities to support gen AI cases at scale and how to use gen AI to improve data practices. This article will cover three actions that data and AI leaders can consider to help them move from gen AI pilots to scaling data solutions. The first focuses on how organizations can strengthen the quality and readiness of their data for gen AI use cases. The second looks at how organizations can use gen AI to build better data products with their modernized data platforms. The third explores key data-management considerations that enable reuse and accelerate the development of data solutions. It starts at the source: Improve your data While data quality has long been an important concern for data and AI leaders, the risks and costs of feeding poor data into gen AI models cannot be overstated, ranging from poor outcomes, costly fixes, and cyber breaches to a loss of user trust in the outputs. The 2024 McKinsey survey cited above, in fact, found that 63 percent of respondents—seven percentage points more than in the 2023 survey—said that output inaccuracy was the greatest risk they saw in their organizations’ use of gen AI. 2 “ The state of AI in early 2024 ,” May 30, 2024. Traditional methods of ensuring data quality aren’t enough; leaders should consider the following ways of improving and expanding their source data. Obtain better and more-accurate source data from complex data types About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Organizations are struggling to handle the increased complexity of unstructured data sets. For example, banks might want to look at both structured financial information, such as transaction history, as well as financial statements and market analyses to determine the creditworthiness of a corporate client. But processing combinations of structured and unstructured data often increases the chance of errors because, while internal teams and subject-matter experts have the relevant knowledge, they generally struggle to codify that knowledge so that data pipeline processes can be easily replicated. Tools have evolved to handle the relationship between different types and sources of data. For example, knowledge graphs can help capture complex relationships between entities, providing meaningful context for large language models (LLMs) and their downstream data sets. These kinds of capabilities make it easier to accurately map data points from unstructured to structured data. Even when data engineers understand the relationship between data sets, they still need to assign different methods to interpret that data based on attributes, such as the data format (PDF, PowerPoint, Word, or image files, for example). This is a challenge as companies integrate formats into their systems that are becoming increasingly complex. Multimodal models are sophisticated enough now to parse more complex types of documents that feature disparate data formats, such as extracting tabular data from unstructured documents. While these models are becoming easier to use, they can still make mistakes (and, in some cases, are expensive). Accuracy issues require constant review, which is often still manual. Some data engineers, for example, spend a lot of time checking two screens of an integrated development environment to observe the differences between outputs. As concurrent use cases increase, this manual approach quickly hits its limits. Data leaders need to focus resources on implementing automated evaluation methods, mechanisms to manage versioning, and data-relevancy scoring to enhance multimodal model output accuracy and consistency. An investment firm knew it needed to improve its data access and usage to implement a virtual assistant. In order to use product information from structured and unstructured data sources, it had to build data pipelines for parsing and processing unstructured data, identify which version of each document was most recent, and adapt the length of articles for mobile users. The firm’s data engineers used multimodal model capabilities to parse tabular data from documents into structured data and build a medallion architecture (a popular design pattern for organizing data that supports modular pipeline development). Additionally, they introduced versioning and relevancy scores to improve output accuracy. As a result, the company was able to quickly start work on use cases, such as due-diligence activities, with a production-grade gen AI environment within two weeks. Creating value beyond the hype Create data when they aren’t available Some gen AI use cases are difficult to pursue because the required data are difficult to obtain and process, which is often an issue in healthcare, life sciences, or other sectors that have stringent data security regulations. To overcome these challenges, in some cases, a data engineer can manually generate a file to test the efficacy of a use case. But the process can be time-consuming and inefficient. Instead, data and AI leaders are investing in gen AI tools to generate synthetic data as test data or to produce new values based completely on the column descriptions and context of the table, allowing them to either create a new data set or make revisions to an existing one. Some companies have already used synthetic data generators to create statistically similar data sets. Use gen AI to accelerate the building of reusable data products Data products , such as a 360-degree view of individual customers, are the cornerstone of how companies use data to generate value at scale for the business. 3 Veeral Desai, Tim Fountaine, and Kayvaun Rowshankish, “ How to unlock the full value of data? Manage it like a product ,” McKinsey, June 14, 2022. But such data products can be difficult and time-consuming to develop. With better data and new gen AI tools, however, companies are finding they can accelerate development and improve outputs. For example, one hospitality company expedited the creation of customer domain data models by up to 60 percent while increasing productivity in feature engineering by 50 percent. It was able to hit those marks by focusing on automatically generating both end-to-end data transformation pipelines in PySpark and robust documentation of all the complex transformations that occurred. Shift to end-to-end creation of data products Until recently, available technology has limited the creation of data pipelines (such as a medallion architecture) to a laborious step-by-step approach. While using gen AI to perform tasks, such as generating an individual table from natural language, may make data engineers more efficient, engineers still must complete a series of other upstream and downstream steps, such as combining all the tables. Data and AI leaders instead are starting to take an end-to-end approach to building data pipelines by automating all the steps, achieving, in some cases, time savings of 80 to 90 percent and enhanced scalability for specific use cases. Writing the data pipeline code to generate data products traditionally has been one of the most time-consuming tasks for data engineers. We now are seeing the automated creation of data pipelines, written in languages such as SQL or Python, to create entire models that can solve for multiple use cases at once. Rather than looking at a modest scope of work, such as generating an individual table from a natural-language prompt, the capabilities exist to generate dozens of tables as a cohesive target data model capable of providing solutions to multiple use cases. Before an organization can begin generating these types of capabilities, however, it needs to ensure it has trustworthy, easily understandable, and available data. For companies that have been building their data estate for many years, an important element of this process is understanding their legacy code bases and existing data. Many companies struggle, however, because of poor data lineage or cataloging, leading to a limited understanding of how their data are generated. In response, some companies are employing a variety of agents (gen AI applications) across multiple LLMs to analyze legacy code bases and generate natural-language text descriptions. This approach not only improves the organization’s understanding of its code base but also facilitates the creation of data catalog features, streamlining the identification and removal of redundant code segments. The state of AI in early 2024: Gen AI adoption spikes and starts to generate value Enhance consistency with better orchestration and data management Developing gen AI applications requires a level of orchestration and modularization that enables easy reuse of specific capabilities. Traditional continuous integration/continuous delivery (CI/CD) methods are often not up to the task, because they cannot maintain the necessary consistency between gen AI programs due to the introduction of gen AI–specific activities, such as prompt engineering. In response, some data and AI leaders are using agent-based frameworks, a structure that facilitates collaboration and coordination among multiple gen AI agents. These frameworks orchestrate gen AI agents and the complexities involved with scaling their use (and reuse). Agent-based frameworks are equipped with reasoning, code execution, tool usage, and planning abilities as well as enhanced workflow management. They can help address limitations associated with LLMs, such as process-management challenges, cross-verification errors, and end-to-end workflow design constraints. By incorporating these agents into a gen AI architecture, organizations can better manage complex tasks and improve overall performance, reliability, value, and user satisfaction. Some companies are employing agent-based frameworks in consumer-facing chatbots or enterprise knowledge retrieval systems. To better manage their data products, many companies are turning to a range of tools. Some are working with off-the-shelf tools, though these often have issues with complex scenarios, such as automatically generating insights from unstructured data. Organizations that use gen AI–augmented data catalogs can facilitate real-time metadata tagging, including automatically generating metadata from structured and unstructured content and creating smart tags. This has the effect of improving data discovery and assisting in the selection of appropriate structured and unstructured data for gen AI models. Migrate and modernize data products Before beginning the process of using gen AI capabilities, such as code translation, to migrate data products and their underlying pipelines from one platform to another, companies need to first determine the right LLM for the job. While many organizations use LLMs supplied by their cloud service provider, certain LLMs may be trained more proficiently on one set of coding languages than on others. For example, one LLM may be better suited to write PySpark code for pipelines, while another is more efficient at Terraform for developing infrastructure as code. Organizations can use these LLMs to facilitate smoother migration to platforms that use PySpark or SQL, though, in some cases, depending on the coding language or framework, fine-tuning a model may still be necessary. By understanding which LLMs to use for given coding languages—and how to automate code translation across languages—companies can better migrate pipelines from mainframes and legacy-managed services already in the cloud to more-modern cloud resources. Identifying the appropriate LLM, however, may require additional testing time, which data and AI leaders should account for in their project road maps. Scale gen AI with security and coding standards Data and AI leaders face big challenges in managing and governing the rapidly expanding use of unstructured data. The proliferation of gen AI models and applications not only introduces risks but also hampers getting to scale because teams often end up using different—and sometimes conflicting—tools and approaches. By protecting data at every stage of the development process and automating the integration of coding best practices, companies can mitigate risk as well as enforce standards to scale their gen AI solutions. Protect data at each step Unstructured data such as PDFs, video, and audio files hold a wealth of information for gen AI models, but they create significant security issues and require strong data-protection controls. Traditional access controls, however, may not suffice. Unstructured data, for example, must be converted into a format that a gen AI application can analyze to understand the context and to then generate metadata that help determine access rights to the data. To mitigate security risks, some data and AI leaders are designing modularized pipelines capable of automatically securing data. For example, extracting a revenue table with notes that span multiple pages in a PDF will require implementing traditional role-based access control, including hiding related sentences in the text. Because gen AI outputs are still often inconsistent, data and AI leaders should carefully build consistent, secure access controls and guardrails at each checkpoint in the data pipeline, from ingestion to vectorization to retrieval-augmented generation (RAG) to consumption by gen AI models. Integrate coding best practices into gen AI outputs A key feature of scale is ensuring the consistent adherence to approved standards and best practices when engineering data. This can be an issue when using code sourced directly from LLMs, where the quality may not meet expectations, because, for example, the code lacks organizational context or does not fit the standard frameworks an organization uses. To help overcome these issues and improve data quality, some organizations are integrating coding best practices into all their gen AI–generated code. Another approach is to use gen AI to analyze column values, determine appropriate rules for data quality based on existing rules, and then seamlessly integrate them into the pipeline generation process. Companies generally have a common set of data quality rules for data products, often with only slight changes across use cases. Organizations that define what those rules are—with the correct parameters for adjustments to different situations—can develop gen AI solutions that allow them to automatically add the rules to their pipelines. Gen AI tools are available to accelerate the development of data products and data platforms and improve their performance. But to use them effectively, companies will have to address a broad range of technical challenges. Focusing on orchestration capabilities, automating data-development programs, and improving usability will allow data and AI leaders to help their organizations move from gen AI pilots to scaling solutions that drive real value. Asin Tavakoli is a partner in McKinsey’s Düsseldorf office; Carlo Giovine is a partner in the London office; Joe Caserta and Jorge Machado are partners in the New York office, where Kayvaun Rowshankish is a senior partner; Jon Boorstein is a solutions architect in the Denver office; and Nathan Westby is a data strategist in the Chicago office. The authors wish to thank Bryan Petzold, Chett Rubenstein, Danny Siegel, Gaspard Fouilland, Henry Zhang, Jean-Baptiste Dubois, Malhar Aras, Mo Sherif, Neeraj Malhotra, Olivier Fournier, Patrick Wollner, and Ramin Ostad for their contributions to this article. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles The data dividend: Fueling generative AI Moving past gen AI’s honeymoon phase: Seven hard truths for CIOs to get from pilot to scale A generative AI reset: Rewiring to turn potential into value in 2024","Data and AI leaders face challenges scaling generative AI (gen AI) due to data management issues, including quality and integration difficulties. To overcome these, organizations can enhance data quality, utilize gen AI for better data products, and implement end-to-end automation"
Gen AI and beyond: Where else to focus now,"Yes, gen AI can be dazzling. But to deliver value, leaders will have to look beyond center stage.",https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/gen-ai-and-beyond-where-else-to-focus-now,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/gen%20ai%20and%20beyond%20where%20else%20to%20focus%20now/dont%20let%20gen%20ai%20outshine%20other%20business%20imperatives-1596100353-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-07-12T12:00:00Z,"Gen AI and beyond: Where else to focus now Gen AI has rightly seized leaders’ attention. But is it also eclipsing lower-profile digital imperatives? On this episode of The McKinsey Podcast , McKinsey senior partners Rodney Zemmel and Kate Smaje , with global editorial director Lucia Rahilly, talk about ideas leaders risk overlooking with gen AI in the spotlight , and how to ensure your digital initiatives—including gen AI—work in tandem to drive meaningful value. This transcript has been edited for clarity and length. The McKinsey Podcast is cohosted by Roberta Fusaro and Lucia Rahilly. Where to start Lucia Rahilly: Gen AI has been the shiny new object of the business world, but as your new article suggests, it risks blinding leaders to other digital tools also vital to their organization’s success. How do you see leaders balancing that tendency to go after the glitter with the need to maintain focus on other essential business operations and strategies? Rodney Zemmel: Generative AI is a very shiny object indeed, which sounds a bit disparaging because it can and is already delivering real value. But it’s the wrong question to ask, “What’s my gen AI strategy?” You’ve got to start with where value comes from and think about how you get value from transforming a domain of your business with technology. Whether generative AI , old-fashioned AI, process digitization, or anything else, that has to be subsidiary to the question of where value is coming from. Business that’s like your brain Lucia Rahilly: Your report lays out ten “unsung ideas” on digital and AI, and today we’re going to focus on three of those. Let’s start with the idea that every company will become a neural business. What does this mean? Rodney Zemmel: There were a couple of amazing scientific breakthroughs last year in our understanding of the brain. At my old lab in Cambridge, we got our first visualization of the connectome, or how all the different neurons fit together—first in a fruit fly brain, and then from a slice of the human brain from a Google team. What we see is this incredible, intricate architecture where everything connects with everything else. And we think this is the new metaphor for business. The old metaphor for how a business is organized is a tree: hierarchical, with branches that extend from each other. But the trouble with that analogy is that it’s very hard to get connections across the boughs of the tree. To do most interesting and innovative things in business, you’ve got to get those connections working much more effectively than they do in many rigid hierarchical organizations. This isn’t a new idea. It’s a new take on it, and it speaks to the scale of the connections needed. But also, you need to make sure the overall common patterns, governance, and organizing structure is beautifully intricate and networked and enables teams across the organization to work with each other and form and reform without complete chaos. Want to subscribe to The McKinsey Podcast ? Kate Smaje: This is about enabling speed. Could I, as an organization, work at a higher metabolic rate than today? And second, this is about scale. That’s where some of these common patterns come into play, because the greater the reusability, the greater the pattern recognition, the more you’re able to do at scale, as opposed to reinventing the wheel every time. Lucia Rahilly: Teams have to function autonomously as they’re forming and reforming. Could you say a bit about what autonomy means in this context? Rodney Zemmel: One way to take this forward is in what we call a product and platform company. You have a central set of platform services and a distributed network of empowered teams that have autonomy and are aligned against a specific business goal, and they draw services from the central platform. They’re autonomous in that they’re self-contained and working toward a business goal they own. But they’re not autonomous in that they’re working within an overall company framework and set of objectives, there’s a platform team from which they’re expected to draw services, and they follow rules rather than just go create their own. What we’ve seen in this product and platform model is that it’s early days. But if we look at a set of companies that have adopted it, the top half of companies in terms of maturity had 60 percent greater total shareholder returns than the bottom half of companies. Lucia Rahilly: Could you give us an example of a company that has successfully implemented this agile neural network approach? Rodney Zemmel: One of the companies we talked about in our Rewired book , DBS Bank, known as one of the leading banks in digital banking, has really rethought of itself into horizontal cells . As soon as you use a banking example, people say, “Well, that obviously makes sense in a service industry.” But another company that’s in the book, Freeport-McMoRan, has done this in their copper mining operations. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Kate Smaje: One of the ways any company can test this is by asking a simple question: How quickly can you conceive of, build, and launch a new product and service today? Rodney Zemmel: The acid test is a good question, because it’s hard to find a company these days where a senior leader won’t say, “Yeah, of course we’re working at agile.” And often what that means is they have a technology team working in agile . But it won’t always mean that business and technology are working together properly, and frankly, it rarely means that you’ve got the control functions embedded in those agile pods in the right way. Lucia Rahilly: Speaking of control functions, what kind of operating model needs to be in place for this kind of neural business to function successfully? And what kind of oversight is necessary for these autonomous teams to function well, including limiting missteps and keeping productivity up in this model? Rodney Zemmel: Right, and how do you do it at scale? Because again, many companies can do this, but how you do it across dozens to hundreds of teams? That’s the hard part. First, a lot of it is about talent . You need to put the effort into upskilling and reskilling your talent to be able to work in this model. Then it’s about being super thoughtful on how you staff these teams and how you get your senior leadership team comfortable so they’ll set guardrails and objectives. They’ll participate in reviews at the big milestones, but every decision is not running up the chain to them. It requires a fairly evolved governance framework. Let’s take data as an example, really figuring out all the data governance rules within your organization because you can see a clear ROI on the next AI use case. If you’re not putting those data governance models and rules in place up front, then you’re going to make it impossible to work in this kind of distributed and scalable model. Kate Smaje: I ask, “Do I have a set of outcomes that empowered teams are working toward?” This is where it becomes important for management to check in and know how things are going. If you have alignment on the desired team outcomes, then you have transparency into whether we’re there yet. And if not, what’s getting in the way? How do we be better next time? Last, back to this notion of pattern recognition, how do I make sure I’m solving for reusability? How the best pull away Lucia Rahilly: Let’s move to another of these ideas, on digital and AI leaders becoming forever transformers. What are some of the new technologies or trends leaders should be on the lookout for now? Kate Smaje: In some ways, everybody has the technology they love to geek out on, and we’re as guilty of that as the next person. But for me, the magic is less about a single technology or singular trend and more about the combined power of bringing several of these technologies together. It’s only when that really happens—and, by the way, the same was true for generative AI—that you create an opportunity for a breakthrough in creating a new business model, creating a disruption that hadn’t happened before. But for me, the magic is less about a single technology or singular trend and more about the combined power of bringing several of these technologies together. Rodney Zemmel: We have an analysis called Digital Quotient or AI Quotient , where we look at how well companies have adopted different digital or AI approaches. In the past two or three years, we’ve seen that industry is no longer destiny. There’s much greater difference within an industry than there is between industries. The most advanced industrial companies are more digitized than the high-tech median, and the least advanced are less digitized than the public-sector median. What’s behind that is this notion of a forever transformer. You see companies that started on the journey are able to get ahead, keep investing, and, frankly, get further ahead. And you see increasing returns to digital leaders over time as they’re able to pull ahead of others in the industry. Lucia Rahilly: I have kind of a romantic fascination with quantum . I went through a Carlo Rovelli phase. Rodney Zemmel: He’s so good. Lucia Rahilly: He’s so good. I liked to think about quantum entanglement as a romantic construct. But our research shows that some industries stand to gain considerably by applying quantum computing very practically to specific use cases, whereas I tend to think of it as more abstract. What does quantum in practice look like? Rodney Zemmel: I’m as excited as you are about quantum. In fact, all the conversations we’re having about AI or gen AI today could be about quantum five to ten years from now. It’s important to emphasize that it is still a science experiment. While the pace of change is amazing, the number of functional qubits, which are the units you need to perform quantum work, that you can get in a quantum computer today is still really small. So it’s still in the research or maybe early development phase. But if it works, the impact could be absolutely spectacular. Industries being talked about are financial services, pharmaceuticals, chemical and agriculture, automotive, and a range of others. And, essentially, the many hard math problems that would take years to centuries to solve using traditional algorithms can go much, much faster with a quantum algorithm approach. You can solve them in an exponential rather than a linear rate. So it could affect everything from portfolio construction and performance analysis in financial services to how to design effective catalysis in agriculture—which doesn’t sound that exciting, but if you could find a more efficient way to produce ammonia-based fertilizers, the economic impact on the world would be enormous. I have a feeling that what goes first will be things that resemble real quantum physics problems. But then over time, anything that’s a complex math problem—whether how to redesign a delivery route for a logistics company or how to best build up layers of carbon fiber to develop a strong material for aerospace—will be massively tractable by quantum computing when it works. Making gen AI your superpower Lucia Rahilly: As gen AI gets better and better and employees become increasingly dependent on it for at least some parts of their portfolio, how can organizations identify which roles or tasks will benefit most from gen AI to create a more productive workforce? Kate Smaje: Our research undoubtedly says there is opportunity for major productivity gains, but they’re pretty hard to realize today. Some of that is because you must have, for any technology breakthrough, a commensurate or an equal and opposite breakthrough on the human side. How am I going to change the workflow so that I can materially free up time? What am I going to do in terms of learnings, upskilling, reskilling, new career paths that fundamentally reset what humans will do when AI superpowers sit alongside them? Rodney Zemmel: The gen AI superpower is not how to find a way to save 20 minutes in your day, but how to find a way to make using gen AI your first instinct. We’ve seen it so far in software development. If you just give the tools to a software developer and say, “Here’s the latest,” the developers will each go find the most boring part of what they do and use it to accelerate that. And you’ll get these 5 or 10 percent productivity benefits. If instead you say, let’s look at the full team and look at a week or month in the life of the software development life cycle and not just, how does developer A or B do their job on an average Tuesday? And you think about how the whole team changes their work, you train people, and you have real measurement for where it’s working better than a human or not—that’s how you build superpowers. Lucia Rahilly: How are you seeing leaders tackle that learning and training? Kate Smaje: What I see a lot of is, we’re going to train our organization on tech, on AI. We’re going to teach them what it is, we’re going to explain it, bust the myths, and so on. And that’s important, don’t get me wrong. But it’s one of those necessary but not sufficient things. The things missing are, for example, to really use well what is fundamentally an assistive technology. You have to know how to use it to get the best out of it. We certainly see investments in things like teaching how to do great prompts. So rather than teaching you about it, teaching you how to use it becomes really important. The second is, to Rodney’s point, in the day-to-day workflow. It’s about making sure you have incredible critical thinking skills to be able to parse out some of the complex risk and responsible AI usage issues, to think about how hallucination is going to run through this, and what you need to do in the pre- and post-processing of the modeling. You will probably need to have amazing EQ [emotional quotient] and relational skills, because what the human is going to do—that the tech won’t—may be more on that side. Maybe even, frankly, people will need higher cognitive capacity or curiosity to learn, to keep evolving and iterating. For me, there’s not yet enough focus on what let’s call the nontech skills the human is really going to need in a hybrid intelligence setting. Lucia Rahilly: Do you see tech professionals as equally in need of upskilling as employees outside the tech sector? Kate Smaje: It’s both. None of us is immune to the need to keep learning, not least because, in some ways, the pace of change today will never be this slow again. It’s about your ability, even as a tech professional, to understand and be open to the new technologies that will come in. How do I make sure I’m ready to learn and embrace those? How do I keep getting better at using that technology in my job? As a technologist, how am I going to help get value out of models, not just build great models? Rodney Zemmel: For the average company, a senior team is going to learn better from seeing what a leading nontech company does than a tech company. What we’ve seen work very successfully is when management teams have done what we call go-and-see visits with other companies, often in industries quite different from their own, where average companies have really applied this and really learned how to transform their businesses with digital and AI. For the average company, a senior team is going to learn better from seeing what a leading nontech company does than a tech company. Once you see a “normal” company do it, that brings the power of the technology to life much more than seeing what digital natives can do—which for the average company, is exciting but feels a bit more like a trip to the zoo than something directly relevant to their daily lives. What lies ahead Lucia Rahilly: Do you see a risk of employees becoming overly reliant on AI? And do organizations need to take steps to help ensure employees retain their human judgment? Kate Smaje: In some ways, we can see “reliance on AI” as a pejorative term or as a real positive, in that employees are using AI to do their jobs better, faster, cheaper, at lower risk. The reality is that human judgment will become more important than ever for making sure these models are built responsibly, and more important in making sure the value really comes out of them. To make sure humans are using AI responsibly, there are at least two things to consider. One is constantly questioning the technology. The second is constantly looking for the “and.” Where does one plus one equal five here, regarding bringing humans plus technology to get a breakthrough that wasn’t otherwise possible? As long as we’re still doing those two things, human judgment will become more important, not less. Rodney Zemmel: That said, it’s clear that this is going to be better than humans in many cases. I’ll give you a maybe silly example. In tennis, there’s electronic line judging. Wimbledon and the US Open have gone different routes. In Wimbledon they have electronic line judging, but they keep the humans wearing green blazers standing on the sidelines. In the US Open, they’ve gone all electronic. And most people would say the US Open version is working just as well or better. There’s less interruption of play. There’s less back and forth. There are no more obviously wrong calls. Interestingly, I’m told that the US Open employs as many people as Wimbledon does, but in different jobs. It’s people in the tech control room, and people that are deploying, setting up, and monitoring the technology. Lucia Rahilly: We recently posted an interview with Reid Hoffman for the At the Edge podcast. He suggested that AI has the potential to develop EQ and soft skills. Any thoughts on how that might affect the AI–human calculus in the workplace? Kate Smaje: We see this already. Rodney and I often joke about this very small study that was done in the United Kingdom with GPs [general practitioners], where they tested a human versus a bot to see if the patient could tell the difference. The patients pretty much could, in most cases. Then the patients were asked which they preferred. Staggeringly, most folks preferred the bot. They said, “I felt that it understood my needs better. It was more empathetic. It solved my problem faster.” We shouldn’t underestimate that the technology is already pretty darn good at the qualities we often associate with humans. Lucia Rahilly: Anything else to call out that might not be top of mind for leaders but should be? Rodney Zemmel: There’s a question about what the future of the workforce is going to look like. There was a very interesting interview with Garry Kasparov some time ago. He famously was beaten by the IBM chess computer back in the ’90s. He said, “Look, I was the first knowledge worker to lose my job to a computer. And now it’s coming for all of you.” That’s a bit exaggerated, but that view is clearly out there. There are companies that say, “OK, we no longer need junior people, analysts, people doing routine tasks. We can get away with a workforce or evolve to a workforce that has a very different pyramid shape.” There are others who say, “Maybe. But this is about the superpowers idea. It means we can make the analysts or the junior people in our company as productive in the future as our most senior people are today, because this is going to take away a lot of the routinized drudgery of what they do and really give them these incredible abilities to create more value.” There’s a view that says the value of the data scientist goes down and the value of the data engineer goes up in the future. So from a workforce planning standpoint, this is profound. Frankly, the answer doesn’t exist yet. People are going to need some real thinking time and flexibility to evolve what this means for workforce planning. Kate Smaje: I couldn’t agree more. Your point on flex has another flavor to it as well, in that so much of what we’re really talking about here is constant learning, constant experimentation. And that’s very easy to fund, resource, and allocate time to in good times. It’s much harder to do when economies or markets turn and companies have to batten down the hatches. There is a real challenge for leaders to figure out: how do I have a more through-cycle mindset for investing and learning for the future when the level of certainty, and therefore the level of ROI prediction, is more challenged? Can I have a plan here that’s flexible enough for sunny times as well as rainy ones? Lucia Rahilly is the global editorial director of McKinsey Global Publishing and is based in the New York office. Explore a career with us Related Articles Ten unsung digital and AI ideas shaping business The economic potential of generative AI: The next productivity frontier Steady progress in approaching the quantum advantage","In a McKinsey Podcast episode, leaders discuss the importance of balancing focus on generative AI with other digital initiatives, emphasizing the need for a neural business model that fosters connections and autonomy among teams. They also highlight the necessity of upskilling,"
McKinsey technology trends outlook 2024,"Which technology trends matter most for companies in 2024? New analysis by the McKinsey Technology Council highlights the adoption,...",https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20top%20trends%20in%20tech%202024/technology-trends-outlook-2024-1463331528-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-07-16T12:00:00Z,"McKinsey technology trends outlook 2024 Despite challenging overall market conditions in 2023, continuing investments in frontier technologies promise substantial future growth in enterprise adoption. Generative AI (gen AI) has been a standout trend since 2022, with the extraordinary uptick in interest and investment in this technology unlocking innovative possibilities across interconnected trends such as robotics and immersive reality. While the macroeconomic environment with elevated interest rates has affected equity capital investment and hiring, underlying indicators—including optimism, innovation, and longer-term talent needs—reflect a positive long-term trajectory in the 15 technology trends we analyzed. What’s new in this year’s analysis This year, we reflected the shifts in the technology landscape with two changes on the list of trends: digital trust and cybersecurity (integrating what we had previously described as Web3 and trust architectures) and the future of robotics. Robotics technologies’ synergy with AI is paving the way for groundbreaking innovations and operational shifts across the economic and workforce landscapes. We also deployed a survey to measure adoption levels across trends. These are among the findings in the latest McKinsey Technology Trends Outlook, in which the McKinsey Technology Council identified the most significant technology trends unfolding today. This research is intended to help executives plan ahead by developing an understanding of potential use cases, sources of value, adoption drivers, and the critical skills needed to bring these opportunities to fruition. Our analysis examines quantitative measures of interest, innovation, investment, and talent to gauge the momentum of each trend. Recognizing the long-term nature and interdependence of these trends, we also delve into the underlying technologies, uncertainties, and questions surrounding each trend. (For more about new developments in our research, please see the sidebar “What’s new in this year’s analysis”; for more about the research itself, please see the sidebar “Research methodology.”) New and notable The two trends that stood out in 2023 were gen AI and electrification and renewables. Gen AI has seen a spike of almost 700 percent in Google searches from 2022 to 2023, along with a notable jump in job postings and investments. The pace of technology innovation has been remarkable. Over the course of 2023 and 2024, the size of the prompts that large language models (LLMs) can process, known as “context windows,” spiked from 100,000 to two million tokens. This is roughly the difference between adding one research paper to a model prompt and adding about 20 novels to it. And the modalities that gen AI can process have continued to increase, from text summarization and image generation to advanced capabilities in video, images, audio, and text. This has catalyzed a surge in investments and innovation aimed at advancing more powerful and efficient computing systems. The large foundation models that power generative AI, such as LLMs, are being integrated into various enterprise software tools and are also being employed for diverse purposes such as powering customer-facing chatbots, generating ad campaigns, accelerating drug discovery, and more. We expect this expansion to continue, pushing the boundaries of AI capabilities. Senior leaders’ awareness of gen AI innovation has increased interest, investment, and innovation in AI technologies, such as robotics, which is a new addition to our trends analysis this year. Advancements in AI are ushering in a new era of more capable robots, spurring greater innovation and a wider range of deployments. Research methodology To assess the development of each technology trend, our team collected data on five tangible measures of activity: search engine queries, news publications, patents, research publications, and investment. For each measure, we used a defined set of data sources to find occurrences of keywords associated with each of the 15 trends, screened those occurrences for valid mentions of activity, and indexed the resulting numbers of mentions on a 0–1 scoring scale that is relative to the trends studied. The innovation score combines the patents and research scores; the interest score combines the news and search scores. (While we recognize that an interest score can be inflated by deliberate efforts to stimulate news and search activity, we believe that each score fairly reflects the extent of discussion and debate about a given trend.) Investment measures the flows of funding from the capital markets into companies linked with the trend. Data sources for the scores include the following: In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends: Finally, we used survey data to calculate the enterprise-wide adoption scores for each trend: Electrification and renewables was the other trend that bucked the economic headwinds, posting the highest investment and interest scores among all the trends we evaluated. Job postings for this sector also showed a modest increase. Although many trends faced declines in investment and hiring in 2023, the long-term outlook remains positive. This optimism is supported by the continued longer-term growth in job postings for the analyzed trends (up 8 percent from 2021 to 2023) and enterprises’ continued innovation and heightened interest in harnessing these technologies, particularly for future growth. In 2023, technology equity investments fell by 30 to 40 percent to approximately $570 billion due to rising financing costs and a cautious near-term growth outlook, prompting investors to favor technologies with strong revenue and margin potential. This approach aligns with the strategic perspective leading companies are adopting, in which they recognize that fully adopting and scaling cutting-edge technologies is a long-term endeavor. This recognition is evident when companies diversify their investments across a portfolio of several technologies, selectively intensifying their focus on areas most likely to push technological boundaries forward. While many technologies have maintained cautious investment profiles over the past year, gen AI saw a sevenfold increase in investments, driven by substantial advancements in text, image, and video generation. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Despite an overall downturn in private equity investment, the pace of innovation has not slowed. Innovation has accelerated in the three trends that are part of the “AI revolution” group: gen AI, applied AI, and industrializing machine learning. Gen AI creates new content from unstructured data (such as text and images), applied AI leverages machine learning models for analytical and predictive tasks, and industrializing machine learning accelerates and derisks the development of machine learning solutions. Applied AI and industrializing machine learning, boosted by the widening interest in gen AI, have seen the most significant uptick in innovation, reflected in the surge in publications and patents from 2022 to 2023. Meanwhile, electrification and renewable-energy technologies continue to capture high interest, reflected in news mentions and web searches. Their popularity is fueled by a surge in global renewable capacity, their crucial roles in global decarbonization efforts, and heightened energy security needs amid geopolitical tensions and energy crises. The talent environment largely echoed the investment picture in tech trends in 2023. The technology sector faced significant layoffs, particularly among large technology companies, with job postings related to the tech trends we studied declining by 26 percent—a steeper drop than the 17 percent decrease in global job postings overall. The greater decline in demand for tech-trends-related talent may have been fueled by technology companies’ cost reduction efforts amid decreasing revenue growth projections. Despite this reduction, the trends with robust investment and innovation, such as gen AI, not only maintained but also increased their job postings, reflecting a strong demand for new and advanced skills. Electrification and renewables was the other trend that saw positive job growth, partially due to public sector support for infrastructure spending. Even with the short-term vicissitudes in talent demand, our analysis of 4.3 million job postings across our 15 tech trends underscored a wide skills gap. Compared with the global average, fewer than half the number of potential candidates have the high-demand tech skills specified in job postings. Despite the year-on-year decreases for job postings in many trends from 2022 to 2023, the number of tech-related job postings in 2023 still represented an 8 percent increase from 2021, suggesting the potential for longer-term growth (Exhibit 1). Enterprise technology adoption momentum The trajectory of enterprise technology adoption is often described as an S-curve that traces the following pattern: technical innovation and exploration, experimenting with the technology, initial pilots in the business, scaling the impact throughout the business, and eventual fully scaled adoption (Exhibit 2). This pattern is evident in this year’s survey analysis of enterprise adoption conducted across our 15 technologies. Adoption levels vary across different industries and company sizes, as does the perceived progress toward adoption. Image description: A graph depicts the adoption curve of technology trends, scored from 1 to 5, where 1 represents frontier innovation, located at the bottom left corner of the curve; 2 is experimenting, located slightly above frontier innovation; 3 is piloting, which follows the upward trajectory of the curve; 4 is scaling, marked by a vertical ascent as adoption increases; and 5 is fully scaled, positioned at the top of the curve, indicating near-complete adoption. In 2023, the trends are positioned along the adoption curve as follows: future of space technologies and quantum technologies are at the frontier innovation stage; climate technologies beyond electrification and renewables, future of bioengineering, future of mobility, future of robotics, and immersive-reality technologies are at the experimenting stage; digital trust and cybersecurity, electrification and renewables, industrializing machine learning, and next-gen software development are at the piloting stage; and advanced connectivity, applied AI, cloud and edge computing, and generative AI are at the scaling stage. Footnote: Trend is more relevant to certain industries, resulting in lower overall adoption across industries compared with adoption within relevant industries. Source: McKinsey technology adoption survey data End of image description. We see that the technologies in the S-curve’s early stages of innovation and experimenting are either on the leading edge of progress, such as quantum technologies and robotics, or are more relevant to a specific set of industries, such as bioengineering and space. Factors that could affect the adoption of these technologies include high costs, specialized applications, and balancing the breadth of technology investments against focusing on a select few that may offer substantial first-mover advantages. As technologies gain traction and move beyond experimenting, adoption rates start accelerating, and companies invest more in piloting and scaling. We see this shift in a number of trends, such as next-generation software development and electrification. Gen AI’s rapid advancement leads among trends analyzed, about a quarter of respondents self-reporting that they are scaling its use. More mature technologies, like cloud and edge computing and advanced connectivity, continued their rapid pace of adoption, serving as enablers for the adoption of other emerging technologies as well (Exhibit 3). Image description: A segmented bar graph shows the adoption levels of tech trends in 2023 as a percentage of respondents. The trends are divided into 5 segments, comprising 100%: fully scaled, scaling, piloting, experimenting, and not investing. The trends are arranged based on the combined percentage sum of fully scaled and scaling shares. Listed from highest to lowest, these combined percentages are as follows: Source: McKinsey technology adoption survey data End of image description. The process of scaling technology adoption also requires a conducive external ecosystem where user trust and readiness, business model economics, regulatory environments, and talent availability play crucial roles. Since these ecosystem factors vary by geography and industry, we see different adoption scenarios playing out. For instance, while the leading banks in Latin America are on par with their North American counterparts in deploying gen AI use cases, the adoption of robotics in manufacturing sectors varies significantly due to differing labor costs affecting the business case for automation. As executives navigate these complexities, they should align their long-term technology adoption strategies with both their internal capacities and the external ecosystem conditions to ensure the successful integration of new technologies into their business models. Executives should monitor ecosystem conditions that can affect their prioritized use cases to make decisions about the appropriate investment levels while navigating uncertainties and budgetary constraints on the way to full adoption (see the “Adoption developments across the globe” sections within each trend or particular use cases therein that executives should monitor).  Across the board, leaders who take a long-term view—building up their talent, testing and learning where impact can be found, and reimagining the businesses for the future—can potentially break out ahead of the pack. Lareina Yee is a senior partner in McKinsey’s Bay Area office, where Michael Chui is a McKinsey Global Institute partner, Roger Roberts is a partner, and Mena Issler is an associate partner. The authors wish to thank the following McKinsey colleagues for their contributions to this research: Aakanksha Srinivasan, Ahsan Saeed, Alex Arutyunyants, Alex Singla, Alex Zhang, Alizee Acket-Goemaere, An Yan, Anass Bensrhir, Andrea Del Miglio, Andreas Breiter, Ani Kelkar, Anna Massey, Anna Orthofer, Arjit Mehta, Arjita Bhan, Asaf Somekh, Begum Ortaoglu, Benjamin Braverman, Bharat Bahl, Bharath Aiyer, Bhargs Srivathsan, Brian Constantine, Brooke Stokes, Bryan Richardson, Carlo Giovine, Celine Crenshaw, Daniel Herde, Daniel Wallance, David Harvey, Delphine Zurkiya, Diego Hernandez Diaz, Douglas Merrill, Elisa Becker-Foss, Emma Parry, Eric Hazan, Erika Stanzl, Everett Santana, Giacomo Gatto, Grace W Chen, Hamza Khan, Harshit Jain, Helen Wu, Henning Soller, Ian de Bode, Jackson Pentz, Jeffrey Caso, Jesse Klempner, Jim Boehm, Joshua Katz, Julia Perry, Julian Sevillano, Justin Greis, Kersten Heineke, Kitti Lakner, Kristen Jennings, Liz Grennan, Luke Thomas, Maria Pogosyan, Mark Patel, Martin Harrysson, Martin Wrulich, Martina Gschwendtner, Massimo Mazza, Matej Macak, Matt Higginson, Matt Linderman, Matteo Cutrera, Mellen Masea, Michiel Nivard, Mike Westover, Musa Bilal, Nicolas Bellemans, Noah Furlonge-Walker, Obi Ezekoye, Paolo Spranzi, Pepe Cafferata, Robin Riedel, Ryan Brukardt, Samuel Musmanno, Santiago Comella-Dorda, Sebastian Mayer, Shakeel Kalidas, Sharmila Bhide, Stephen Xu, Tanmay Bhatnagar, Thomas Hundertmark, Tinan Goli, Tom Brennan, Tom Levin-Reid, Tony Hansen, Vinayak HV, Yaron Haviv, Yvonne Ferrier, and Zina Cole. They also wish to thank the external members of the McKinsey Technology Council for their insights and perspectives, including Ajay Agrawal, Azeem Azhar, Ben Lorica, Benedict Evans, John Martinis, and Jordan Jacobs. Special thanks to McKinsey Global Publishing colleagues Barr Seitz, Diane Rice, Kanika Punwani, Katie Shearer, LaShon Malone, Mary Gayen, Nayomi Chibana, Richard Johnson, Stephen Landau, and Victor Cuevas for making this interactive come alive. Explore a career with us Related Articles Rewired and running ahead: Digital and AI leaders are leaving the rest behind False friends or good ends? The CIO’s four-point guide to navigating technology trends","The McKinsey Technology Trends Outlook 2024 highlights significant growth in enterprise adoption of frontier technologies, particularly generative AI and electrification. Despite a challenging economic landscape, indicators show optimism and innovation. The report emphasizes the need for executives to understand technology"
The key to accelerating AI development? Pragmatism plus imagination,Leaders are treating generative AI as less of a curiosity and more an integral part of business. McKinsey research sheds light...,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-key-to-accelerating-ai-development-pragmatism-plus-imagination,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20key%20to%20accelerating%20ai%20development%20pragmatism%20plus/practical%20imagination%20is%20what%20the%20development%20of%20ai%20needs%20now-1453825854-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center,2024-08-08T12:00:00Z,"The key to accelerating AI development? Pragmatism plus imagination While AI continues to influence the way we work in exciting new ways, it is crucial for organizations to apply guardrails to keep it safe. On this episode of The McKinsey Podcast , McKinsey senior partners Alexander Sukharevsky and Lareina Yee dig into new research on AI adoption , with editorial director Roberta Fusaro. In our second segment, how do you muster the courage to talk about something uncomfortable at work? Senior partner Sherina Ebrahim has two tips. This transcript has been edited for clarity and length. The McKinsey Podcast is cohosted by Roberta Fusaro and Lucia Rahilly. AI’s time to shine Roberta Fusaro: We’re here to discuss the latest McKinsey report on the state of AI , a technology evolving at an exponential rate. When it comes to gen AI, which is just one type of AI, our latest results show that 65 percent of our respondents reported their organizations regularly use it. This is double the percentage from our previous survey, which we conducted less than 12 months ago. Why is this new number important? Lareina Yee: This number represents optimism. Even though we have a long way to go, the number shows that people are moving from curiosity to integrating it into their businesses. What’s also important to note is that the report is not just looking at generative AI. It’s looking at AI overall. This has been a trend 40 years in the making. One of the things we’re seeing is that all of this excitement about generative AI is providing oxygen and daylight to the broader set of capabilities that can really help companies advance. Alexander Sukharevsky: Yes, generative AI allows us to democratize about a 40-year AI journey because it is so in our faces that we can really see and feel what it is. We’re able to interact with it. Our clients’ kids are interacting with this technology, and it’s getting discussed over dinners. So something that used to be a niche market is suddenly part of the mainstream. On the other hand, when 75 percent of respondents say that generative AI is used in their organization, the next question should be, what exactly are they using it for? Are they using it for experimentation, familiarizing themselves with the technology, or are they actually trying to unlock true business value? Partnering for AI success Roberta Fusaro: Staying with generative AI , Alexander, about half the respondents in our research say that they are using readily available gen AI models rather than building their own. What are the pros and cons of doing that? Alexander Sukharevsky: One important fact to bear in mind if you step back is that only 11 percent of AI models end up in production, meaning they become day-to-day true business tools to unlock value. If we consider some of the cost and risk of generative AI, this number is close to a single digit when we’re speaking about the traditional enterprise and not just tech companies. Therefore, it’s important to recognize that the model itself makes up only 15 percent of the success. Now we are moving into paradigm of not just “build versus buy” but “build, partner, and buy.” There are certain open-source models with amazing community support that organizations can customize to their needs. There are some proprietary models with very high investment behind them that organizations cannot develop themselves. And there are some models that organizations will develop in partnership with third parties. Want to subscribe to The McKinsey Podcast ? At the end of the day, the enterprise of the future will have a spine brain of dozens of foundational models. Some of them will be proprietary that you buy. Some of them will be those that you develop on your own. And some of them will be open source. So the answer to this question [to buy or build] depends on the client. Lareina Yee: This is an important topic because it is a classic question to wonder about “buy versus build” in technology. But Alexander and I have been working on this in the deployment, and I think we’re in a different paradigm. Being part of a partnership is a really important point that Alexander is raising. It is hard to build all of this on your own. It is also not feasible to buy all of this on your own. What you’re finding is that you have to partner across the stack. That’s kind of a traditional tech term. What that means is you’re going to partner with large language model providers. There are lots of choices. So the point of all this is to drive and unlock some business value that you weren’t able to access before. We’re seeing a lot of companies build a constellation of partnerships in order to deliver the promise of gen AI solutions. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Alexander Sukharevsky: But to power the models, you also need the compute power. You will need certain partners that will allow you to get this compute power. And even if you are the most powerful and well-resourced organization in the world, you cannot make it yourself. Lareina Yee: The number-one question to ask yourself is, “What is the business use case that I’m trying to achieve?” And based off that, “What are the sets of providers that are going to help me most?” That might be a combination of a very large language model provider that’s very enterprise focused. It could be someone who has stronger strengths in video but is doing something around text. And so, even though this is a fast space, I think it always comes back to, “What is the business objective? What’s the people objective?” And then, just being far more open in your mindset of how you bring in different technology providers and different combinations of partners to achieve that quickly. The future is still human Roberta Fusaro: Talent is a huge question and issue for everyone. I’m curious about what the research showed, or if there are different talent imperatives for executives who are trying to get ahead on gen AI. Lareina Yee: Talent is always top of mind. You have to get really practical and match the talent to, for example, a gen AI, AI, or machine learning solution. Those have different use cases. But in all cases, there are sets of capabilities that are going to be really important for your team. And the number-one thing we see in the report, and we see in our own experiences with clients, is data capabilities. So how you think about data and the type of talent you have is important. That’s just one example of the type of talent you need to implement these solutions. When we’re asked, “What’s going on with talent,” the question is typically more about jobs gained/jobs lost. And that’s more of an economic question. And for that, we know these technologies do change the fabric of jobs. But one of the optimistic things we see is they also create new jobs. So what we see in terms of talent is there are many different aspects of it. There’s the talent and capabilities you’re going to need as a company to develop and scale these solutions. There’s also an overall talent question in terms of how they change the fabric of jobs. Alexander Sukharevsky: One of Lareina’s favorite quotes is, “On every dollar of technology we need to invest three to five in human beings,” because human beings are very expensive and difficult to change. So the real questions are: “Beyond having an amazing technology department, who’s able to help you to operate and build the tools? How do you convince the rest of the organization to really use these tools, to embrace them, to manage risk vis-à-vis any other third party?” These are the difficult questions where you take colleagues who are coming completely outside of technology to learn technology and to trust technology. That’s quite a journey, be it around change management or be it around capabilities. Lareina Yee: We spend so much time on the technology. But in fact, that’s the easy part. The harder part is the human change. And we also sometimes lose the plot here. The purpose is not generative AI as a technology. The purpose is generative AI as a tool to help humanity. People are at the center of this. And that change is hard.  There’s that level of micro change. The purpose is not generative AI as a technology. The purpose is generative AI as a tool to help humanity. People are at the center of this. And that change is hard. There’s also the macro change, “Do I trust how I interact with a machine differently? How do I feel about potentially leaving actions to a machine?” We’re starting to see the rise of agentic capabilities, which is where these systems can take an action. There are a whole host of questions, and us getting more comfortable with that is a journey, and changing the fundamental business processes that we use—that’s the hard stuff. Use cases and applications Roberta Fusaro: I’m curious if in the new research we’re seeing different sorts of applications of generative AI. Are there parts of the organization where we’re seeing it more or less? Lareina Yee: Looking at the report, the most common domains we see are marketing and sales. We also see enormous amounts of work in product development and software engineering. These arenas are expected because these are where the types of knowledge work are most applicable to the capabilities of the technology today, especially when the vast majority of what we’re looking at is more the summarization and concision of text. We also see a difference by industry. It’s not surprising that we see the technology sector, the energy sector, and financial services sector being the sectors that are probably the furthest along in experimenting and beginning to deploy these capabilities at scale. Alexander Sukharevsky: The way to look at this is that generative AI, essentially, is the most convenient human interface to apply other AI techniques. And therefore, it’s all about interface; be it interface with a database, be it interface with other algorithms, be it even interface between different generative AI applications. I think if you fast-forward, to Lareina’s point, you will see more and more autonomous virtual agents communicating with each other to solve different tasks under strict human supervision to properly manage risk as well as to ensure that the quality of deliverables is going to be up to the standards that we’re looking for. Therefore, while currently we’re seeing mostly interaction that is human versus machine, as we develop, we’re going to see more and more machine-to-machine interactions to solve different tasks. Now we’re not talking about superintelligence or AGI [artificial general intelligence]; we are years away from that moment. At the same time, we’ll see very sophisticated, very niche assistants that will help us to do our job better, faster, and more precisely. Limiting the risks of AI Roberta Fusaro: There’s lots of opportunity, clearly, given our conversation so far. But according to our report, two of the top risks most often cited by organizations when it comes to their use of gen AI are inaccuracy and IP [intellectual property] infringement. Have organizations started to mitigate some of these risks? And if so, how? Lareina Yee: So when we look at the risks, there are a lot of risks. And one of the things both Alexander and I remind our clients about is that these are the early innings of the technology. Inaccuracy is one of the risks that people are most concerned about, but there’s also intellectual property infringement, cybersecurity, individual privacy, regulatory compliance, explainability, fairness, and amplification of bias. For those that are developing these large language models, they are working really quickly on many of these risks. Explainability is another one. There’s also the reduction of hallucinations, which is something that you’ve seen has gotten better over the course of the year. It’s not down to zero, but there’s been a lot of work on the provider side to make sure that it’s better. And that’s going to improve the inaccuracy issue. On the other side of this is companies’ implementation. How they develop, train, and test these systems is incredibly important before they let them out. Alexander Sukharevsky: The most important part to really understand is, “What are the risks?” Because if you look at our report, the majority of respondents believe there are risks, yet they cannot articulate what these risks are. There are ways of solving these risks . Number one is clearly having a human in the loop. And that’s why I don’t like to speak about artificial intelligence. I rather prefer “hybrid intelligence,” where we bring the best of humans and machines working together to overcome the challenges and the risks and unlock the opportunities. The most important part to really understand is, ‘What are the risks?’ Because if you look at our report, the majority of respondents believe there are risks, yet they cannot articulate what these risks are. On the other hand, should we think that technology can’t help us solve some of these issues? For example, as to IP or traceability, you could apply technology to track the IP, to protect IP. At the same time, while we believe that we all focus on very short-term risks, I do believe that we, as humanity, should step back and think, “What’s the bigger picture? What does this thing do for us, for future generations? Where should or shouldn’t we apply it—be it from a humanitarian point of view, a social point of view, or an environmental point of view? What type of future are we shaping by applying AI as a technology?” And those are significantly bigger questions that we should spend more time with, within the boardrooms as well as the machine rooms, to ensure that we understand exactly where we are heading. Lareina Yee: I think there are some incredibly long-term questions, Alexander, and some of them are very philosophical in terms of our relationship with machines. I also think one of them is the human capacity for adaptability and creativity. And let me take a simple example, something that any parent, any student, any teacher might relate to, which is the very practical concern of plagiarism. This has come up a lot—that concern that students might use ChatGPT or Claude to plagiarize. That’s a real concern and not a risk of the system. That’s actually in the usage. There is an incredibly practical hack that some teachers are using, which is that the exams are written in the classroom. We have this old technology called handwriting and pencils and paper that we can use to show that we have mastered the information. And it’s a very simple example, but what it shows is that there are some incredibly important ethical, very large questions that introducing these capabilities into our day-to-day lives brings. Responsible AI governance Roberta Fusaro: Lareina, you’ve written a bit in the report about AI governance, and that seems related here to the risks and making sure that we don’t go too far. How can companies begin to put some teeth into their AI governance? Lareina Yee: As Alexander and I talk to companies, we start by saying, “Responsible AI starts day one.” So in a traditional world and with previous generations, the way that we may have thought of this is you develop a solution, and then you make sure to catch the risks and have a compliance function. We absolutely need all that strength in our compliance, but we also have to move upstream and bring responsible AI on day one. So what does that mean? It means at a governance level, you’ve got someone with responsible AI capability and expertise that’s at the table making the decisions. That might be at your C-suite level, having someone help have that discussion. It also means that, as you’re developing these solutions, you are testing and integrating how you develop these solutions to ward against things like bias and inaccuracy. So how we think about responsible AI isn’t a moment. It’s embedded in the way in which we develop our business plans, in the way in which we build, configure, and test the solutions, and the way in which we implement it and continue to get feedback, and the way we have strong compliance on the back end if there was a mistake made. Steps for realizing value Roberta Fusaro: What are some first steps for organizations that want to make sure that they’re starting to realize value from their investments in gen AI? Lareina Yee: I think the first step starts with having the success metrics. What are you trying to achieve with this? Deploying generative AI just to say you’ve done it, just to create a conceptual demo or gizmo, that’s not going to lead to business value. At the very onset, it’s important to say, “What are the success metrics? What will I see quarter over quarter?” And then, “How are we doing against that?” So that might be that you expect 20 percent more productivity, and you’re going to use that extra capacity to reach more customers. Alexander Sukharevsky: This step-back moment is extremely important. And once you identify what you’re looking for, you should go back to the recipe that we discussed before in terms of, “What does it take to scale and embed AI within the organization?” Lareina Yee: Alexander, I love your point on scale because sometimes people ask, “What does it mean to scale?” If you only have ten engineers using the solution, that’s not scale. Scale is when you have the vast majority of the engineers using the solution and actually showing results out of it. Arguably the harder and the longer step is the adoption curve of users, and everybody using it, and changing work. That takes real time. So you may have the solution out in 12 weeks, but do you have the adoption and the usage out in 12 weeks? No. You must continue to work on that quarter over quarter, where over the course of a year or 18 months, you’ve gotten the type of business results that you aspire to have. The future is bright Roberta Fusaro: What are your final thoughts about where we’re heading with gen AI? Lareina Yee: The technology and its capabilities are unbelievably exciting. In order to capture it, we need to bring back that sense of pragmatic decision making. What are the cases that are going to make a difference in our business? How do we start to invest fully? How do we invest in these cases? How do we bring them to life? And how do we create that value for our businesses? I think we’re headed into an era of important pragmatism. Alexander Sukharevsky: I agree with Lareina with the caveat that we are still at the pre-awareness phase because the technology is so new. In less than a year, ten million developers got access to these tools. So what we are seeing now is just the beginning, and I believe it’s therefore the era of creativity and imagination. Though we kind of understand what it might do, we haven’t had enough time to figure out how to reinvent our business models and the way we work today. Together with the pragmatism that Lareina was talking about, and the imagination I mentioned, I think in the next 12 to 18 months we will see breakthrough pragmatic solutions, where you apply technology not just to entertain yourself but to unlock true value, be it for business or more important, for humanity. What to do when you’re not being heard Lucia Rahilly: Next up, McKinsey senior partner Sherina Ebrahim shares two tips to help anyone confronting their manager’s irritating behavior. Sherina Ebrahim: The first time I returned from parental leave, I was a manager, and I had come back to work part time. Back then, working part time was a well-established policy, but it was not as widespread as it is today, particularly for the manager role. When I came back, I took off one day a week. The first week, the partner that I worked with had a meeting scheduled for my day off. I did the meeting anyway. The second week, the same thing happened, and I did the meeting. Then the third week, the same thing happened: we had an internal team meeting scheduled, and again I didn’t say anything. But at this point, I thought I needed to say something. So I said to the partner, “You know, I am working part time and tomorrow is my day off, and we’ve now scheduled, for the third time, a meeting on my day off.” And honestly, the partner was mortified. He had just completely forgot. He fully apologized and we changed the meeting, moved on, and the rest of the engagement was perfectly fine in terms of how we made it work. The learning for me from that was two things. The first was assume positive intent. It really was one of those, “I’m not used to it, just moving from one thing to another, just wasn’t thinking about it” type of things. The second is stand up for yourself. When you see something that doesn’t quite work for you, at least bring it up and have a conversation. I think that helped me for the rest of my career because of course, things aren’t always perfect. There are going to be times when you’re working part time, and if you don’t actually have the conversation and engage, you don’t know what your manager is thinking, they don’t know what you are thinking, and it actually doesn’t lead to a positive outcome. Alexander Sukharevsky is a senior partner in McKinsey’s London office, Lareina Yee is a senior partner in the Bay Area office, and Sherina Ebrahim is a senior partner in the New Jersey office. Lucia Rahilly is the global editorial director of McKinsey Global Publishing and is based in the New York office, and Roberta Fusaro is an editorial director in the Boston office. Explore a career with us Related Articles McKinsey technology trends outlook 2024 Gen AI and beyond: Where else to focus now Moving past gen AI’s honeymoon phase: Seven hard truths for CIOs to get from pilot to scale","The McKinsey Podcast discusses AI development, emphasizing the importance of pragmatism and imagination. Recent research shows increased generative AI adoption, with organizations needing to address risks and foster talent. Key points include responsible AI governance, successful implementation, and the"
