2024-08-20 02:06:15 [scrapy.addons] INFO: Enabled addons:
[]
2024-08-20 02:06:15 [scrapy.extensions.telnet] INFO: Telnet Password: 8c4dc986d5594e0f
2024-08-20 02:06:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-08-20 02:06:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'mckinsey_scraper',
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'mckinsey_capabilities_digital_insights_20240820_020259.log',
 'NEWSPIDER_MODULE': 'mckinsey_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['mckinsey_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-08-20 02:06:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'mckinsey_scraper.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-08-20 02:06:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-08-20 02:06:15 [scrapy.middleware] INFO: Enabled item pipelines:
['mckinsey_scraper.pipelines.OpenAIPipeline',
 'mckinsey_scraper.pipelines.GoogleSheetsPipeline',
 'mckinsey_scraper.pipelines.ExportPipeline']
2024-08-20 02:06:15 [scrapy.core.engine] INFO: Spider opened
2024-08-20 02:06:15 [httpx] DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
2024-08-20 02:06:15 [httpx] DEBUG: load_verify_locations cafile='C:\\Users\\R9000P\\web_scraper_Hasmo\\venv\\Lib\\site-packages\\certifi\\cacert.pem'
2024-08-20 02:06:15 [urllib3.util.retry] DEBUG: Converted retries value: 3 -> Retry(total=3, connect=None, read=None, redirect=None, status=None)
2024-08-20 02:06:15 [google.auth.transport.requests] DEBUG: Making request: POST https://oauth2.googleapis.com/token
2024-08-20 02:06:15 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): oauth2.googleapis.com:443
2024-08-20 02:06:15 [urllib3.connectionpool] DEBUG: https://oauth2.googleapis.com:443 "POST /token HTTP/11" 200 None
2024-08-20 02:06:15 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.googleapis.com:443
2024-08-20 02:06:16 [urllib3.connectionpool] DEBUG: https://www.googleapis.com:443 "GET /drive/v3/files?q=mimeType%3D%22application%2Fvnd.google-apps.spreadsheet%22+and+name+%3D+%22Web+Scraping+Data%22&pageSize=1000&supportsAllDrives=True&includeItemsFromAllDrives=True&fields=kind%2CnextPageToken%2Cfiles%28id%2Cname%2CcreatedTime%2CmodifiedTime%29 HTTP/11" 200 None
2024-08-20 02:06:16 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): sheets.googleapis.com:443
2024-08-20 02:06:16 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4?includeGridData=false HTTP/11" 200 None
2024-08-20 02:06:16 [urllib3.connectionpool] DEBUG: https://www.googleapis.com:443 "POST /drive/v3/files/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/permissions?supportsAllDrives=true HTTP/11" 200 None
2024-08-20 02:06:17 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4?includeGridData=false HTTP/11" 200 None
2024-08-20 02:06:17 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "POST /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4:batchUpdate HTTP/11" 200 None
2024-08-20 02:06:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-08-20 02:06:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 8_7_1) Gecko/20130401 Firefox/67.4 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights
2024-08-20 02:06:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights> (referer: None)
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.2; Win64; x64; en-US) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/50.0.1583.338 Safari/536 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/from-legacy-to-cloud-lessons-from-the-trenches
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Linux; Linux x86_64) AppleWebKit/602.38 (KHTML, like Gecko) Chrome/51.0.3859.347 Safari/602 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/embracing-digital-transformation-with-a-digital-factory
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) Gecko/20130401 Firefox/70.5 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-it-takes-to-rewire-a-cpg-company-to-outcompete-in-digital-and-ai
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows NT 10.4; WOW64; en-US) AppleWebKit/533.3 (KHTML, like Gecko) Chrome/53.0.2542.273 Safari/600 for https://www.mckinsey.com/industries/healthcare/our-insights/generative-ai-in-healthcare-adoption-trends-and-whats-next
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows; U; Windows NT 10.0; Win64; x64; en-US) AppleWebKit/600.38 (KHTML, like Gecko) Chrome/53.0.1859.361 Safari/534 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-big-product-and-platform-shift-five-actions-to-get-the-transformation-right
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.1; WOW64) AppleWebKit/602.19 (KHTML, like Gecko) Chrome/51.0.3302.125 Safari/535 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Linux; Linux x86_64) AppleWebKit/602.38 (KHTML, like Gecko) Chrome/51.0.3859.347 Safari/602 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/rewired-to-outcompete
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Linux; Linux x86_64; en-US) AppleWebKit/602.21 (KHTML, like Gecko) Chrome/51.0.1089.205 Safari/600 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/technologys-generational-moment-with-generative-ai-a-cio-and-cto-guide
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 8_6_7; en-US) Gecko/20100101 Firefox/64.2 for https://www.mckinsey.com/capabilities/mckinsey-digital/cloud/cloud-insights/all-insights
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 8_7_1) Gecko/20130401 Firefox/67.4 for https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/enterprise-softwares-growing-reach
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.1; WOW64) AppleWebKit/602.19 (KHTML, like Gecko) Chrome/51.0.3302.125 Safari/535 for https://www.mckinsey.com/featured-insights/the-rise-of-quantum-computing
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_0_8) AppleWebKit/535.21 (KHTML, like Gecko) Chrome/50.0.2746.191 Safari/600 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/leadership-and-digital-transformation
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) Gecko/20130401 Firefox/70.5 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-data-leaders-technical-guide-to-scaling-gen-ai
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 9_9_1; en-US) Gecko/20100101 Firefox/52.9 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/gen-ai-and-beyond-where-else-to-focus-now
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.2; Win64; x64; en-US) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/50.0.1583.338 Safari/536 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech
2024-08-20 02:06:17 [mckinsey_capabilities_digital_insights] DEBUG: User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.1; WOW64) AppleWebKit/602.19 (KHTML, like Gecko) Chrome/51.0.3302.125 Safari/535 for https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-key-to-accelerating-ai-development-pragmatism-plus-imagination
2024-08-20 02:06:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/from-legacy-to-cloud-lessons-from-the-trenches> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:06:18 [httpcore.connection] DEBUG: close.started
2024-08-20 02:06:18 [httpcore.connection] DEBUG: close.complete
2024-08-20 02:06:18 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nFrom legacy to cloud: Lessons learned This interview has been updated to acknowledge external contributors. Modernizing legacy systems and platforms can drive significant business value by enabling faster innovation, greater agility, and lower costs. Organizations take a variety of approaches to modernization, typically based on their specific situation, such as the current state of their investments, their risk appetite, and their time horizon. In this interview, we highlight one such approach, where Lincoln Financial Group transitioned its sizable legacy footprint to cloud within two years. Rob Klaczak, senior vice president and divisional CIO for life, annuities, and distribution, and Satyendra Kumar, vice president and executive sponsor and program lead, discuss Lincoln Financial Group’s transformative journey from decades-old legacy platforms to a dynamic cloud-based architecture, the lessons learned on the way, and their advice for others with similar goals. McKinsey: What prompted you to undertake this transformation? Rob Klaczak: Lincoln Financial’s primary goals for migrating its legacy footprint (for example, assembler code, COBOL-based systems, highly customized system configurations) to the cloud focused on three objectives: reducing overall operating costs, addressing the high expenses associated with certain specialized software licensing, and transitioning to a more modern and flexible environment. The need for modernization and the desire to move away from our fixed-cost legacy setup have been the crucial drivers of this migration. In the context of an insurance company like us, whether managing a million policies or just a few policies, the costs associated with our legacy platforms were largely fixed, posing a financial challenge. We undertook our program to address these challenges, which were complex due to the nature of our business; the large scope of the modernization, which included 120 complex systems; and an accelerated time frame of less than two years to complete the entire program. Satyendra Kumar: Another key objective was to move the decision-making power from IT to the business side by implementing a model that put a price on the consumption of technology services. Now each line of business has the discretion to increase or reduce its spending in alignment with its business goals. McKinsey: How were you able to get senior management’s support and buy-in? Rob Klaczak: The decision to transition to a cloud-based system—and getting senior management’s support for it—was based on a strategic blend of three things. First was grounding technology investments in a cost-benefit analysis aligned with the organization's commitment to efficiency and cost effectiveness. We positioned the cloud transition as a significant expense-saving measure with tangible business benefits. Second, the transition involved managing 12 to 15 policy administration engines critical to Lincoln Financial’s core operations in life, annuity, and retirement. Confidence in the success of the transition was contingent on a comprehensive risk-mitigation strategy. Recognizing the inherent high-risk nature of the program, we put together a robust risk-mitigation plan. Third, the team's execution strategy has focused on maintaining flawless operations throughout the transition. Despite an accelerated timeline, the emphasis has been on ensuring a high-quality product to avoid disruptions to internal businesses and external customer experiences. Our planning included meticulous checking, multiple validation processes, business acceptance testing, and parallel production runs undertaken by the team to guarantee a seamless transition. McKinsey: How did you assemble the team to pull this off? Rob Klaczak: The success of our effort came from a combination of strong leadership, adaptive planning, thorough due diligence, and effective organizational design. Satyendra's leadership style, technical acumen, and commitment have been central to driving the program's success. Our operating model also emphasizes leadership alignment, building organizational support, and implementing an agile approach to overcome the complexities of the transition process. A significant aspect of the transition strategy involves adaptive planning. Traditional program management office (PMO) approaches are inadequate for dealing with the complexities of systems that have been in place for over 50 years. We therefore adopted an iterative approach, emphasizing frequent assessments, replanning, and agile responses to evolving requirements. Gaining support and alignment across all levels of the organization has been critical. Transparency in decision making, involvement of diverse stakeholders, and clear objectives have contributed to building confidence among senior management and the broader team. Designing robust organizational operating and engagement models is paramount. The hub-and-spoke model, where the core team (hub) is connected to various parts of the business and IT (spokes), ensures effective communication, information flow, and collective engagement. The emphasis is on avoiding isolation and fostering a collaborative environment to address challenges and celebrate successes collectively. Cloud by McKinsey Insights McKinsey: How did you approach overall planning for such a significant migration? Satyendra Kumar: There were a number of key areas we focused on. First, we adopted a multiprovider, multipartner strategy for the transition. And the necessity of bringing partners together early on and encouraging collaboration beyond organizational boundaries was critical. Security was also a key consideration, and we worked closely with all key partners to ensure that we understood the nuances of security in a legacy system and met current standards in the target state. The creation of a comprehensive, Wikipedia-style playbook democratized data collection and information sharing across the organization. We prioritized applications based on business needs, considering factors like processing times and application sensitivity, and took a dynamic approach to planning, blending automation and manual processes. Lincoln Financial's success in executing an agile approach, despite initial challenges with shifting dates, was due to the agile mindset, which was essential for adapting to unknowns, building confidence, and consistently delivering results. We also drew inspiration from Navy SEAL strategies, emphasizing preparation for the unknown and the ability to quickly readjust plans. Leadership played a critical role in instilling confidence through successful deliveries and a transparent, agile approach. Positive feedback from business leaders highlighted the program’s success with minimal disruptions. Building and executing a robust cloud operating model was also essential in gaining support across the organization, and we empowered the team with decision-making authority, which helped us avoid “analysis paralysis” and become comfortable with short-term tactics. We also closely engaged stakeholders and leadership for interfacing applications so that their own feature release schedules were in sync with the migration schedule to ensure a seamless experience for the business users. McKinsey: What were the major technical or nontechnical challenges? Rob Klaczak: With a program like this, one should expect lots of challenges, and the only way forward is to work through them. A few of them included legacy security measures—authentication without authorization posed a significant challenge. Early engagement with the chief information security officer (CISO) and fostering a strong relationship with the CISO’s team were crucial for navigating security complexities. We also focused on the need for a fundamental shift in mindset, from creating multiple environments in the legacy footprint to optimizing for cost efficiency in a cloud-based, consumption-driven structure. Emphasis on thought leadership and adapting to a more efficient approach in orchestrating processes was necessary. Satyendra Kumar: This program is very exciting for technology professionals but posed significant challenges to senior management because there were so many unknowns related to more than 100 million lines of code, diverse old technologies, and fundamental changes in the underlying data structures and formats. Solutions involved conducting equivalency tests, securing data, and leveraging compression and decompression technologies. Underestimating the time required for moving large volumes of data became a significant challenge. Migrating data across extensive policy engine platforms presented time-consuming hurdles. We also faced challenges related to code conversion, especially in technologies tied to specific partners, which demanded expertise in certain niche languages. The search for source code and addressing gaps in applications that lacked source code added complexity. Identifying and dealing with technology blind spots, where certain technologies and functionalities are outdated, was also difficult. McKinsey: How is the performance in the target state? Satyendra Kumar: While the organization has not yet accumulated sufficient volume to comprehensively assess efficiency, there are early positive indicators. Parameters such as environment stability, meeting service levels, and running at optimized costs have shown promising results. Initial anecdotal evidence suggests improved performance for both external customers and internal business users. The cloud environment, despite its complexity, is more efficient, thanks to advancements in cloud technologies. Notable improvements in cycle times, with a reported enhancement of 20 to 30 percent, and affirmation of reliability, scalability, and performance of the cloud-based systems, have been the highlights so far. McKinsey: What are the key lessons learned, and do you have any advice for others? Satyendra Kumar: Careful and detailed planning, along with a SWAT team approach to identify and resolve unknowns, is critical to success. You also need to bring the whole organization along and clearly lay out the role each team needs to play. Communicate effectively and extensively within the organization and with vendor partners to create awareness and build a highly engaging team. Rob Klaczak: An effort like this needs unwavering support from senior management. We also acknowledge the dedication of team members and partners and their enthusiasm and eagerness to contribute to this challenging and exciting initiative. The unifying goal attached to the program and the collective effort of a thousand individuals have been instrumental in overcoming obstacles and achieving success. Rob Klaczak is senior vice president and divisional CIO for life, annuities, and distribution at Lincoln Financial Group, where Satyendra Kumar is vice president and executive sponsor and program lead. This interview was conducted by Colin Gunter , a partner in McKinsey’s Atlanta office; Sanjay Kaniyar , a partner in the Boston office; Yash Rajyaguru , a principal lead for cloud delivery in the Washington, DC, office; and Mayukh Samajder , a principal architect in the Stamford office. The authors wish to thank Chris Cahill, Navnith Jayaram, and Alan Lin from Lincoln Financial Group for their contributions to this interview. Explore a career with us Related Articles What every insurance leader should know about cloud In search of cloud value: Can generative AI transform cloud ROI? Getting ahead in the cloud"}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:06:18 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:06:18 [httpcore.connection] DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-20 02:06:18 [httpcore.connection] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D62052AD0>
2024-08-20 02:06:18 [httpcore.connection] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020D6259DA30> server_hostname='api.openai.com' timeout=5.0
2024-08-20 02:06:19 [httpcore.connection] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D620513D0>
2024-08-20 02:06:19 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:06:19 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:06:19 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:06:19 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:06:19 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:06:20 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:06:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'832'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'197021'), (b'x-ratelimit-reset-requests', b'1m44.541s'), (b'x-ratelimit-reset-tokens', b'893ms'), (b'x-request-id', b'req_26847e42ab6e992048e7a425576bdb16'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pew_9VAwidna9Dq3cw4sMOeoNwgug8p.d9R2u9lM0FE-1724137580-1.0.1.1-pR2LtiiHCTSdvllOdH5Yn5wcnjPuI4dun4tu8zMNordB5jCoe0cFECN9dJbbgHvU0ZcMm4I4VFmQJ76d2fbYkg; path=/; expires=Tue, 20-Aug-24 07:36:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=BQPZhhfbSHJ0iupeRo416NWIpEOrUquweAVn6d35YUA-1724137580748-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608a410e8b6071-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:06:20 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:06:20 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:06:20 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:06:20 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:06:20 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:06:20 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Tue, 20 Aug 2024 07:06:20 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-organization', 'user-zdyom7q4bmlbujea2gl0pk3n'), ('openai-processing-ms', '832'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15552000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9987'), ('x-ratelimit-remaining-tokens', '197021'), ('x-ratelimit-reset-requests', '1m44.541s'), ('x-ratelimit-reset-tokens', '893ms'), ('x-request-id', 'req_26847e42ab6e992048e7a425576bdb16'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=pew_9VAwidna9Dq3cw4sMOeoNwgug8p.d9R2u9lM0FE-1724137580-1.0.1.1-pR2LtiiHCTSdvllOdH5Yn5wcnjPuI4dun4tu8zMNordB5jCoe0cFECN9dJbbgHvU0ZcMm4I4VFmQJ76d2fbYkg; path=/; expires=Tue, 20-Aug-24 07:36:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=BQPZhhfbSHJ0iupeRo416NWIpEOrUquweAVn6d35YUA-1724137580748-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8b608a410e8b6071-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-08-20 02:06:20 [openai._base_client] DEBUG: request_id: req_26847e42ab6e992048e7a425576bdb16
2024-08-20 02:06:20 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Lincoln Financial Group successfully transitioned from legacy systems to cloud architecture in under two years, driven by goals of cost reduction, flexibility, and improved decision-making. Key lessons include careful planning, strong leadership, effective communication, and unwavering senior management support, resulting in
2024-08-20 02:06:20 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:20 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AG1 HTTP/11" 200 None
2024-08-20 02:06:20 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AG1?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:06:20 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:20 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:06:20 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:06:21 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A2%3AG2 HTTP/11" 200 None
2024-08-20 02:06:21 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A2%3AG2?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:06:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/from-legacy-to-cloud-lessons-from-the-trenches>
{'title': 'From legacy to cloud: Lessons learned', 'description': 'The journey to cloud is complex, demanding leadership, careful planning, and an agile approach to the unexpected.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/from-legacy-to-cloud-lessons-from-the-trenches', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/from%20legacy%20to%20cloud%20lessons%20from%20the%20trenches/thumb-klaczak-kumar-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-03-11T12:00:00Z', 'article_text': "From legacy to cloud: Lessons learned This interview has been updated to acknowledge external contributors. Modernizing legacy systems and platforms can drive significant business value by enabling faster innovation, greater agility, and lower costs. Organizations take a variety of approaches to modernization, typically based on their specific situation, such as the current state of their investments, their risk appetite, and their time horizon. In this interview, we highlight one such approach, where Lincoln Financial Group transitioned its sizable legacy footprint to cloud within two years. Rob Klaczak, senior vice president and divisional CIO for life, annuities, and distribution, and Satyendra Kumar, vice president and executive sponsor and program lead, discuss Lincoln Financial Group’s transformative journey from decades-old legacy platforms to a dynamic cloud-based architecture, the lessons learned on the way, and their advice for others with similar goals. McKinsey: What prompted you to undertake this transformation? Rob Klaczak: Lincoln Financial’s primary goals for migrating its legacy footprint (for example, assembler code, COBOL-based systems, highly customized system configurations) to the cloud focused on three objectives: reducing overall operating costs, addressing the high expenses associated with certain specialized software licensing, and transitioning to a more modern and flexible environment. The need for modernization and the desire to move away from our fixed-cost legacy setup have been the crucial drivers of this migration. In the context of an insurance company like us, whether managing a million policies or just a few policies, the costs associated with our legacy platforms were largely fixed, posing a financial challenge. We undertook our program to address these challenges, which were complex due to the nature of our business; the large scope of the modernization, which included 120 complex systems; and an accelerated time frame of less than two years to complete the entire program. Satyendra Kumar: Another key objective was to move the decision-making power from IT to the business side by implementing a model that put a price on the consumption of technology services. Now each line of business has the discretion to increase or reduce its spending in alignment with its business goals. McKinsey: How were you able to get senior management’s support and buy-in? Rob Klaczak: The decision to transition to a cloud-based system—and getting senior management’s support for it—was based on a strategic blend of three things. First was grounding technology investments in a cost-benefit analysis aligned with the organization's commitment to efficiency and cost effectiveness. We positioned the cloud transition as a significant expense-saving measure with tangible business benefits. Second, the transition involved managing 12 to 15 policy administration engines critical to Lincoln Financial’s core operations in life, annuity, and retirement. Confidence in the success of the transition was contingent on a comprehensive risk-mitigation strategy. Recognizing the inherent high-risk nature of the program, we put together a robust risk-mitigation plan. Third, the team's execution strategy has focused on maintaining flawless operations throughout the transition. Despite an accelerated timeline, the emphasis has been on ensuring a high-quality product to avoid disruptions to internal businesses and external customer experiences. Our planning included meticulous checking, multiple validation processes, business acceptance testing, and parallel production runs undertaken by the team to guarantee a seamless transition. McKinsey: How did you assemble the team to pull this off? Rob Klaczak: The success of our effort came from a combination of strong leadership, adaptive planning, thorough due diligence, and effective organizational design. Satyendra's leadership style, technical acumen, and commitment have been central to driving the program's success. Our operating model also emphasizes leadership alignment, building organizational support, and implementing an agile approach to overcome the complexities of the transition process. A significant aspect of the transition strategy involves adaptive planning. Traditional program management office (PMO) approaches are inadequate for dealing with the complexities of systems that have been in place for over 50 years. We therefore adopted an iterative approach, emphasizing frequent assessments, replanning, and agile responses to evolving requirements. Gaining support and alignment across all levels of the organization has been critical. Transparency in decision making, involvement of diverse stakeholders, and clear objectives have contributed to building confidence among senior management and the broader team. Designing robust organizational operating and engagement models is paramount. The hub-and-spoke model, where the core team (hub) is connected to various parts of the business and IT (spokes), ensures effective communication, information flow, and collective engagement. The emphasis is on avoiding isolation and fostering a collaborative environment to address challenges and celebrate successes collectively. Cloud by McKinsey Insights McKinsey: How did you approach overall planning for such a significant migration? Satyendra Kumar: There were a number of key areas we focused on. First, we adopted a multiprovider, multipartner strategy for the transition. And the necessity of bringing partners together early on and encouraging collaboration beyond organizational boundaries was critical. Security was also a key consideration, and we worked closely with all key partners to ensure that we understood the nuances of security in a legacy system and met current standards in the target state. The creation of a comprehensive, Wikipedia-style playbook democratized data collection and information sharing across the organization. We prioritized applications based on business needs, considering factors like processing times and application sensitivity, and took a dynamic approach to planning, blending automation and manual processes. Lincoln Financial's success in executing an agile approach, despite initial challenges with shifting dates, was due to the agile mindset, which was essential for adapting to unknowns, building confidence, and consistently delivering results. We also drew inspiration from Navy SEAL strategies, emphasizing preparation for the unknown and the ability to quickly readjust plans. Leadership played a critical role in instilling confidence through successful deliveries and a transparent, agile approach. Positive feedback from business leaders highlighted the program’s success with minimal disruptions. Building and executing a robust cloud operating model was also essential in gaining support across the organization, and we empowered the team with decision-making authority, which helped us avoid “analysis paralysis” and become comfortable with short-term tactics. We also closely engaged stakeholders and leadership for interfacing applications so that their own feature release schedules were in sync with the migration schedule to ensure a seamless experience for the business users. McKinsey: What were the major technical or nontechnical challenges? Rob Klaczak: With a program like this, one should expect lots of challenges, and the only way forward is to work through them. A few of them included legacy security measures—authentication without authorization posed a significant challenge. Early engagement with the chief information security officer (CISO) and fostering a strong relationship with the CISO’s team were crucial for navigating security complexities. We also focused on the need for a fundamental shift in mindset, from creating multiple environments in the legacy footprint to optimizing for cost efficiency in a cloud-based, consumption-driven structure. Emphasis on thought leadership and adapting to a more efficient approach in orchestrating processes was necessary. Satyendra Kumar: This program is very exciting for technology professionals but posed significant challenges to senior management because there were so many unknowns related to more than 100 million lines of code, diverse old technologies, and fundamental changes in the underlying data structures and formats. Solutions involved conducting equivalency tests, securing data, and leveraging compression and decompression technologies. Underestimating the time required for moving large volumes of data became a significant challenge. Migrating data across extensive policy engine platforms presented time-consuming hurdles. We also faced challenges related to code conversion, especially in technologies tied to specific partners, which demanded expertise in certain niche languages. The search for source code and addressing gaps in applications that lacked source code added complexity. Identifying and dealing with technology blind spots, where certain technologies and functionalities are outdated, was also difficult. McKinsey: How is the performance in the target state? Satyendra Kumar: While the organization has not yet accumulated sufficient volume to comprehensively assess efficiency, there are early positive indicators. Parameters such as environment stability, meeting service levels, and running at optimized costs have shown promising results. Initial anecdotal evidence suggests improved performance for both external customers and internal business users. The cloud environment, despite its complexity, is more efficient, thanks to advancements in cloud technologies. Notable improvements in cycle times, with a reported enhancement of 20 to 30 percent, and affirmation of reliability, scalability, and performance of the cloud-based systems, have been the highlights so far. McKinsey: What are the key lessons learned, and do you have any advice for others? Satyendra Kumar: Careful and detailed planning, along with a SWAT team approach to identify and resolve unknowns, is critical to success. You also need to bring the whole organization along and clearly lay out the role each team needs to play. Communicate effectively and extensively within the organization and with vendor partners to create awareness and build a highly engaging team. Rob Klaczak: An effort like this needs unwavering support from senior management. We also acknowledge the dedication of team members and partners and their enthusiasm and eagerness to contribute to this challenging and exciting initiative. The unifying goal attached to the program and the collective effort of a thousand individuals have been instrumental in overcoming obstacles and achieving success. Rob Klaczak is senior vice president and divisional CIO for life, annuities, and distribution at Lincoln Financial Group, where Satyendra Kumar is vice president and executive sponsor and program lead. This interview was conducted by Colin Gunter , a partner in McKinsey’s Atlanta office; Sanjay Kaniyar , a partner in the Boston office; Yash Rajyaguru , a principal lead for cloud delivery in the Washington, DC, office; and Mayukh Samajder , a principal architect in the Stamford office. The authors wish to thank Chris Cahill, Navnith Jayaram, and Alan Lin from Lincoln Financial Group for their contributions to this interview. Explore a career with us Related Articles What every insurance leader should know about cloud In search of cloud value: Can generative AI transform cloud ROI? Getting ahead in the cloud", 'summary': 'Lincoln Financial Group successfully transitioned from legacy systems to cloud architecture in under two years, driven by goals of cost reduction, flexibility, and improved decision-making. Key lessons include careful planning, strong leadership, effective communication, and unwavering senior management support, resulting in'}
2024-08-20 02:06:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/embracing-digital-transformation-with-a-digital-factory> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:06:21 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nEmbracing digital transformation with a digital factory When Saudi Arabia’s Alinma Bank decided to embark on a digital transformation, it built a digital factory. This approach is one way companies can incubate innovation and model agile ways of working that can then provide a foundation for spreading these practices throughout the organization. At Alinma Bank, leadership focused on building digital capabilities that have allowed them to deliver disruptive digital solutions to a variety of customer segments. Sami Al-Rowaithey, Alinma Bank’s chief digital officer (CDO), discusses with McKinsey partner Sonia Wedrychowicz the value of adopting agile, attracting diverse talent, and putting the customer at the heart of everything. What follows are edited highlights from their conversation. Building a digital factory Sonia Wedrychowicz: Can you describe what a digital factory is and what it means to Alinma Bank? Sami Al-Rowaithey: Essentially, it’s a platform to power up and deliver digital transformation. It’s a space to foster innovation, embrace new ways of working, promote transparency, encourage teamwork, and adopt agile ways of working, with the ultimate objective of rapidly delivering on our aspirations. Alinma’s digital factory was established a little more than one year ago and is responsible for spearheading the bank’s digital transformation. It’s responsible for managing the entire digital structure and its associated strategies, business development, product innovation, experience management, performance management, and digital profitability. Sonia Wedrychowicz: How did you go about establishing the digital factory? Sami Al-Rowaithey: It was an exciting journey. We were contemplating different approaches in terms of how and where to start. We ultimately decided to start small and scale fast to minimize resistance and ease the adoption of new practices within the organization. We started with a small team working on one project, and then looked at building a relevant operating model suitable for what we wanted to do—and for the organization as a whole. We determined how the team would operate, the composition and structure of squads (teams), how the tribes (groups of related squads) were defined, and what practices and tools they needed. We started with one initiative and one tribe. One year later, we now have four tribes and around eight squads operating within the factory, independently delivering projects for various customer segments. Another important consideration was how this digital factory would interact with the wider organization, such as IT, marketing, business, and other functions. The third point we addressed was sponsorship, which is key, since we needed to be supported from the top of the organization to drive this massive transformation. So, we spent a lot of time communicating the values, objectives, and advantages of creating a digital factory to the whole organization. Finally, and most important, are our people. We looked for talent from different industries to inject new DNA into the bank that can champion this transformation. Putting the customer at the heart of everything Sonia Wedrychowicz: Digital factories often can feel different from other parts of an organization. How did you approach establishing an operating model that has allowed you to successfully innovate? Sami Al-Rowaithey: We’ve embraced practices around empowerment and enablement and have encouraged our people to experiment and make mistakes. We want them to know that it’s OK to learn from mistakes and move on. Transparency is key as well, so we always encourage our people not to shy away from speaking up. This gives us better visibility into what is happening on the ground and what support employees need from us to achieve their goals. Transparency also applies to customers, because it’s crucial to understand customers deeply to give them what they want, not what we think they want. So, in order to develop propositions and solutions that resonate with customers, we’ve created a beta community to test our journeys, experiences, and products. Putting the customer at the heart of everything we do and always putting our people first are the two main ingredients for success. Spreading innovation throughout the institution Sonia Wedrychowicz: Do you think this new focus on delivering value to customers has radiated outside of the digital factory? Sami Al-Rowaithey: In fact, yes, and very quickly. The technologies and tools we’ve embraced within the factory are now being adopted by the bank’s wider IT organization. And our marketing department is already working on establishing something similar to our beta community. We created squads to bring all our people together in one space, on one floor, working as one team to deliver on products and objectives in agile ways of working. Now we’re seeing that model spread to other departments, like IT, retail, and corporate. Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI The importance of diversity in the digital factory Sonia Wedrychowicz: You’ve introduced a diversity transformation within the digital factory. Why was that important, and how have you achieved it? Sami Al-Rowaithey: Let me explain our recruitment strategy. We wanted to start small but fast. So, we launched two parallel tracks, the first of which relied on vendors and contractors, to ramp up quickly. We also launched a parallel track looking for people to recruit within the bank, so we managed to scale up very quickly, in just a few months. Because we also looked for talent outside the bank, we attracted people from different industries, like fintechs, start-ups, government, and telcos, to create diversity. In addition, we also looked at diversity in terms of background and nationality to stimulate creative thinking. We are always looking for the most qualified people, and I’m proud to say that we have a lot of talented women in the digital factory. They comprise around 30 percent of our team. Starting small and scaling quickly Sonia Wedrychowicz: You said you started small but grew quickly. How did the digital factory approach enable you to roll out multiple projects at the same time? Sami Al-Rowaithey: It was a big task. But we developed a digital-transformation strategy touching every vertical in the bank and covering the entire spectrum, be it digitizing customer experiences, improving multichannel delivery, enhancing our digital sales, maximizing the contribution of digital to the bottom line, or improving customer satisfaction. Then we looked at venturing into new businesses, leapfrogging via innovation, and creating propositions to attract and acquire specific customer segments. We asked ourselves, “How do we go beyond normal banking? How do we embrace open banking? How do we build ecosystems? How do we leverage the external ecosystem to accelerate our digitalization agenda?” Many of these aspirations have already been translated into initiatives. We have an ambitious vision, to be the fastest and most convenient bank in Saudi Arabia, so we needed to fundamentally change how we run our business and create an engine that constantly challenges the status quo by asking how business is conducted, how processes are defined, how experiences are reimagined, and how quickly we can deliver. Since we needed to scale up quickly, one important principle we kept in mind was always to focus on delivering incremental value to customers while building the foundations. That’s why we managed to scale quickly and deliver on multiple initiatives in our road map. Overcoming challenges around talent, mindset, and culture Sonia Wedrychowicz: What kind of challenges did the digital-factory initiative face? Sami Al-Rowaithey: I would pinpoint two main items. The first challenge was the search for talent, which is crucial, because without it, we couldn’t accomplish anything. We’re seeing a talent scarcity across the globe and found it difficult both to recruit and to retain people with the right skill sets. The second challenge was basically one of mindset and culture. As you can imagine, it’s not easy changing the mindset within a large bank in a short period of time. That’s why it took a lot of time aligning with the wider organization to make them feel part of our success. So we brought them into the digital factory, collaborated with them, took their feedback seriously, and engaged and iterated with them. That eased the adoption of the digital factory within the larger organization, minimized resistance, and made people more comfortable with us—because at the beginning, the rest of the bank viewed us as a threatening department here to take their jobs. But that’s all in the past now, and the organization-wide perception of the digital factory is extremely positive. Advice for others on the journey Sonia Wedrychowicz: What advice would you give to others embarking on a digital transformation? Sami Al-Rowaithey: The first thing I would say is to not spend a lot of time trying to figure out all the details of the journey. It’s important to start quick, learn as you go, be flexible, modify, and move on. Secondly, you need to be resilient and persistent. The journey will be full of challenges, but you’ll manage as long as you always keep the final goal in mind. If there’s a will, there’s a way. Finally, it’s important to maintain autonomy, but don’t fall into the trap of isolating yourself within the organization. Always keep your stakeholders engaged and aligned while preserving the flexibility and autonomy to deliver and move fast on shared goals. Sonia Wedrychowicz: What is the future of the digital factory for Alinma Bank? Sami Al-Rowaithey: I’d be lying if I said I know what the future holds, but I believe in our road map. We have a pipeline of initiatives and propositions for specific customer segments on multiple fronts. We also want to focus more on propagating the values, practices, and principles of the digital factory throughout the organization. Finally, we will continue to scale up. When we were moving into the digital factory space a year ago, it seemed very spacious. When you go through the corridors today, there are hardly any spaces left. We've got a lot of engaged people, a lot of movement, a lot of energy, and a lot of passion. And finally, from a personal perspective, I strongly believe that fostering advanced digital talent and offering solutions enabling individuals to make informed financial decisions can significantly benefit society. Watch the full interview here . Sami Al-Rowaithey is the chief digital officer of Alinma Bank. Sonia Wedrychowicz is a partner in McKinsey’s Dubai office. Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement. Explore a career with us Related Articles Welcome to the Digital Factory: The answer to how to scale your digital transformation In digital and AI transformations, start with the problem, not the technology Rewired to outcompete"}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:06:21 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:06:21 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:06:21 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:06:21 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:06:21 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:06:21 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:06:22 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'197121'), (b'x-ratelimit-reset-requests', b'1m50.637s'), (b'x-ratelimit-reset-tokens', b'863ms'), (b'x-request-id', b'req_0b0e57e055b082e92f83b4f05502d0d8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608a5108cb6071-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:06:22 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:06:22 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:06:22 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:06:22 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:06:22 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:06:22 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:06:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '620', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '197121', 'x-ratelimit-reset-requests': '1m50.637s', 'x-ratelimit-reset-tokens': '863ms', 'x-request-id': 'req_0b0e57e055b082e92f83b4f05502d0d8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608a5108cb6071-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:06:22 [openai._base_client] DEBUG: request_id: req_0b0e57e055b082e92f83b4f05502d0d8
2024-08-20 02:06:22 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Alinma Bank established a digital factory to drive its digital transformation by fostering innovation, agile practices, and diverse talent. This initiative allows for rapid delivery of customer-centric solutions, encourages collaboration within the wider organization, and aims to scale up continuously while overcoming
2024-08-20 02:06:22 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:22 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:22 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:06:22 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:06:23 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A3%3AG3 HTTP/11" 200 None
2024-08-20 02:06:23 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A3%3AG3?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:06:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/embracing-digital-transformation-with-a-digital-factory>
{'title': 'Embracing digital transformation with a digital factory', 'description': "In this interview, Alinma Bank's chief digital officer discusses the importance of a digital factory to the bank’s overall transformation journey.", 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/embracing-digital-transformation-with-a-digital-factory', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/embracing%20digital%20transformation%20with%20a%20digital%20factory/thumb-sami-thumb-1536x1536-v2.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-03-28T12:00:00Z', 'article_text': "Embracing digital transformation with a digital factory When Saudi Arabia’s Alinma Bank decided to embark on a digital transformation, it built a digital factory. This approach is one way companies can incubate innovation and model agile ways of working that can then provide a foundation for spreading these practices throughout the organization. At Alinma Bank, leadership focused on building digital capabilities that have allowed them to deliver disruptive digital solutions to a variety of customer segments. Sami Al-Rowaithey, Alinma Bank’s chief digital officer (CDO), discusses with McKinsey partner Sonia Wedrychowicz the value of adopting agile, attracting diverse talent, and putting the customer at the heart of everything. What follows are edited highlights from their conversation. Building a digital factory Sonia Wedrychowicz: Can you describe what a digital factory is and what it means to Alinma Bank? Sami Al-Rowaithey: Essentially, it’s a platform to power up and deliver digital transformation. It’s a space to foster innovation, embrace new ways of working, promote transparency, encourage teamwork, and adopt agile ways of working, with the ultimate objective of rapidly delivering on our aspirations. Alinma’s digital factory was established a little more than one year ago and is responsible for spearheading the bank’s digital transformation. It’s responsible for managing the entire digital structure and its associated strategies, business development, product innovation, experience management, performance management, and digital profitability. Sonia Wedrychowicz: How did you go about establishing the digital factory? Sami Al-Rowaithey: It was an exciting journey. We were contemplating different approaches in terms of how and where to start. We ultimately decided to start small and scale fast to minimize resistance and ease the adoption of new practices within the organization. We started with a small team working on one project, and then looked at building a relevant operating model suitable for what we wanted to do—and for the organization as a whole. We determined how the team would operate, the composition and structure of squads (teams), how the tribes (groups of related squads) were defined, and what practices and tools they needed. We started with one initiative and one tribe. One year later, we now have four tribes and around eight squads operating within the factory, independently delivering projects for various customer segments. Another important consideration was how this digital factory would interact with the wider organization, such as IT, marketing, business, and other functions. The third point we addressed was sponsorship, which is key, since we needed to be supported from the top of the organization to drive this massive transformation. So, we spent a lot of time communicating the values, objectives, and advantages of creating a digital factory to the whole organization. Finally, and most important, are our people. We looked for talent from different industries to inject new DNA into the bank that can champion this transformation. Putting the customer at the heart of everything Sonia Wedrychowicz: Digital factories often can feel different from other parts of an organization. How did you approach establishing an operating model that has allowed you to successfully innovate? Sami Al-Rowaithey: We’ve embraced practices around empowerment and enablement and have encouraged our people to experiment and make mistakes. We want them to know that it’s OK to learn from mistakes and move on. Transparency is key as well, so we always encourage our people not to shy away from speaking up. This gives us better visibility into what is happening on the ground and what support employees need from us to achieve their goals. Transparency also applies to customers, because it’s crucial to understand customers deeply to give them what they want, not what we think they want. So, in order to develop propositions and solutions that resonate with customers, we’ve created a beta community to test our journeys, experiences, and products. Putting the customer at the heart of everything we do and always putting our people first are the two main ingredients for success. Spreading innovation throughout the institution Sonia Wedrychowicz: Do you think this new focus on delivering value to customers has radiated outside of the digital factory? Sami Al-Rowaithey: In fact, yes, and very quickly. The technologies and tools we’ve embraced within the factory are now being adopted by the bank’s wider IT organization. And our marketing department is already working on establishing something similar to our beta community. We created squads to bring all our people together in one space, on one floor, working as one team to deliver on products and objectives in agile ways of working. Now we’re seeing that model spread to other departments, like IT, retail, and corporate. Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI The importance of diversity in the digital factory Sonia Wedrychowicz: You’ve introduced a diversity transformation within the digital factory. Why was that important, and how have you achieved it? Sami Al-Rowaithey: Let me explain our recruitment strategy. We wanted to start small but fast. So, we launched two parallel tracks, the first of which relied on vendors and contractors, to ramp up quickly. We also launched a parallel track looking for people to recruit within the bank, so we managed to scale up very quickly, in just a few months. Because we also looked for talent outside the bank, we attracted people from different industries, like fintechs, start-ups, government, and telcos, to create diversity. In addition, we also looked at diversity in terms of background and nationality to stimulate creative thinking. We are always looking for the most qualified people, and I’m proud to say that we have a lot of talented women in the digital factory. They comprise around 30 percent of our team. Starting small and scaling quickly Sonia Wedrychowicz: You said you started small but grew quickly. How did the digital factory approach enable you to roll out multiple projects at the same time? Sami Al-Rowaithey: It was a big task. But we developed a digital-transformation strategy touching every vertical in the bank and covering the entire spectrum, be it digitizing customer experiences, improving multichannel delivery, enhancing our digital sales, maximizing the contribution of digital to the bottom line, or improving customer satisfaction. Then we looked at venturing into new businesses, leapfrogging via innovation, and creating propositions to attract and acquire specific customer segments. We asked ourselves, “How do we go beyond normal banking? How do we embrace open banking? How do we build ecosystems? How do we leverage the external ecosystem to accelerate our digitalization agenda?” Many of these aspirations have already been translated into initiatives. We have an ambitious vision, to be the fastest and most convenient bank in Saudi Arabia, so we needed to fundamentally change how we run our business and create an engine that constantly challenges the status quo by asking how business is conducted, how processes are defined, how experiences are reimagined, and how quickly we can deliver. Since we needed to scale up quickly, one important principle we kept in mind was always to focus on delivering incremental value to customers while building the foundations. That’s why we managed to scale quickly and deliver on multiple initiatives in our road map. Overcoming challenges around talent, mindset, and culture Sonia Wedrychowicz: What kind of challenges did the digital-factory initiative face? Sami Al-Rowaithey: I would pinpoint two main items. The first challenge was the search for talent, which is crucial, because without it, we couldn’t accomplish anything. We’re seeing a talent scarcity across the globe and found it difficult both to recruit and to retain people with the right skill sets. The second challenge was basically one of mindset and culture. As you can imagine, it’s not easy changing the mindset within a large bank in a short period of time. That’s why it took a lot of time aligning with the wider organization to make them feel part of our success. So we brought them into the digital factory, collaborated with them, took their feedback seriously, and engaged and iterated with them. That eased the adoption of the digital factory within the larger organization, minimized resistance, and made people more comfortable with us—because at the beginning, the rest of the bank viewed us as a threatening department here to take their jobs. But that’s all in the past now, and the organization-wide perception of the digital factory is extremely positive. Advice for others on the journey Sonia Wedrychowicz: What advice would you give to others embarking on a digital transformation? Sami Al-Rowaithey: The first thing I would say is to not spend a lot of time trying to figure out all the details of the journey. It’s important to start quick, learn as you go, be flexible, modify, and move on. Secondly, you need to be resilient and persistent. The journey will be full of challenges, but you’ll manage as long as you always keep the final goal in mind. If there’s a will, there’s a way. Finally, it’s important to maintain autonomy, but don’t fall into the trap of isolating yourself within the organization. Always keep your stakeholders engaged and aligned while preserving the flexibility and autonomy to deliver and move fast on shared goals. Sonia Wedrychowicz: What is the future of the digital factory for Alinma Bank? Sami Al-Rowaithey: I’d be lying if I said I know what the future holds, but I believe in our road map. We have a pipeline of initiatives and propositions for specific customer segments on multiple fronts. We also want to focus more on propagating the values, practices, and principles of the digital factory throughout the organization. Finally, we will continue to scale up. When we were moving into the digital factory space a year ago, it seemed very spacious. When you go through the corridors today, there are hardly any spaces left. We've got a lot of engaged people, a lot of movement, a lot of energy, and a lot of passion. And finally, from a personal perspective, I strongly believe that fostering advanced digital talent and offering solutions enabling individuals to make informed financial decisions can significantly benefit society. Watch the full interview here . Sami Al-Rowaithey is the chief digital officer of Alinma Bank. Sonia Wedrychowicz is a partner in McKinsey’s Dubai office. Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement. Explore a career with us Related Articles Welcome to the Digital Factory: The answer to how to scale your digital transformation In digital and AI transformations, start with the problem, not the technology Rewired to outcompete", 'summary': 'Alinma Bank established a digital factory to drive its digital transformation by fostering innovation, agile practices, and diverse talent. This initiative allows for rapid delivery of customer-centric solutions, encourages collaboration within the wider organization, and aims to scale up continuously while overcoming'}
2024-08-20 02:06:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-it-takes-to-rewire-a-cpg-company-to-outcompete-in-digital-and-ai> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:06:23 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nWhat it takes to rewire a CPG company to outcompete in digital and AI There’s a race on to capture value from digital and AI, and consumer packaged goods (CPG) companies are in danger of falling behind both retailers and consumers. It’s not for lack of trying. Like most sectors, CPG companies have been on some form of digital and AI transformation journey. But most of them are stuck in the pilot purgatory stage characterized by plenty of subscale activity and little at-scale value. Our analysis of digital and AI maturity has shown that CPG companies are among the poorest performers, while retailers are near the top (Exhibit 1). 1 The scores are based on Digital Quotient (DQ) and AI Quotient (AIQ) assessments that measure digital and AI maturity across core capabilities and management practices essential to capturing value. The DQ and AIQ gap between leaders and laggards was 10.3 percentage points in the period from 2016–19; the gap increased to 16.3 percentage points in the period from 2020–22. This halting progress is all the more frustrating and worrisome in view of the huge value at stake. We analyzed the potential of digital and AI transformations to drive top- and bottom-line impact along the full value chain. 2 Analysis based on McKinsey’s CPG digital and AI impact calculator tool (latest version June 2023), which consists of a repository of more than 60 digital and AI use cases across 11 domains in front (precision revenue growth management; data-driven marketing; sales and in-store excellence; portfolio innovation and design; e-commerce and direct to consumer), middle (autonomous planning; plant of the future; digital logistics; digital procurement and supply management and supplier collaboration), and back (talent analytics; general and administrative services). Our analysis revealed a potential 6 to 10 percent incremental revenue uplift and corresponding growth of 3 to 5 percentage points in EBITDA over three to five years, depending on the subcategory. Furthermore, the increased adoption of generative AI (gen AI) could increase the economic impact of traditional AI by 15 to 40 percent , unlocking an additional $160 billion to $270 billion annually in profit (measured in EBITDA) for CPG companies globally. 3 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. The CPG sector faces some unique challenges. The proliferation of data, for example, and its complexity—sources are scattered across retailers, suppliers, manufacturers, and consumers—have created massive issues in terms of harnessing the data to find, track, and capture value. At its core, the reason for this low success rate is that companies fail to perform the deep organizational surgery required to affect the broad-based change that’s needed. It’s never “just tech” when it comes to successful digital and AI transformations. Companies need to rewire how they work . 4 Eric Lamarre, Kate Smaje, and Rodney Zemmel, “ Rewired to outcompete ,” McKinsey, June 20, 2023. But even while CPG as a sector performs poorly, some companies are high performers, as Exhibit 1 shows. One beverage company that embarked on a digital and AI transformation unlocked 18 percent EBITDA uplift over two years. It was able to make and sustain these improvements by being comprehensive in the scale of, and commitment to, the change needed. A committee of senior leaders started by prioritizing domains that had significant growth opportunities and were feasible, given their capabilities. They then developed a detailed road map and established more than 50 cross-functional pods—joint teams spanning markets, regions, and enterprises—with specific goals and the autonomy to deliver necessary solutions. They put in place a centralized stage-gate process with clear decision rights to track, advance, and fund solutions to help maintain momentum. To support the technology solutions, they moved aggressively into cloud to help create more scale and flexibility to use in building modular, customized applications. They also invested in a data lake and a governance model with clear areas of responsibility. For example, IT defined and managed the data architecture while the business defined use cases for data products. Realizing talent was an acute issue, they upskilled their own people through tailored learning curricula that included on-the-job learning, formal training sessions, and individual coaching. Six questions to help outcompete with digital and AI In working with more than 200 large companies across industries, including 25 of the top 30 CPG companies, we found that six enterprise capabilities are critical for companies to rewire themselves and achieve sustainable competitive advantage from digital and AI (Exhibit 2). In rewiring how they work, CPG companies need to answer six key questions. 1. Where is the value? Making sure that a digital and AI transformation delivers meaningful value starts with prioritizing and focusing efforts on domains where meaningful value exists. While the distribution of value varies across CPG sectors, our analysis shows that the greatest payoff for most sectors is concentrated heavily in two areas: consumer insights and demand creation, and customer and channel management (Exhibit 3). There is one notable exception: the beauty industry, where the direct-to-consumer area takes center stage. New technologies can have a big impact on that interaction model, as well as on the e-commerce process and fulfillment management. In general, these are the domains CPG companies should prioritize for their transformation programs. As CPG companies assess the value, they will need to be thoughtful about understanding gen AI’s impact. McKinsey analysis identified just four areas—customer operations, marketing and sales, software engineering, and research and development—that could account for approximately 75 percent of the total annual value from gen AI use cases . 5 “ The economic potential of generative AI ,” June 14, 2023. The majority of that value comes from increased productivity in the form of, for example, better and faster issue resolution in customer service, more personalized communications, and more-effective product discovery. Gen AI could increase the productivity of the marketing function, with a value between 5 and 15 percent of total marketing spending . 6 “ The economic potential of generative AI ,” June 14, 2023. One consumer company, for example, implemented a gen AI large language model (LLM) to improve the manual process of financial planning and analysis (FP&A) research. An initial proof of concept showed a reduction of up to 30 percent in time spent on research. Some companies are already actively educating their organizations, especially leadership, about gen AI, the capabilities it unlocks, and its applications in business. In fact, since the second quarter of 2023, almost all CPGs we analyzed have had an immersion session on AI for C-level executives. Creating value beyond the hype 2. Are leaders from the business side actively part of the transformation? CPG companies often underestimate the role of business functions in a successful digital and AI transformation, relegating the initiative to IT. Case in point: At a large food manufacturer, the supply chain domain was one of the company’s most successful domains, in part because the leadership, including the COO and CFO, made supply chain a priority. The business dedicated a senior director as product owner for not only the build but also rollout and adoption, and these business leaders joined biweekly sprint reviews, engaging with the supply chain digital leader and the working team in designing a completely new way to optimize customer service. Top business talent should act as product owners of the transformation for their given product, working closely with technology leaders to define the road map of solutions, managing the pipeline of use cases to build the solution, influencing technology infrastructure decisions, governing data, and being the voice of the transformation to their wider teams. The core operational unit is the agile “squad.” Comprised generally of five to eight people across business, data, technology, and design functions, these teams are responsible for building the solutions on the road map (Exhibit 4). They are crucial for scaling. Acting autonomously based on clear guidelines, these agile squads are the only way companies can enable hundreds or even thousands of teams to deliver transformational change. 3. Are you an attractive long-term employer for digital talent? Without top in-house technical talent, CPG companies will struggle with their transformation. Having a hiring strategy and competitive compensation will only get you so far in attracting and retaining digital talent, especially when you are competing with digital natives. The core issue is that work at CPG companies often doesn’t attract top tech talent. Companies will need to offer meaningful missions, learning opportunities, and an environment where tech talent can thrive. A good place to start is upskilling leaders to better understand how tech creates value. P&G instituted a reverse-mentoring program in which junior tech people worked with senior leaders to help them understand how to use tech. 7 “How P&G’s 4D culture helps with successful digital transformation,” Human Resources Online, May 12, 2020. Leaders also went to leading digital businesses to observe operations and speak with leaders to understand what skills are important to bring into an organization. It’s important to focus on hiring talent with some proficiency in relevant areas. Competent developers are significantly more productive than inexperienced ones, and that trend carries over into gen AI as well . 8 “ The economic potential of generative AI ,” June 14, 2023. To find the right talent, CPGs should look to suppliers or retailers who are already progressing on their digital journey. Adjacent sectors such as hospitality and telecom can also be sources of expert talent with broader skills that are transferable to CPG companies. Offering promotions and compensation based on skills mastery and establishing engineering-specific career tracks can also help in retaining your top people. A large beverage CPG knew it needed to upgrade its talent if it wanted its digital and AI transformation to succeed. But established recruiting practices were slow and not geared to the leading technical talent the business needed. A talent win room came together with a new plan. First, they invested in developing clear new role descriptions, tailored to the specific skills required. Second, they focused on identifying new recruiting sources rather than turning to more general jobs and networking venues. Third, they sped up the evaluation process with coding tests, which allowed them to quickly narrow down more than 7,500 initial applicants to high-potential candidates. And fourth, they put in place batch days organized around the full set of decision makers, which allowed them to make decisions on candidates and extend an offer within 24 hours. Over this time, the talent win room had a set of KPIs that they referred to often to track their progress and correct any issues quickly. In 90 days, they were able to fill the 25 critical digital and analytics roles they needed—a tenfold increase in the speed of hiring. 4. Are you deploying your technology investments to optimize for reuse? Many CPG companies have key elements of a core infrastructure in place—such as cloud, data lakes, and planning software—but they are often not set up to operate at scale. This situation is largely the result of a complex tech stack where systems are built to support a specific function or market. This makes it challenging to share data and reuse solutions, leading to costly replication of applications and difficulty in scaling. Enabling solutions that serve multiple domains has significant benefits, such as allowing a company to use a broader range of data to make better revenue growth management (RGM) decisions. Getting to this state requires companies to develop a modular architecture (Exhibit 5). For this approach to work in practice, companies need a global strategy and a team made up of experts from central IT (including enterprise architects, cloud developers, and engineers) and leaders from target markets to design the system together. They should focus on creating modules to support three to five market archetypes (for example, hypermarkets in the United States and more-traditional trade stores in Latin America), develop a road map for building them, and then test them in the market. Typically, this process includes making key decisions, such as what domain tools to deploy, what cloud infrastructure to develop, and whether to build or buy specific technologies. Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI 5. Are you developing data products? Data in the CPG industry is notoriously fragmented across retailers, distributors, consumers, syndicated data providers, marketing platforms, contract manufacturers, third-party logistics providers, and more. This issue has become even more acute with generative AI, with the introduction of huge amounts of unstructured data. Without a centralized, well-coordinated data strategy, teams end up using raw data for their one-off needs, wasting data scientist and engineering capacity on creating inconsistent data sets that can’t be accessed by other teams or systems. To redress this issue, companies need to focus on three things: A global CPG was able to rapidly transform its RGM domain end-to-end in just two years by building modular technology components that enabled it to scale solutions across its more than 30 category/market combinations. Instead of building pricing and promotions analytics around the data available for a particular region/category, for example, the company built a standardized RGM data product that teams could easily use. Each market category only had to input its own data into the product to take advantage of the underlying analytics engine. Because the data product was modular, specific local factors, such as currencies and units of measure, could easily be swapped in. 6. Are you anticipating and preparing for the most critical scaling challenges? The fragmentation in CPG companies—accounts, categories, brands, geographies, and functions—makes adoption and scaling technology challenging. Too often, companies have to redo a lot of work to tailor solutions to local environments. While the adoption of technology relies on many factors, in practice it is most crucial to involve potential future users early in solutions development; give end users incentives to use the technology; minimize the effort required of them, by building solutions into existing tools, for example; and track their uptake over time. The key to tackling scaling is to “assetize” solutions by packaging them as modular assets that teams can easily reuse. The focus should be on technologies, such as APIs; processes, such as solution rollouts, operational guidelines, and training; and support, such as subject-matter experts who understand how to deploy the solution and adapt it to different environments. A digital and AI transformation is a complex journey. But for CPG companies willing to make the commitment to change at scale, the value can be transformative and a competitive necessity. Abdul Wahab Shaikh is a partner in McKinsey’s Atlanta office, Shruti Lal is a partner in the Chicago office, Hannah Mayer is an associate partner in the Bay Area office, and Spurthi Gummadala is a consultant in the Seattle office. The authors wish to thank Roger Roberts for his contributions to this article. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles Rewired and running ahead: Digital and AI leaders are leaving the rest behind Rewired to outcompete A generative AI reset: Rewiring to turn potential into value in 2024'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:06:23 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:06:23 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:06:23 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:06:23 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:06:23 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:06:23 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:06:24 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'691'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'195712'), (b'x-ratelimit-reset-requests', b'1m57.061s'), (b'x-ratelimit-reset-tokens', b'1.286s'), (b'x-request-id', b'req_82ac92a66ebe5d14958ff13615cc4263'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608a5ee8a36071-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:06:24 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:06:24 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:06:24 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:06:24 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:06:24 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:06:24 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:06:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '691', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '195712', 'x-ratelimit-reset-requests': '1m57.061s', 'x-ratelimit-reset-tokens': '1.286s', 'x-request-id': 'req_82ac92a66ebe5d14958ff13615cc4263', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608a5ee8a36071-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:06:24 [openai._base_client] DEBUG: request_id: req_82ac92a66ebe5d14958ff13615cc4263
2024-08-20 02:06:24 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Consumer packaged goods (CPG) companies are struggling to leverage digital and AI effectively, often stuck in pilot phases. To succeed, they must prioritize value areas, involve business leaders, attract digital talent, optimize technology investments, develop cohesive data strategies, and
2024-08-20 02:06:24 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:25 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:25 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:06:25 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:06:25 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A4%3AG4 HTTP/11" 200 None
2024-08-20 02:06:25 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A4%3AG4?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:06:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-it-takes-to-rewire-a-cpg-company-to-outcompete-in-digital-and-ai>
{'title': 'What it takes to rewire a CPG company to outcompete in digital and AI', 'description': 'Answering six specific questions holds the key to successful digital and AI transformations for CPG companies.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-it-takes-to-rewire-a-cpg-company-to-outcompete-in-digital-and-ai', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/what%20it%20takes%20to%20rewire%20a%20cpg%20company%20to%20outcompete%20in%20digital%20and%20ai/thumb-gettyimages-1457743520.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-06-12T12:00:00Z', 'article_text': 'What it takes to rewire a CPG company to outcompete in digital and AI There’s a race on to capture value from digital and AI, and consumer packaged goods (CPG) companies are in danger of falling behind both retailers and consumers. It’s not for lack of trying. Like most sectors, CPG companies have been on some form of digital and AI transformation journey. But most of them are stuck in the pilot purgatory stage characterized by plenty of subscale activity and little at-scale value. Our analysis of digital and AI maturity has shown that CPG companies are among the poorest performers, while retailers are near the top (Exhibit 1). 1 The scores are based on Digital Quotient (DQ) and AI Quotient (AIQ) assessments that measure digital and AI maturity across core capabilities and management practices essential to capturing value. The DQ and AIQ gap between leaders and laggards was 10.3 percentage points in the period from 2016–19; the gap increased to 16.3 percentage points in the period from 2020–22. This halting progress is all the more frustrating and worrisome in view of the huge value at stake. We analyzed the potential of digital and AI transformations to drive top- and bottom-line impact along the full value chain. 2 Analysis based on McKinsey’s CPG digital and AI impact calculator tool (latest version June 2023), which consists of a repository of more than 60 digital and AI use cases across 11 domains in front (precision revenue growth management; data-driven marketing; sales and in-store excellence; portfolio innovation and design; e-commerce and direct to consumer), middle (autonomous planning; plant of the future; digital logistics; digital procurement and supply management and supplier collaboration), and back (talent analytics; general and administrative services). Our analysis revealed a potential 6 to 10 percent incremental revenue uplift and corresponding growth of 3 to 5 percentage points in EBITDA over three to five years, depending on the subcategory. Furthermore, the increased adoption of generative AI (gen AI) could increase the economic impact of traditional AI by 15 to 40 percent , unlocking an additional $160 billion to $270 billion annually in profit (measured in EBITDA) for CPG companies globally. 3 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. The CPG sector faces some unique challenges. The proliferation of data, for example, and its complexity—sources are scattered across retailers, suppliers, manufacturers, and consumers—have created massive issues in terms of harnessing the data to find, track, and capture value. At its core, the reason for this low success rate is that companies fail to perform the deep organizational surgery required to affect the broad-based change that’s needed. It’s never “just tech” when it comes to successful digital and AI transformations. Companies need to rewire how they work . 4 Eric Lamarre, Kate Smaje, and Rodney Zemmel, “ Rewired to outcompete ,” McKinsey, June 20, 2023. But even while CPG as a sector performs poorly, some companies are high performers, as Exhibit 1 shows. One beverage company that embarked on a digital and AI transformation unlocked 18 percent EBITDA uplift over two years. It was able to make and sustain these improvements by being comprehensive in the scale of, and commitment to, the change needed. A committee of senior leaders started by prioritizing domains that had significant growth opportunities and were feasible, given their capabilities. They then developed a detailed road map and established more than 50 cross-functional pods—joint teams spanning markets, regions, and enterprises—with specific goals and the autonomy to deliver necessary solutions. They put in place a centralized stage-gate process with clear decision rights to track, advance, and fund solutions to help maintain momentum. To support the technology solutions, they moved aggressively into cloud to help create more scale and flexibility to use in building modular, customized applications. They also invested in a data lake and a governance model with clear areas of responsibility. For example, IT defined and managed the data architecture while the business defined use cases for data products. Realizing talent was an acute issue, they upskilled their own people through tailored learning curricula that included on-the-job learning, formal training sessions, and individual coaching. Six questions to help outcompete with digital and AI In working with more than 200 large companies across industries, including 25 of the top 30 CPG companies, we found that six enterprise capabilities are critical for companies to rewire themselves and achieve sustainable competitive advantage from digital and AI (Exhibit 2). In rewiring how they work, CPG companies need to answer six key questions. 1. Where is the value? Making sure that a digital and AI transformation delivers meaningful value starts with prioritizing and focusing efforts on domains where meaningful value exists. While the distribution of value varies across CPG sectors, our analysis shows that the greatest payoff for most sectors is concentrated heavily in two areas: consumer insights and demand creation, and customer and channel management (Exhibit 3). There is one notable exception: the beauty industry, where the direct-to-consumer area takes center stage. New technologies can have a big impact on that interaction model, as well as on the e-commerce process and fulfillment management. In general, these are the domains CPG companies should prioritize for their transformation programs. As CPG companies assess the value, they will need to be thoughtful about understanding gen AI’s impact. McKinsey analysis identified just four areas—customer operations, marketing and sales, software engineering, and research and development—that could account for approximately 75 percent of the total annual value from gen AI use cases . 5 “ The economic potential of generative AI ,” June 14, 2023. The majority of that value comes from increased productivity in the form of, for example, better and faster issue resolution in customer service, more personalized communications, and more-effective product discovery. Gen AI could increase the productivity of the marketing function, with a value between 5 and 15 percent of total marketing spending . 6 “ The economic potential of generative AI ,” June 14, 2023. One consumer company, for example, implemented a gen AI large language model (LLM) to improve the manual process of financial planning and analysis (FP&A) research. An initial proof of concept showed a reduction of up to 30 percent in time spent on research. Some companies are already actively educating their organizations, especially leadership, about gen AI, the capabilities it unlocks, and its applications in business. In fact, since the second quarter of 2023, almost all CPGs we analyzed have had an immersion session on AI for C-level executives. Creating value beyond the hype 2. Are leaders from the business side actively part of the transformation? CPG companies often underestimate the role of business functions in a successful digital and AI transformation, relegating the initiative to IT. Case in point: At a large food manufacturer, the supply chain domain was one of the company’s most successful domains, in part because the leadership, including the COO and CFO, made supply chain a priority. The business dedicated a senior director as product owner for not only the build but also rollout and adoption, and these business leaders joined biweekly sprint reviews, engaging with the supply chain digital leader and the working team in designing a completely new way to optimize customer service. Top business talent should act as product owners of the transformation for their given product, working closely with technology leaders to define the road map of solutions, managing the pipeline of use cases to build the solution, influencing technology infrastructure decisions, governing data, and being the voice of the transformation to their wider teams. The core operational unit is the agile “squad.” Comprised generally of five to eight people across business, data, technology, and design functions, these teams are responsible for building the solutions on the road map (Exhibit 4). They are crucial for scaling. Acting autonomously based on clear guidelines, these agile squads are the only way companies can enable hundreds or even thousands of teams to deliver transformational change. 3. Are you an attractive long-term employer for digital talent? Without top in-house technical talent, CPG companies will struggle with their transformation. Having a hiring strategy and competitive compensation will only get you so far in attracting and retaining digital talent, especially when you are competing with digital natives. The core issue is that work at CPG companies often doesn’t attract top tech talent. Companies will need to offer meaningful missions, learning opportunities, and an environment where tech talent can thrive. A good place to start is upskilling leaders to better understand how tech creates value. P&G instituted a reverse-mentoring program in which junior tech people worked with senior leaders to help them understand how to use tech. 7 “How P&G’s 4D culture helps with successful digital transformation,” Human Resources Online, May 12, 2020. Leaders also went to leading digital businesses to observe operations and speak with leaders to understand what skills are important to bring into an organization. It’s important to focus on hiring talent with some proficiency in relevant areas. Competent developers are significantly more productive than inexperienced ones, and that trend carries over into gen AI as well . 8 “ The economic potential of generative AI ,” June 14, 2023. To find the right talent, CPGs should look to suppliers or retailers who are already progressing on their digital journey. Adjacent sectors such as hospitality and telecom can also be sources of expert talent with broader skills that are transferable to CPG companies. Offering promotions and compensation based on skills mastery and establishing engineering-specific career tracks can also help in retaining your top people. A large beverage CPG knew it needed to upgrade its talent if it wanted its digital and AI transformation to succeed. But established recruiting practices were slow and not geared to the leading technical talent the business needed. A talent win room came together with a new plan. First, they invested in developing clear new role descriptions, tailored to the specific skills required. Second, they focused on identifying new recruiting sources rather than turning to more general jobs and networking venues. Third, they sped up the evaluation process with coding tests, which allowed them to quickly narrow down more than 7,500 initial applicants to high-potential candidates. And fourth, they put in place batch days organized around the full set of decision makers, which allowed them to make decisions on candidates and extend an offer within 24 hours. Over this time, the talent win room had a set of KPIs that they referred to often to track their progress and correct any issues quickly. In 90 days, they were able to fill the 25 critical digital and analytics roles they needed—a tenfold increase in the speed of hiring. 4. Are you deploying your technology investments to optimize for reuse? Many CPG companies have key elements of a core infrastructure in place—such as cloud, data lakes, and planning software—but they are often not set up to operate at scale. This situation is largely the result of a complex tech stack where systems are built to support a specific function or market. This makes it challenging to share data and reuse solutions, leading to costly replication of applications and difficulty in scaling. Enabling solutions that serve multiple domains has significant benefits, such as allowing a company to use a broader range of data to make better revenue growth management (RGM) decisions. Getting to this state requires companies to develop a modular architecture (Exhibit 5). For this approach to work in practice, companies need a global strategy and a team made up of experts from central IT (including enterprise architects, cloud developers, and engineers) and leaders from target markets to design the system together. They should focus on creating modules to support three to five market archetypes (for example, hypermarkets in the United States and more-traditional trade stores in Latin America), develop a road map for building them, and then test them in the market. Typically, this process includes making key decisions, such as what domain tools to deploy, what cloud infrastructure to develop, and whether to build or buy specific technologies. Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI 5. Are you developing data products? Data in the CPG industry is notoriously fragmented across retailers, distributors, consumers, syndicated data providers, marketing platforms, contract manufacturers, third-party logistics providers, and more. This issue has become even more acute with generative AI, with the introduction of huge amounts of unstructured data. Without a centralized, well-coordinated data strategy, teams end up using raw data for their one-off needs, wasting data scientist and engineering capacity on creating inconsistent data sets that can’t be accessed by other teams or systems. To redress this issue, companies need to focus on three things: A global CPG was able to rapidly transform its RGM domain end-to-end in just two years by building modular technology components that enabled it to scale solutions across its more than 30 category/market combinations. Instead of building pricing and promotions analytics around the data available for a particular region/category, for example, the company built a standardized RGM data product that teams could easily use. Each market category only had to input its own data into the product to take advantage of the underlying analytics engine. Because the data product was modular, specific local factors, such as currencies and units of measure, could easily be swapped in. 6. Are you anticipating and preparing for the most critical scaling challenges? The fragmentation in CPG companies—accounts, categories, brands, geographies, and functions—makes adoption and scaling technology challenging. Too often, companies have to redo a lot of work to tailor solutions to local environments. While the adoption of technology relies on many factors, in practice it is most crucial to involve potential future users early in solutions development; give end users incentives to use the technology; minimize the effort required of them, by building solutions into existing tools, for example; and track their uptake over time. The key to tackling scaling is to “assetize” solutions by packaging them as modular assets that teams can easily reuse. The focus should be on technologies, such as APIs; processes, such as solution rollouts, operational guidelines, and training; and support, such as subject-matter experts who understand how to deploy the solution and adapt it to different environments. A digital and AI transformation is a complex journey. But for CPG companies willing to make the commitment to change at scale, the value can be transformative and a competitive necessity. Abdul Wahab Shaikh is a partner in McKinsey’s Atlanta office, Shruti Lal is a partner in the Chicago office, Hannah Mayer is an associate partner in the Bay Area office, and Spurthi Gummadala is a consultant in the Seattle office. The authors wish to thank Roger Roberts for his contributions to this article. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles Rewired and running ahead: Digital and AI leaders are leaving the rest behind Rewired to outcompete A generative AI reset: Rewiring to turn potential into value in 2024', 'summary': 'Consumer packaged goods (CPG) companies are struggling to leverage digital and AI effectively, often stuck in pilot phases. To succeed, they must prioritize value areas, involve business leaders, attract digital talent, optimize technology investments, develop cohesive data strategies, and'}
2024-08-20 02:06:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/industries/healthcare/our-insights/generative-ai-in-healthcare-adoption-trends-and-whats-next> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:06:26 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nGenerative AI in healthcare: Adoption trends and what’s next The transformative power of generative AI (gen AI) will likely reshape the healthcare industry over time, and organizations are beginning to take action. In our Q1 2024 survey, more than 70 percent of respondents from healthcare organizations—including payers, providers, and healthcare services and technology (HST) groups—say that they are pursuing or have already implemented gen AI capabilities (see sidebar, “Research methodology”). Research methodology To better understand how healthcare organizations are thinking about generative AI (gen AI) use, McKinsey launched a research effort to gather insights from leaders in payer, provider, and healthcare services and technology (HST) groups. We surveyed US healthcare stakeholders about a number of topics, including their plans to use gen AI solutions, how they expect to adopt gen AI tools, their ROI measurements, their expectations for areas that will benefit the most from gen AI, and the roadblocks to scaling gen AI. These surveys are not meant to be a comprehensive or an exhaustive view of all healthcare stakeholders or to predict their actions in the future. Instead, the surveys are meant to provide early insights into the potential of gen AI. The most recent survey included 100 respondents and was in the field for one week during March 2024. Among respondents, 33 percent were C-level executives, and 31 percent belonged to organizations with greater than $10 billion in revenue. The first survey was fielded during one week in December 2023 and included leaders from 40 payers, 40 provider organizations, and 20 HST companies. The Q1 2024 survey, which included 100 US healthcare leaders, was conducted in March and comes after the Q4 2023 survey of 100 US leaders, which was conducted in December 2023. As we look at the responses across these populations in both surveys, a few themes emerge. Integration and intentions In the Q1 2024 survey, a majority of respondents say that their organizations are either already using gen AI tools or are testing them out. Most of the surveyed respondents are in the proof-of-concept stage with gen AI, as stakeholders contemplate trade-offs among returns, risks, strategic priorities, governance, maturity, and other factors. Yet despite the industry’s general interest in using AI, there is still a consistent portion of respondents without any plans to pursue gen AI or who are maintaining a wait-and-see approach. Partner or pioneer Among those surveyed who are implementing gen AI, 59 percent are already partnering with third-party vendors to develop customized solutions, and 24 percent report plans to build solutions in-house, while only 17 percent expect to buy off-the-shelf gen AI products. Among those who haven’t yet implemented gen AI, 41 percent say they intend to buy gen AI products, which may be driven by this population’s concerns with risk (57 percent are not pursuing gen AI, because of risk considerations) and technology needs (29 percent). The ROI for gen AI As with any investment, it’s critical for stakeholders to be able to realize the value that gen AI promises. A measurable positive impact serves as strong reinforcement for continued and expanded use and investment. While the number of respondents who have implemented gen AI is small, among those who have, most have not yet calculated the ROI or are waiting on measurable results. But about 60 percent of those who have implemented gen AI solutions are either already seeing a positive ROI or expect to. Gen AI’s vast scope Gen AI may create tremendous value in areas that could fundamentally improve patient experience and streamline operations. Specifically, clinician and clinical productivity is viewed by most respondents as an area where gen AI may have the highest value. Furthermore, expectations for gen AI’s potential in applications to improve patient and member engagement and experience, administrative efficiency and effectiveness, and quality of care and delivery indicate a diffusion of gen AI interest beyond clinical uses into areas that improve overall patient care interactions. Hurdles to scale up Risk concerns and considerations top the list of scale-up challenges faced by surveyed leaders, regardless of whether they work at a payer, provider, or HST company. This is likely due to the untested nature of the technology, the investment needed to build capabilities, and uncertainty around regulations. It signals the importance of governance and mitigation strategies to tackle the range of risk issues—from privacy to clinical outcomes—to ensure regulatory compliance and excellence in care. After risks, the next most prevalent roadblocks indicated by respondents are insufficient capability, data and tech infrastructure, and proof of value. This demonstrates healthcare organizations’ limited tech readiness to deploy gen AI solutions and also to validate its capabilities. After gen AI entered the global stage at the end of 2022, we now see the healthcare industry more actively considering its strategy for using this technology. While these surveys are small and do not represent an exhaustive view of all healthcare stakeholders, they are meant to provide early insights into gen AI’s potential. As the survey results show, many healthcare leaders have begun pursuing plans to more broadly adopt the technology, which has in part been enabled by strategic partnerships . Given the complexities regarding technical implementation and integration across a business, cross-functional collaborations allow organizations to bring in outside talent while taking advantage of building flexible and customizable gen AI solutions, compared with buying off-the-shelf solutions. Yet depending on an organization’s tech maturity or how straightforward a use case is, buying publicly available gen AI products may offer a viable alternative to tap into the technology’s value proposition. Direct purchases may make sense, particularly for functional uses that have matured faster, such as for customer service applications. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. As gen AI deployment progresses, many surveyed leaders share that their organizations are focused on initially using this technology to support clinically adjacent applications, with clinical and administrative efficiency and patient/member engagement surfacing as areas believed to gain the most from gen AI. However, as organizations develop strong competencies in governance and risk management, we expect additional focus on core clinical applications as well, further improving the overall patient/member experience. Despite gen AI’s promise, the path to responsible usage is not without its hurdles . Risks such as inaccurate outputs and biases are particularly critical in healthcare when dealing with patients . As organizations introduce this new technology into workflows, AI risks seem to be top of mind for many surveyed healthcare leaders. Risks will need to be proactively mitigated, which starts with a concerted focus on establishing governance processes, frameworks, and guardrails to anticipate, identify, and manage risks. By doing so, healthcare organizations can use gen AI to help ensure that benefits are realized in line with regulatory expectations without compromising ethics or safety. Jessica Lamb is a partner in McKinsey’s New York office; Greg Israelstam is a consultant in the Chicago office, where Shashank Bhasker is an expert associate partner; and Rahul Agarwal is a senior expert in the New Jersey office. The authors wish to thank Anna Dirksen, Valen Piotrowski, and Xuan Chai for their contributions to this article. This article was edited by Querida Anderson, a senior editor in the New York office. Explore a career with us Related Articles Public health’s inflection point with generative AI The AI opportunity: How payers can capture it now Tackling healthcare’s biggest burdens with generative AI'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:06:26 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:06:26 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:06:26 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:06:26 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:06:26 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:06:26 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:06:27 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:06:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'197770'), (b'x-ratelimit-reset-requests', b'2m3.276s'), (b'x-ratelimit-reset-tokens', b'669ms'), (b'x-request-id', b'req_9b148552ab8993e6ae91231cad822f6b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608a6de96d6071-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:06:27 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:06:27 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:06:27 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:06:27 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:06:27 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:06:27 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:06:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '553', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '197770', 'x-ratelimit-reset-requests': '2m3.276s', 'x-ratelimit-reset-tokens': '669ms', 'x-request-id': 'req_9b148552ab8993e6ae91231cad822f6b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608a6de96d6071-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:06:27 [openai._base_client] DEBUG: request_id: req_9b148552ab8993e6ae91231cad822f6b
2024-08-20 02:06:27 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Over 70% of healthcare organizations are pursuing generative AI (gen AI) solutions, with many in the proof-of-concept stage. Key areas for improvement include clinician productivity and patient engagement. However, concerns about risks, technology readiness, and ROI
2024-08-20 02:06:27 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:06:27 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 2.15 seconds...
2024-08-20 02:06:29 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:06:29 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 4.55 seconds...
2024-08-20 02:06:34 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:06:34 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:06:34 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 2.17 seconds...
2024-08-20 02:06:36 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:06:36 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 4.10 seconds...
2024-08-20 02:06:40 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:06:40 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 8.51 seconds...
2024-08-20 02:06:49 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:06:49 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 16.03 seconds...
2024-08-20 02:07:05 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 429 None
2024-08-20 02:07:05 [mckinsey_capabilities_digital_insights] WARNING: Rate limit exceeded, retrying in 32.00 seconds...
2024-08-20 02:07:37 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:37 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:37 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:37 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A5%3AG5 HTTP/11" 200 None
2024-08-20 02:07:37 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A5%3AG5?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/industries/healthcare/our-insights/generative-ai-in-healthcare-adoption-trends-and-whats-next>
{'title': 'Generative AI in healthcare: Adoption trends and what’s next', 'description': 'Surveyed healthcare leaders say their organizations are eager to use generative AI to help enhance how healthcare stakeholders work and operate, but some are still adopting a wait-and-see approach.', 'url': 'https://www.mckinsey.com/industries/healthcare/our-insights/generative-ai-in-healthcare-adoption-trends-and-whats-next', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/industries/healthcare%20systems%20and%20services/our%20insights/generative%20ai%20in%20healthcare%20adoption%20trends%20and%20whats%20next/generative-ai-in-healthcare-845813466-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-07-25T12:00:00Z', 'article_text': 'Generative AI in healthcare: Adoption trends and what’s next The transformative power of generative AI (gen AI) will likely reshape the healthcare industry over time, and organizations are beginning to take action. In our Q1 2024 survey, more than 70 percent of respondents from healthcare organizations—including payers, providers, and healthcare services and technology (HST) groups—say that they are pursuing or have already implemented gen AI capabilities (see sidebar, “Research methodology”). Research methodology To better understand how healthcare organizations are thinking about generative AI (gen AI) use, McKinsey launched a research effort to gather insights from leaders in payer, provider, and healthcare services and technology (HST) groups. We surveyed US healthcare stakeholders about a number of topics, including their plans to use gen AI solutions, how they expect to adopt gen AI tools, their ROI measurements, their expectations for areas that will benefit the most from gen AI, and the roadblocks to scaling gen AI. These surveys are not meant to be a comprehensive or an exhaustive view of all healthcare stakeholders or to predict their actions in the future. Instead, the surveys are meant to provide early insights into the potential of gen AI. The most recent survey included 100 respondents and was in the field for one week during March 2024. Among respondents, 33 percent were C-level executives, and 31 percent belonged to organizations with greater than $10 billion in revenue. The first survey was fielded during one week in December 2023 and included leaders from 40 payers, 40 provider organizations, and 20 HST companies. The Q1 2024 survey, which included 100 US healthcare leaders, was conducted in March and comes after the Q4 2023 survey of 100 US leaders, which was conducted in December 2023. As we look at the responses across these populations in both surveys, a few themes emerge. Integration and intentions In the Q1 2024 survey, a majority of respondents say that their organizations are either already using gen AI tools or are testing them out. Most of the surveyed respondents are in the proof-of-concept stage with gen AI, as stakeholders contemplate trade-offs among returns, risks, strategic priorities, governance, maturity, and other factors. Yet despite the industry’s general interest in using AI, there is still a consistent portion of respondents without any plans to pursue gen AI or who are maintaining a wait-and-see approach. Partner or pioneer Among those surveyed who are implementing gen AI, 59 percent are already partnering with third-party vendors to develop customized solutions, and 24 percent report plans to build solutions in-house, while only 17 percent expect to buy off-the-shelf gen AI products. Among those who haven’t yet implemented gen AI, 41 percent say they intend to buy gen AI products, which may be driven by this population’s concerns with risk (57 percent are not pursuing gen AI, because of risk considerations) and technology needs (29 percent). The ROI for gen AI As with any investment, it’s critical for stakeholders to be able to realize the value that gen AI promises. A measurable positive impact serves as strong reinforcement for continued and expanded use and investment. While the number of respondents who have implemented gen AI is small, among those who have, most have not yet calculated the ROI or are waiting on measurable results. But about 60 percent of those who have implemented gen AI solutions are either already seeing a positive ROI or expect to. Gen AI’s vast scope Gen AI may create tremendous value in areas that could fundamentally improve patient experience and streamline operations. Specifically, clinician and clinical productivity is viewed by most respondents as an area where gen AI may have the highest value. Furthermore, expectations for gen AI’s potential in applications to improve patient and member engagement and experience, administrative efficiency and effectiveness, and quality of care and delivery indicate a diffusion of gen AI interest beyond clinical uses into areas that improve overall patient care interactions. Hurdles to scale up Risk concerns and considerations top the list of scale-up challenges faced by surveyed leaders, regardless of whether they work at a payer, provider, or HST company. This is likely due to the untested nature of the technology, the investment needed to build capabilities, and uncertainty around regulations. It signals the importance of governance and mitigation strategies to tackle the range of risk issues—from privacy to clinical outcomes—to ensure regulatory compliance and excellence in care. After risks, the next most prevalent roadblocks indicated by respondents are insufficient capability, data and tech infrastructure, and proof of value. This demonstrates healthcare organizations’ limited tech readiness to deploy gen AI solutions and also to validate its capabilities. After gen AI entered the global stage at the end of 2022, we now see the healthcare industry more actively considering its strategy for using this technology. While these surveys are small and do not represent an exhaustive view of all healthcare stakeholders, they are meant to provide early insights into gen AI’s potential. As the survey results show, many healthcare leaders have begun pursuing plans to more broadly adopt the technology, which has in part been enabled by strategic partnerships . Given the complexities regarding technical implementation and integration across a business, cross-functional collaborations allow organizations to bring in outside talent while taking advantage of building flexible and customizable gen AI solutions, compared with buying off-the-shelf solutions. Yet depending on an organization’s tech maturity or how straightforward a use case is, buying publicly available gen AI products may offer a viable alternative to tap into the technology’s value proposition. Direct purchases may make sense, particularly for functional uses that have matured faster, such as for customer service applications. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. As gen AI deployment progresses, many surveyed leaders share that their organizations are focused on initially using this technology to support clinically adjacent applications, with clinical and administrative efficiency and patient/member engagement surfacing as areas believed to gain the most from gen AI. However, as organizations develop strong competencies in governance and risk management, we expect additional focus on core clinical applications as well, further improving the overall patient/member experience. Despite gen AI’s promise, the path to responsible usage is not without its hurdles . Risks such as inaccurate outputs and biases are particularly critical in healthcare when dealing with patients . As organizations introduce this new technology into workflows, AI risks seem to be top of mind for many surveyed healthcare leaders. Risks will need to be proactively mitigated, which starts with a concerted focus on establishing governance processes, frameworks, and guardrails to anticipate, identify, and manage risks. By doing so, healthcare organizations can use gen AI to help ensure that benefits are realized in line with regulatory expectations without compromising ethics or safety. Jessica Lamb is a partner in McKinsey’s New York office; Greg Israelstam is a consultant in the Chicago office, where Shashank Bhasker is an expert associate partner; and Rahul Agarwal is a senior expert in the New Jersey office. The authors wish to thank Anna Dirksen, Valen Piotrowski, and Xuan Chai for their contributions to this article. This article was edited by Querida Anderson, a senior editor in the New York office. Explore a career with us Related Articles Public health’s inflection point with generative AI The AI opportunity: How payers can capture it now Tackling healthcare’s biggest burdens with generative AI', 'summary': 'Over 70% of healthcare organizations are pursuing generative AI (gen AI) solutions, with many in the proof-of-concept stage. Key areas for improvement include clinician productivity and patient engagement. However, concerns about risks, technology readiness, and ROI'}
2024-08-20 02:07:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 4 items (at 4 items/min)
2024-08-20 02:07:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-big-product-and-platform-shift-five-actions-to-get-the-transformation-right> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:38 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nThe big product and platform shift: Five actions to get the transformation right Many incumbent organizations across industries and sectors want to become more like tech companies: fast, agile, and dominant. They’re doing so to remain competitive at a time when B2B and B2C customers have high and rapidly changing expectations and digital disruptors are upending the business landscape. About the authors This article is a collaborative effort by Rushabh Gala, Naufal Khan , Ling Lau , Gautam Lunawat , and Anindita Pal, representing views from McKinsey Digital. The key to making this change lies in adopting a technology operating model based on products and platforms . This model organizes technology around user-facing products, to facilitate end-user journeys or experiences (ordering, bill paying, and loyalty programs, for example), and the underlying platforms that enable them, such as customer relationship management (CRM) and marketing technology (MarTech). The benefits of this product and platform model have been well established. The product and platform model ensures that technology delivery is aligned to the strategy and related priorities. In our experience, it can generate significant business value, spur innovation, improve customer and employee experience, decrease time to market by up to three times, reduce product defects by 50 to 70 percent, improve brand and image perception, and increase operating margins and total shareholder returns. A recent McKinsey survey revealed that at nearly three-quarters of top-performing companies, the most-senior tech leaders are highly involved in shaping company strategy. 1 “ Prioritizing technology transformations to win ,” McKinsey, March 24, 2022. About our Operating Model Index The impact of shifts in the operating model on an organization’s performance has been studied and quantified in our Operating Model Index research. The research gathers insights from more than 400 organizations across industries and analyzes the correlation between operating model maturity and business outcomes, such as innovation, operating margin, total returns to shareholders, brand and image perception, and customer engagement. We will review the results and their implications for organizations in our upcoming article series. The issue, however, is that many companies that want to develop a product and platform model struggle to do so. We analyzed more than 50 organizations across industries and geographies undergoing product and platform operating model transformations. (See sidebar “About our Operating Model Index.”) Although a few companies have met or exceeded their objectives, the efforts of a significant number either have stalled (for various reasons) or were unable to scale following initial progress. What do the few get right that eludes the many? Our analysis revealed five actions that are critical for transitioning successfully to a product and platform operating model: getting the design of products right, prioritizing platform redesign, partnering with the business, rethinking tech governance, and transforming software engineering practices. 1. Build product teams around the end-user experience In a product and platform operating model, “products” are the technology-enabled offerings—tools, services, or experiences—that allow customers and employees to engage in activities that create value. These might include “search” for a retailer, for example, or “financial planning and analysis” for a finance team. These products can be grouped around a variety of organizing principles, each with a specific team to serve the needs of the end user, deliver on the goals of the business, and align with the organization’s market position or digital maturity. For example, a market leader whose main concern is providing an omnichannel experience will set up multidisciplinary teams organized around products, such as ordering, and provide these products through multiple channels. Platform teams provide and maintain services that product teams consume (such as CRM and authentication). An effective organizational approach has often been to build product teams around stages of the customer experience surrounding a purchase, from search to payment, or adjacent capabilities, such as loyalty programs or billing functions. Teams might also be organized around the employee experience, from recruitment to onboarding. In these approaches, the emphasis is on models that can be broadly applied and reused. Key considerations when creating product teams There are a number of questions that leaders should ask themselves when setting up their product teams: Each product team will have a mission and be accountable for business outcomes. The teams must be small enough to be effective, yet contain all the cross-functional skills required for the team to function autonomously. It is critical to keep the number of teams manageable. Too many can strain resources while blurring accountability and adding bureaucracy. (See sidebar “Key considerations when creating product teams.”) A global telco ran into several challenges when it rolled out its digital transformation prior to shifting to a product and platform design for its entire organization. In some product areas (such as promotions and trade-in), multiple business leaders claimed ownership of the same part of the design, and IT struggled to staff and resource them all. This led to a need for increased coordination, which affected the company’s ability to prioritize work and capture value from the transformation. Eventually, the telco paused the scale-up, designed a full product and platform model that addressed skill needs and talent allocations, aligned all stakeholders, and ensured the business assigned a single owner to each product. Only then did it resume scaling the transformation. Would you like to learn more about McKinsey Technology ? 2. Don’t forget the platforms When embarking on the transformation, companies often assume that simply reorganizing around products will be sufficient. That is rarely the case; indeed, it often results in greater technical debt . Platform teams focus on making a company’s core systems more accessible, reusable, and better able to support products. Platforms develop and manage the underlying core systems (such as identity and access management and order management) and backbone (such as storage, aggregation, analysis, and provision of data) on which products are built. Products consume the services that platforms develop through APIs and microservices. When designing and operationalizing platforms, companies should focus on three elements: Invest time in equipping your people for the change A key for scaling this operating model transformation is building the necessary new capabilities to ensure that everyone is on the same page and understands the role they play in the transformation. A global telco, for instance, created large-scale academies to train more than 1,000 employees with key product roles on product, agile, and DevOps concepts. The company first focused on pilot participants before scaling to the entire organization. It also designed and developed new career paths, incentives, and performance-management systems to support the effort. A well-defined product and platform design can function as the de facto organizational structure (Exhibit 1). Our experience suggests that, since strategic priorities shift from year to year, organizations can anticipate that the design of their products and platforms may also shift by 10 to 15 percent in order to align with strategy. (See sidebar “Invest time in equipping your people for the change.”) The approach to developing a platform capability can vary. An Asia-based bank created large platform teams across business units and geographies with joint business and technology leadership and accountability. Their efforts included developing persistent resourcing, shared performance objectives, and dedicated business processes and technical assets. This approach sped up platform modernization and rapidly increased the autonomy of product teams. A global retailer, on the other hand, had the product and platform groups working together, because the architecture was highly coupled in a few core systems, such as e-commerce platforms. The product and platform leaders committed to working together to modernize the platforms and eventually make them consumable via APIs. 3. Reinvent tech funding to make product and platform teams autonomous Providing product and platform teams with reasonable autonomy requires a flexible but disciplined governance model. The first step is to define accountability to manage demand across different products. For example, all product enhancements and ideas for new features should flow to the leader of the respective product category or senior product owner, who oversees multiple product teams and helps with decisions on prioritization and resource allocation. That person regularly (perhaps quarterly) updates a central portfolio team to provide transparency on progress. This approach decentralizes decision making, eliminates duplicate responsibilities in the organization, and nourishes a collaborative and outcome-based culture. This shift begins by funding product areas so that each product and platform leader has the autonomy to make and adjust funding decisions for their teams. Product leaders should have a single prioritized backlog (building features, fixing errors, remediating technical debt) and secure capital and operating expenditures to keep consistent product teams in place. Functions such as design and agile coaching are often funded through earmarked operating budgets. The quid pro quo of providing more autonomy to product and platform teams is that the teams commit to clear OKRs linked to outcomes and aligned with the goals of the company. Organizations using OKRs to track progress and dynamically reallocate investments based on performance increase financial accountability, improve control of end-to-end product expenses, and can ultimately capture more value. We have seen organizations using this approach reduce the time required for annual budgeting by more than 60 percent and the time spent on management reporting by 20 to 30 percent. At most companies today, some areas—especially for large existing programs—may maintain project-oriented governance for one to two years, while other areas (such as customer journeys) can move more quickly to product-based governance. It is important to be disciplined in finding the right balance while maintaining progress. Products and platforms: Is your technology operating model ready? 4. Establish joint accountability between tech and the business The main goal of a product and platform transformation is to generate the biggest impact for the business. That requires the IT function to work much more closely with the business and include all functional stakeholders—sales, marketing, supply chain, and customer service. A clear baseline of existing capabilities and a clear blueprint for progress are useful artifacts for aligning tech with the business. From there, companies can establish a mechanism to sustain business involvement in the transformation. That can come from ensuring that a business leader joins each product team, sometimes as the product owner; has a guidance role on platform teams; and shares joint accountability with corresponding tech leads for delivering on the OKRs. Where broad business support for the product and platform transformation exists, a larger scale-up of the operating model and structural changes to it can happen relatively quickly. In other cases, however, initial business champions and early adopters should launch a few teams to start. Even a small group that quickly demonstrates business value can have a big impact on building support in the business, including for more substantial structural changes (Exhibit 2). A regional bank and a global retailer both opted to use a two-in-a-box model, in which a business leader and a tech leader jointly led a product team. This established clear joint accountability for business and technology performance objectives. This model helped the bank and the retailer develop the confidence to push decision making down to the product team level. Another global retailer, meanwhile, took a slightly different approach, opting for a three-in-a-box model that embedded product, design, and engineering leadership in each team. The company replicates this triad at every level (product group, product, team) to ensure that the right capabilities and effective decision making are available at every stage of the journey. 5. Commit to creating a great developer experience Committing to engineering excellence is about more than hiring great engineers. It’s about creating an environment where engineers can thrive by doing work of the highest value, using advanced tools and relying on automation across software development to reduce toil. At its root, this commitment to creating an advanced engineering environment is about focusing on the developer experience . Advanced tooling includes providing on-demand access to self-service environments for testing, a fully automated and secure continuous integration/continuous delivery (CI/CD) pipeline (feature flag of issues, canary release techniques, and zero downtime), and automated life cycle management that makes it easy to observe and trace issues so teams can rapidly address them. Delivering on these capabilities requires a commitment to decoupled architecture, automating security and integrating it into the development process ( DevSecOps ), and tracking the performance of engineering modernization initiatives. These measures enable developers to seamlessly spin up a platform in minutes, easily consume platform services with multiple consumption models (APIs or GitOps), and rapidly make improvements to platforms through an open-source approach (aka InnerSource) to manage code contribution. Creating this kind of work environment requires a commensurate shift in the work that engineers do. Companies should consider allocating 10 to 30 percent of developer capacity to building new engineering and automation capabilities and upgrading skills through tailored learning programs. These capabilities are essential not only to retaining top engineers but also to enabling product and platform teams to rapidly develop quality software. A global telco invested in the developer experience by setting up an enterprise-wide DevSecOps program that ran in lockstep with the product-model transformation. The program had five key pillars: a modern decoupled architecture, CI/CD practices, operational resiliency, security integrated into development, and tech delivery linked to business outcomes. The company supplemented the program by rolling out a central measurement platform to assess both the maturity and adoption of modern engineering practices through a real-time dashboard. The DevSecOps program ran in parallel with an aggressive migration to the public cloud. The program increased innovation, speed, the reliability and quality of code, and cost savings. Transitioning to a product and platform operating model is no small undertaking. But by taking the five actions outlined in this article, organizations can put themselves in a stronger position to capitalize on the benefits of this operating model—not only spurring innovation and developing better products faster but also improving customer experience and increasing total shareholder returns. It’s an effort worth getting right the first time. Rushabh Gala is an associate partner in McKinsey’s Chicago office, where Naufal Khan is a senior partner and Anindita Pal is a consultant; Ling Lau is a partner in the New Jersey office; and Gautam Lunawat is a partner in the Bay Area office. The authors wish to thank Stephane Bout, Leorizio D'Aversa, Nicolas de la Flor, Martin Harrysson, James Kaplan, Eric Lamarre, Megha Sinha, Phil Tuddenham, and Belkis Vasquez-McCall for their contributions to this article. Explore a career with us Related Articles The ERP platform play: Cheaper, faster, better The Tech: Forward recipe for a successful technology transformation The platform play: How to operate like a tech company"}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:38 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:38 [httpcore.connection] DEBUG: close.started
2024-08-20 02:07:38 [httpcore.connection] DEBUG: close.complete
2024-08-20 02:07:38 [httpcore.connection] DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-20 02:07:38 [httpcore.connection] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D625FADD0>
2024-08-20 02:07:38 [httpcore.connection] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020D6259DA30> server_hostname='api.openai.com' timeout=5.0
2024-08-20 02:07:38 [httpcore.connection] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D625F9210>
2024-08-20 02:07:38 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:38 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:38 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:38 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:38 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:39 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'1207'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'195817'), (b'x-ratelimit-reset-requests', b'59.643s'), (b'x-ratelimit-reset-tokens', b'1.254s'), (b'x-request-id', b'req_b5bf07c2985d25d79245f224cc17680b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c31cec71131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:39 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:39 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:39 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:39 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:39 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:39 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '1207', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '195817', 'x-ratelimit-reset-requests': '59.643s', 'x-ratelimit-reset-tokens': '1.254s', 'x-request-id': 'req_b5bf07c2985d25d79245f224cc17680b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c31cec71131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:39 [openai._base_client] DEBUG: request_id: req_b5bf07c2985d25d79245f224cc17680b
2024-08-20 02:07:39 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Incumbent organizations are shifting towards a product and platform operating model to enhance agility and competitiveness. To succeed, they should focus on five key actions: designing effective product teams, prioritizing platform redesign, reinforcing tech-business collaboration, rethinking tech governance,
2024-08-20 02:07:39 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:40 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:40 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:40 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:40 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A6%3AG6 HTTP/11" 200 None
2024-08-20 02:07:40 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A6%3AG6?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-big-product-and-platform-shift-five-actions-to-get-the-transformation-right>
{'title': 'The big product and platform shift: Five actions to get the transformation right', 'description': 'To succeed, incumbent organizations need to take five actions as they scale their product and platform model transformations.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-big-product-and-platform-shift-five-actions-to-get-the-transformation-right', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20big%20product%20and%20platform%20shift%20five%20actions%20transformation/thumb-gettyimages-509278849.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2023-06-09T12:00:00Z', 'article_text': "The big product and platform shift: Five actions to get the transformation right Many incumbent organizations across industries and sectors want to become more like tech companies: fast, agile, and dominant. They’re doing so to remain competitive at a time when B2B and B2C customers have high and rapidly changing expectations and digital disruptors are upending the business landscape. About the authors This article is a collaborative effort by Rushabh Gala, Naufal Khan , Ling Lau , Gautam Lunawat , and Anindita Pal, representing views from McKinsey Digital. The key to making this change lies in adopting a technology operating model based on products and platforms . This model organizes technology around user-facing products, to facilitate end-user journeys or experiences (ordering, bill paying, and loyalty programs, for example), and the underlying platforms that enable them, such as customer relationship management (CRM) and marketing technology (MarTech). The benefits of this product and platform model have been well established. The product and platform model ensures that technology delivery is aligned to the strategy and related priorities. In our experience, it can generate significant business value, spur innovation, improve customer and employee experience, decrease time to market by up to three times, reduce product defects by 50 to 70 percent, improve brand and image perception, and increase operating margins and total shareholder returns. A recent McKinsey survey revealed that at nearly three-quarters of top-performing companies, the most-senior tech leaders are highly involved in shaping company strategy. 1 “ Prioritizing technology transformations to win ,” McKinsey, March 24, 2022. About our Operating Model Index The impact of shifts in the operating model on an organization’s performance has been studied and quantified in our Operating Model Index research. The research gathers insights from more than 400 organizations across industries and analyzes the correlation between operating model maturity and business outcomes, such as innovation, operating margin, total returns to shareholders, brand and image perception, and customer engagement. We will review the results and their implications for organizations in our upcoming article series. The issue, however, is that many companies that want to develop a product and platform model struggle to do so. We analyzed more than 50 organizations across industries and geographies undergoing product and platform operating model transformations. (See sidebar “About our Operating Model Index.”) Although a few companies have met or exceeded their objectives, the efforts of a significant number either have stalled (for various reasons) or were unable to scale following initial progress. What do the few get right that eludes the many? Our analysis revealed five actions that are critical for transitioning successfully to a product and platform operating model: getting the design of products right, prioritizing platform redesign, partnering with the business, rethinking tech governance, and transforming software engineering practices. 1. Build product teams around the end-user experience In a product and platform operating model, “products” are the technology-enabled offerings—tools, services, or experiences—that allow customers and employees to engage in activities that create value. These might include “search” for a retailer, for example, or “financial planning and analysis” for a finance team. These products can be grouped around a variety of organizing principles, each with a specific team to serve the needs of the end user, deliver on the goals of the business, and align with the organization’s market position or digital maturity. For example, a market leader whose main concern is providing an omnichannel experience will set up multidisciplinary teams organized around products, such as ordering, and provide these products through multiple channels. Platform teams provide and maintain services that product teams consume (such as CRM and authentication). An effective organizational approach has often been to build product teams around stages of the customer experience surrounding a purchase, from search to payment, or adjacent capabilities, such as loyalty programs or billing functions. Teams might also be organized around the employee experience, from recruitment to onboarding. In these approaches, the emphasis is on models that can be broadly applied and reused. Key considerations when creating product teams There are a number of questions that leaders should ask themselves when setting up their product teams: Each product team will have a mission and be accountable for business outcomes. The teams must be small enough to be effective, yet contain all the cross-functional skills required for the team to function autonomously. It is critical to keep the number of teams manageable. Too many can strain resources while blurring accountability and adding bureaucracy. (See sidebar “Key considerations when creating product teams.”) A global telco ran into several challenges when it rolled out its digital transformation prior to shifting to a product and platform design for its entire organization. In some product areas (such as promotions and trade-in), multiple business leaders claimed ownership of the same part of the design, and IT struggled to staff and resource them all. This led to a need for increased coordination, which affected the company’s ability to prioritize work and capture value from the transformation. Eventually, the telco paused the scale-up, designed a full product and platform model that addressed skill needs and talent allocations, aligned all stakeholders, and ensured the business assigned a single owner to each product. Only then did it resume scaling the transformation. Would you like to learn more about McKinsey Technology ? 2. Don’t forget the platforms When embarking on the transformation, companies often assume that simply reorganizing around products will be sufficient. That is rarely the case; indeed, it often results in greater technical debt . Platform teams focus on making a company’s core systems more accessible, reusable, and better able to support products. Platforms develop and manage the underlying core systems (such as identity and access management and order management) and backbone (such as storage, aggregation, analysis, and provision of data) on which products are built. Products consume the services that platforms develop through APIs and microservices. When designing and operationalizing platforms, companies should focus on three elements: Invest time in equipping your people for the change A key for scaling this operating model transformation is building the necessary new capabilities to ensure that everyone is on the same page and understands the role they play in the transformation. A global telco, for instance, created large-scale academies to train more than 1,000 employees with key product roles on product, agile, and DevOps concepts. The company first focused on pilot participants before scaling to the entire organization. It also designed and developed new career paths, incentives, and performance-management systems to support the effort. A well-defined product and platform design can function as the de facto organizational structure (Exhibit 1). Our experience suggests that, since strategic priorities shift from year to year, organizations can anticipate that the design of their products and platforms may also shift by 10 to 15 percent in order to align with strategy. (See sidebar “Invest time in equipping your people for the change.”) The approach to developing a platform capability can vary. An Asia-based bank created large platform teams across business units and geographies with joint business and technology leadership and accountability. Their efforts included developing persistent resourcing, shared performance objectives, and dedicated business processes and technical assets. This approach sped up platform modernization and rapidly increased the autonomy of product teams. A global retailer, on the other hand, had the product and platform groups working together, because the architecture was highly coupled in a few core systems, such as e-commerce platforms. The product and platform leaders committed to working together to modernize the platforms and eventually make them consumable via APIs. 3. Reinvent tech funding to make product and platform teams autonomous Providing product and platform teams with reasonable autonomy requires a flexible but disciplined governance model. The first step is to define accountability to manage demand across different products. For example, all product enhancements and ideas for new features should flow to the leader of the respective product category or senior product owner, who oversees multiple product teams and helps with decisions on prioritization and resource allocation. That person regularly (perhaps quarterly) updates a central portfolio team to provide transparency on progress. This approach decentralizes decision making, eliminates duplicate responsibilities in the organization, and nourishes a collaborative and outcome-based culture. This shift begins by funding product areas so that each product and platform leader has the autonomy to make and adjust funding decisions for their teams. Product leaders should have a single prioritized backlog (building features, fixing errors, remediating technical debt) and secure capital and operating expenditures to keep consistent product teams in place. Functions such as design and agile coaching are often funded through earmarked operating budgets. The quid pro quo of providing more autonomy to product and platform teams is that the teams commit to clear OKRs linked to outcomes and aligned with the goals of the company. Organizations using OKRs to track progress and dynamically reallocate investments based on performance increase financial accountability, improve control of end-to-end product expenses, and can ultimately capture more value. We have seen organizations using this approach reduce the time required for annual budgeting by more than 60 percent and the time spent on management reporting by 20 to 30 percent. At most companies today, some areas—especially for large existing programs—may maintain project-oriented governance for one to two years, while other areas (such as customer journeys) can move more quickly to product-based governance. It is important to be disciplined in finding the right balance while maintaining progress. Products and platforms: Is your technology operating model ready? 4. Establish joint accountability between tech and the business The main goal of a product and platform transformation is to generate the biggest impact for the business. That requires the IT function to work much more closely with the business and include all functional stakeholders—sales, marketing, supply chain, and customer service. A clear baseline of existing capabilities and a clear blueprint for progress are useful artifacts for aligning tech with the business. From there, companies can establish a mechanism to sustain business involvement in the transformation. That can come from ensuring that a business leader joins each product team, sometimes as the product owner; has a guidance role on platform teams; and shares joint accountability with corresponding tech leads for delivering on the OKRs. Where broad business support for the product and platform transformation exists, a larger scale-up of the operating model and structural changes to it can happen relatively quickly. In other cases, however, initial business champions and early adopters should launch a few teams to start. Even a small group that quickly demonstrates business value can have a big impact on building support in the business, including for more substantial structural changes (Exhibit 2). A regional bank and a global retailer both opted to use a two-in-a-box model, in which a business leader and a tech leader jointly led a product team. This established clear joint accountability for business and technology performance objectives. This model helped the bank and the retailer develop the confidence to push decision making down to the product team level. Another global retailer, meanwhile, took a slightly different approach, opting for a three-in-a-box model that embedded product, design, and engineering leadership in each team. The company replicates this triad at every level (product group, product, team) to ensure that the right capabilities and effective decision making are available at every stage of the journey. 5. Commit to creating a great developer experience Committing to engineering excellence is about more than hiring great engineers. It’s about creating an environment where engineers can thrive by doing work of the highest value, using advanced tools and relying on automation across software development to reduce toil. At its root, this commitment to creating an advanced engineering environment is about focusing on the developer experience . Advanced tooling includes providing on-demand access to self-service environments for testing, a fully automated and secure continuous integration/continuous delivery (CI/CD) pipeline (feature flag of issues, canary release techniques, and zero downtime), and automated life cycle management that makes it easy to observe and trace issues so teams can rapidly address them. Delivering on these capabilities requires a commitment to decoupled architecture, automating security and integrating it into the development process ( DevSecOps ), and tracking the performance of engineering modernization initiatives. These measures enable developers to seamlessly spin up a platform in minutes, easily consume platform services with multiple consumption models (APIs or GitOps), and rapidly make improvements to platforms through an open-source approach (aka InnerSource) to manage code contribution. Creating this kind of work environment requires a commensurate shift in the work that engineers do. Companies should consider allocating 10 to 30 percent of developer capacity to building new engineering and automation capabilities and upgrading skills through tailored learning programs. These capabilities are essential not only to retaining top engineers but also to enabling product and platform teams to rapidly develop quality software. A global telco invested in the developer experience by setting up an enterprise-wide DevSecOps program that ran in lockstep with the product-model transformation. The program had five key pillars: a modern decoupled architecture, CI/CD practices, operational resiliency, security integrated into development, and tech delivery linked to business outcomes. The company supplemented the program by rolling out a central measurement platform to assess both the maturity and adoption of modern engineering practices through a real-time dashboard. The DevSecOps program ran in parallel with an aggressive migration to the public cloud. The program increased innovation, speed, the reliability and quality of code, and cost savings. Transitioning to a product and platform operating model is no small undertaking. But by taking the five actions outlined in this article, organizations can put themselves in a stronger position to capitalize on the benefits of this operating model—not only spurring innovation and developing better products faster but also improving customer experience and increasing total shareholder returns. It’s an effort worth getting right the first time. Rushabh Gala is an associate partner in McKinsey’s Chicago office, where Naufal Khan is a senior partner and Anindita Pal is a consultant; Ling Lau is a partner in the New Jersey office; and Gautam Lunawat is a partner in the Bay Area office. The authors wish to thank Stephane Bout, Leorizio D'Aversa, Nicolas de la Flor, Martin Harrysson, James Kaplan, Eric Lamarre, Megha Sinha, Phil Tuddenham, and Belkis Vasquez-McCall for their contributions to this article. Explore a career with us Related Articles The ERP platform play: Cheaper, faster, better The Tech: Forward recipe for a successful technology transformation The platform play: How to operate like a tech company", 'summary': 'Incumbent organizations are shifting towards a product and platform operating model to enhance agility and competitiveness. To succeed, they should focus on five key actions: designing effective product teams, prioritizing platform redesign, reinforcing tech-business collaboration, rethinking tech governance,'}
2024-08-20 02:07:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:41 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nThe economic potential of generative AI: The next productivity frontier The economic potential of generative AI: The next productivity frontier AI has permeated our lives incrementally, through everything from the tech powering our smartphones to autonomous-driving features on cars to the tools retailers use to surprise and delight consumers. As a result, its progress has been almost imperceptible. Clear milestones, such as when AlphaGo, an AI-based program developed by DeepMind, defeated a world champion Go player in 2016, were celebrated but then quickly faded from the public’s consciousness. Generative AI applications such as ChatGPT, GitHub Copilot, Stable Diffusion, and others have captured the imagination of people around the world in a way AlphaGo did not, thanks to their broad utility—almost anyone can use them to communicate and create—and preternatural ability to have a conversation with a user. The latest generative AI applications can perform a range of routine tasks, such as the reorganization and classification of data. But it is their ability to write text, compose music, and create digital art that has garnered headlines and persuaded consumers and households to experiment on their own. As a result, a broader set of stakeholders are grappling with generative AI’s impact on business and society but without much context to help them make sense of it. About the authors This article is a collaborative effort by Michael Chui , Eric Hazan , Roger Roberts , Alex Singla , Kate Smaje , Alex Sukharevsky , Lareina Yee , and Rodney Zemmel , representing views from QuantumBlack, AI by McKinsey; McKinsey Digital; the McKinsey Technology Council; the McKinsey Global Institute; and McKinsey’s Growth, Marketing & Sales Practice. The speed at which generative AI technology is developing isn’t making this task any easier. ChatGPT was released in November 2022. Four months later, OpenAI released a new large language model, or LLM, called GPT-4 with markedly improved capabilities. 1 “Introducing ChatGPT,” OpenAI, November 30, 2022; “GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses,” OpenAI, accessed June 1, 2023. Similarly, by May 2023, Anthropic’s generative AI, Claude, was able to process 100,000 tokens of text, equal to about 75,000 words in a minute—the length of the average novel—compared with roughly 9,000 tokens when it was introduced in March 2023. 2 “Introducing Claude,” Anthropic PBC, March 14, 2023; “Introducing 100K Context Windows,” Anthropic PBC, May 11, 2023. And in May 2023, Google announced several new features powered by generative AI, including Search Generative Experience and a new LLM called PaLM 2 that will power its Bard chatbot, among other Google products. 3 Emma Roth, “The nine biggest announcements from Google I/O 2023,” The Verge , May 10, 2023. To grasp what lies ahead requires an understanding of the breakthroughs that have enabled the rise of generative AI, which were decades in the making. For the purposes of this report, we define generative AI as applications typically built using foundation models. These models contain expansive artificial neural networks inspired by the billions of neurons connected in the human brain. Foundation models are part of what is called deep learning, a term that alludes to the many deep layers within neural networks. Deep learning has powered many of the recent advances in AI, but the foundation models powering generative AI applications are a step-change evolution within deep learning. Unlike previous deep learning models, they can process extremely large and varied sets of unstructured data and perform more than one task. Foundation models have enabled new capabilities and vastly improved existing ones across a broad range of modalities, including images, video, audio, and computer code. AI trained on these models can perform several functions; it can classify, edit, summarize, answer questions, and draft new content, among other tasks. All of us are at the beginning of a journey to understand generative AI’s power, reach, and capabilities. This research is the latest in our efforts to assess the impact of this new era of AI. It suggests that generative AI is poised to transform roles and boost performance across functions such as sales and marketing, customer operations, and software development. In the process, it could unlock trillions of dollars in value across sectors from banking to life sciences. The following sections share our initial findings. For the full version of this report, download the PDF . Key insights Generative AI’s impact on productivity could add trillions of dollars in value to the global economy. Our latest research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases we analyzed—by comparison, the United Kingdom’s entire GDP in 2021 was $3.1 trillion. This would increase the impact of all artificial intelligence by 15 to 40 percent. This estimate would roughly double if we include the impact of embedding generative AI into software that is currently used for other tasks beyond those use cases. About 75 percent of the value that generative AI use cases could deliver falls across four areas: Customer operations, marketing and sales, software engineering, and R&D. Across 16 business functions, we examined 63 use cases in which the technology can address specific business challenges in ways that produce one or more measurable outcomes. Examples include generative AI’s ability to support interactions with customers, generate creative content for marketing and sales, and draft computer code based on natural-language prompts, among many other tasks. Generative AI will have a significant impact across all industry sectors. Banking, high tech, and life sciences are among the industries that could see the biggest impact as a percentage of their revenues from generative AI. Across the banking industry, for example, the technology could deliver value equal to an additional $200 billion to $340 billion annually if the use cases were fully implemented. In retail and consumer packaged goods, the potential impact is also significant at $400 billion to $660 billion a year. Generative AI has the potential to change the anatomy of work, augmenting the capabilities of individual workers by automating some of their individual activities. Current generative AI and other technologies have the potential to automate work activities that absorb 60 to 70 percent of employees’ time today. In contrast, we previously estimated that technology has the potential to automate half of the time employees spend working. 4 “ Harnessing automation for a future that works ,” McKinsey Global Institute, January 12, 2017. The acceleration in the potential for technical automation is largely due to generative AI’s increased ability to understand natural language, which is required for work activities that account for 25 percent of total work time. Thus, generative AI has more impact on knowledge work associated with occupations that have higher wages and educational requirements than on other types of work. The pace of workforce transformation is likely to accelerate, given increases in the potential for technical automation. Our updated adoption scenarios, including technology development, economic feasibility, and diffusion timelines, lead to estimates that half of today’s work activities could be automated between 2030 and 2060, with a midpoint in 2045, or roughly a decade earlier than in our previous estimates. Generative AI can substantially increase labor productivity across the economy, but that will require investments to support workers as they shift work activities or change jobs. Generative AI could enable labor productivity growth of 0.1 to 0.6 percent annually through 2040, depending on the rate of technology adoption and redeployment of worker time into other activities. Combining generative AI with all other technologies, work automation could add 0.5 to 3.4 percentage points annually to productivity growth. However, workers will need support in learning new skills, and some will change occupations. If worker transitions and other risks can be managed, generative AI could contribute substantively to economic growth and support a more sustainable, inclusive world. The era of generative AI is just beginning. Excitement over this technology is palpable, and early pilots are compelling. But a full realization of the technology’s benefits will take time, and leaders in business and society still have considerable challenges to address. These include managing the risks inherent in generative AI, determining what new skills and capabilities the workforce will need, and rethinking core business processes such as retraining and developing new skills. Where business value lies Generative AI is a step change in the evolution of artificial intelligence. As companies rush to adapt and implement it, understanding the technology’s potential to deliver value to the economy and society at large will help shape critical decisions. We have used two complementary lenses to determine where generative AI, with its current capabilities, could deliver the biggest value and how big that value could be (Exhibit 1). The first lens scans use cases for generative AI that organizations could adopt. We define a “use case” as a targeted application of generative AI to a specific business challenge, resulting in one or more measurable outcomes. For example, a use case in marketing is the application of generative AI to generate creative content such as personalized emails, the measurable outcomes of which potentially include reductions in the cost of generating such content and increases in revenue from the enhanced effectiveness of higher-quality content at scale. We identified 63 generative AI use cases spanning 16 business functions that could deliver total value in the range of $2.6 trillion to $4.4 trillion in economic benefits annually when applied across industries. That would add 15 to 40 percent to the $11 trillion to $17.7 trillion of economic value that we now estimate nongenerative artificial intelligence and analytics could unlock. (Our previous estimate from 2017 was that AI could deliver $9.5 trillion to $15.4 trillion in economic value.) Our second lens complements the first by analyzing generative AI’s potential impact on the work activities required in some 850 occupations. We modeled scenarios to estimate when generative AI could perform each of more than 2,100 “detailed work activities”—such as “communicating with others about operational plans or activities”—that make up those occupations across the world economy. This enables us to estimate how the current capabilities of generative AI could affect labor productivity across all work currently done by the global workforce. Some of this impact will overlap with cost reductions in the use case analysis described above, which we assume are the result of improved labor productivity. Netting out this overlap, the total economic benefits of generative AI —including the major use cases we explored and the myriad increases in productivity that are likely to materialize when the technology is applied across knowledge workers’ activities—amounts to $6.1 trillion to $7.9 trillion annually (Exhibit 2). How we estimated the value potential of generative AI use cases To assess the potential value of generative AI, we updated a proprietary McKinsey database of potential AI use cases and drew on the experience of more than 100 experts in industries and their business functions. 1 ” Notes from the AI frontier: Applications and value of deep learning ,” McKinsey Global Institute, April 17, 2018. Our updates examined use cases of generative AI—specifically, how generative AI techniques (primarily transformer-based neural networks) can be used to solve problems not well addressed by previous technologies. We analyzed only use cases for which generative AI could deliver a significant improvement in the outputs that drive key value. In particular, our estimates of the primary value the technology could unlock do not include use cases for which the sole benefit would be its ability to use natural language. For example, natural-language capabilities would be the key driver of value in a customer service use case but not in a use case optimizing a logistics network, where value primarily arises from quantitative analysis. We then estimated the potential annual value of these generative AI use cases if they were adopted across the entire economy. For use cases aimed at increasing revenue, such as some of those in sales and marketing, we estimated the economy-wide value generative AI could deliver by increasing the productivity of sales and marketing expenditures. Our estimates are based on the structure of the global economy in 2022 and do not consider the value generative AI could create if it produced entirely new product or service categories. While generative AI is an exciting and rapidly advancing technology, the other applications of AI discussed in our previous report continue to account for the majority of the overall potential value of AI. Traditional advanced-analytics and machine learning algorithms are highly effective at performing numerical and optimization tasks such as predictive modeling, and they continue to find new applications in a wide range of industries. However, as generative AI continues to develop and mature, it has the potential to open wholly new frontiers in creativity and innovation. It has already expanded the possibilities of what AI overall can achieve (see sidebar “How we estimated the value potential of generative AI use cases”). In this section, we highlight the value potential of generative AI across business functions. Generative AI could have an impact on most business functions; however, a few stand out when measured by the technology’s impact as a share of functional cost (Exhibit 3). Our analysis of 16 business functions identified just four—customer operations, marketing and sales, software engineering, and research and development—that could account for approximately 75 percent of the total annual value from generative AI use cases. Notably, the potential value of using generative AI for several functions that were prominent in our previous sizing of AI use cases, including manufacturing and supply chain functions, is now much lower. 5 Pitchbook. This is largely explained by the nature of generative AI use cases, which exclude most of the numerical and optimization applications that were the main value drivers for previous applications of AI. In addition to the potential value generative AI can deliver in function-specific use cases, the technology could drive value across an entire organization by revolutionizing internal knowledge management systems. Generative AI’s impressive command of natural-language processing can help employees retrieve stored internal knowledge by formulating queries in the same way they might ask a human a question and engage in continuing dialogue. This could empower teams to quickly access relevant information, enabling them to rapidly make better-informed decisions and develop effective strategies. In 2012, the McKinsey Global Institute (MGI) estimated that knowledge workers spent about a fifth of their time, or one day each work week, searching for and gathering information. If generative AI could take on such tasks, increasing the efficiency and effectiveness of the workers doing them, the benefits would be huge. Such virtual expertise could rapidly “read” vast libraries of corporate information stored in natural language and quickly scan source material in dialogue with a human who helps fine-tune and tailor its research, a more scalable solution than hiring a team of human experts for the task. In other cases, generative AI can drive value by working in partnership with workers, augmenting their work in ways that accelerate their productivity. Its ability to rapidly digest mountains of data and draw conclusions from it enables the technology to offer insights and options that can dramatically enhance knowledge work. This can significantly speed up the process of developing a product and allow employees to devote more time to higher-impact tasks. Following are four examples of how generative AI could produce operational benefits in a handful of use cases across the business functions that could deliver a majority of the potential value we identified in our analysis of 63 generative AI use cases. In the first two examples, it serves as a virtual expert, while in the following two, it lends a hand as a virtual collaborator. Customer operations: Improving customer and agent experiences Generative AI has the potential to revolutionize the entire customer operations function, improving the customer experience and agent productivity through digital self-service and enhancing and augmenting agent skills. The technology has already gained traction in customer service because of its ability to automate interactions with customers using natural language. Research found that at one company with 5,000 customer service agents, the application of generative AI increased issue resolution by 14 percent an hour and reduced the time spent handling an issue by 9 percent. 1 Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work , National Bureau of Economic Research working paper number 31161, April 2023. It also reduced agent attrition and requests to speak to a manager by 25 percent. Crucially, productivity and quality of service improved most among less-experienced agents, while the AI assistant did not increase—and sometimes decreased—the productivity and quality metrics of more highly skilled agents. This is because AI assistance helped less-experienced agents communicate using techniques similar to those of their higher-skilled counterparts. The following are examples of the operational improvements generative AI can have for specific use cases: We estimate that applying generative AI to customer care functions could increase productivity at a value ranging from 30 to 45 percent of current function costs. Our analysis captures only the direct impact generative AI might have on the productivity of customer operations. It does not account for potential knock-on effects the technology may have on customer satisfaction and retention arising from an improved experience, including better understanding of the customer’s context that can assist human agents in providing more personalized help and recommendations. Marketing and sales: Boosting personalization, content creation, and sales productivity Generative AI has taken hold rapidly in marketing and sales functions, in which text-based communications and personalization at scale are driving forces. The technology can create personalized messages tailored to individual customer interests, preferences, and behaviors, as well as do tasks such as producing first drafts of brand advertising, headlines, slogans, social media posts, and product descriptions. Marketing Introducing generative AI to marketing functions requires careful consideration. For one thing, mathematical models trained on publicly available data without sufficient safeguards against plagiarism, copyright violations, and branding recognition risks infringing on intellectual property rights. A virtual try-on application may produce biased representations of certain demographics because of limited or biased training data. Thus, significant human oversight is required for conceptual and strategic thinking specific to each company’s needs. Potential operational benefits from using generative AI for marketing include the following: We estimate that generative AI could increase the productivity of the marketing function with a value between 5 and 15 percent of total marketing spending. Our analysis of the potential use of generative AI in marketing doesn’t account for knock-on effects beyond the direct impacts on productivity. Generative AI–enabled synthesis could provide higher-quality data insights, leading to new ideas for marketing campaigns and better-targeted customer segments. Marketing functions could shift resources to producing higher-quality content for owned channels, potentially reducing spending on external channels and agencies. Sales Generative AI could also change the way both B2B and B2C companies approach sales. The following are two use cases for sales: Our analysis suggests that implementing generative AI could increase sales productivity by approximately 3 to 5 percent of current global sales expenditures. This analysis may not fully account for additional revenue that generative AI could bring to sales functions. For instance, generative AI’s ability to identify leads and follow-up capabilities could uncover new leads and facilitate more effective outreach that would bring in additional revenue. Also, the time saved by sales representatives due to generative AI’s capabilities could be invested in higher-quality customer interactions, resulting in increased sales success. Software engineering: Speeding developer work as a coding assistant Treating computer languages as just another language opens new possibilities for software engineering. Software engineers can use generative AI in pair programming and to do augmented coding and train LLMs to develop applications that generate code when given a natural-language prompt describing what that code should do. Software engineering is a significant function in most companies, and it continues to grow as all large companies, not just tech titans, embed software in a wide array of products and services. For example, much of the value of new vehicles comes from digital features such as adaptive cruise control, parking assistance, and IoT connectivity. According to our analysis, the direct impact of AI on the productivity of software engineering could range from 20 to 45 percent of current annual spending on the function. This value would arise primarily from reducing time spent on certain activities, such as generating initial code drafts, code correction and refactoring, root-cause analysis, and generating new system designs. By accelerating the coding process, generative AI could push the skill sets and capabilities needed in software engineering toward code and architecture design. One study found that software developers using Microsoft’s GitHub Copilot completed tasks 56 percent faster than those not using the tool. 1 Peter Cihon et al., The impact of AI on developer productivity: Evidence from GitHub Copilot , Cornell University arXiv software engineering working paper, arXiv:2302.06590, February 13, 2023. An internal McKinsey empirical study of software engineering teams found those who were trained to use generative AI tools rapidly reduced the time needed to generate and refactor code—and engineers also reported a better work experience, citing improvements in happiness, flow, and fulfillment. Our analysis did not account for the increase in application quality and the resulting boost in productivity that generative AI could bring by improving code or enhancing IT architecture—which can improve productivity across the IT value chain. However, the quality of IT architecture still largely depends on software architects, rather than on initial drafts that generative AI’s current capabilities allow it to produce. Large technology companies are already selling generative AI for software engineering, including GitHub Copilot, which is now integrated with OpenAI’s GPT-4, and Replit, used by more than 20 million coders. 2 Michael Nuñez, “Google and Replit join forces to challenge Microsoft in coding tools,” VentureBeat, March 28, 2023. Product R&D: Reducing research and design time, improving simulation and testing Generative AI’s potential in R&D is perhaps less well recognized than its potential in other business functions. Still, our research indicates the technology could deliver productivity with a value ranging from 10 to 15 percent of overall R&D costs. For example, the life sciences and chemical industries have begun using generative AI foundation models in their R&D for what is known as generative design. Foundation models can generate candidate molecules, accelerating the process of developing new drugs and materials. Entos, a biotech pharmaceutical company, has paired generative AI with automated synthetic development tools to design small-molecule therapeutics. But the same principles can be applied to the design of many other products, including larger-scale physical products and electrical circuits, among others. While other generative design techniques have already unlocked some of the potential to apply AI in R&D, their cost and data requirements, such as the use of “traditional” machine learning, can limit their application. Pretrained foundation models that underpin generative AI, or models that have been enhanced with fine-tuning, have much broader areas of application than models optimized for a single task. They can therefore accelerate time to market and broaden the types of products to which generative design can be applied. For now, however, foundation models lack the capabilities to help design products across all industries. In addition to the productivity gains that result from being able to quickly produce candidate designs, generative design can also enable improvements in the designs themselves, as in the following examples of the operational improvements generative AI could bring: We also identified a new R&D use case for nongenerative AI: deep learning surrogates, the use of which has grown since our earlier research, can be paired with generative AI to produce even greater benefits. To be sure, integration will require the development of specific solutions, but the value could be significant because deep learning surrogates have the potential to accelerate the testing of designs proposed by generative AI. While we have estimated the potential direct impacts of generative AI on the R&D function, we did not attempt to estimate the technology’s potential to create entirely novel product categories. These are the types of innovations that can produce step changes not only in the performance of individual companies but in economic growth overall. Industry impacts Across the 63 use cases we analyzed, generative AI has the potential to generate $2.6 trillion to $4.4 trillion in value across industries. Its precise impact will depend on a variety of factors, such as the mix and importance of different functions, as well as the scale of an industry’s revenue (Exhibit 4). For example, our analysis estimates generative AI could contribute roughly $310 billion in additional value for the retail industry (including auto dealerships) by boosting performance in functions such as marketing and customer interactions. By comparison, the bulk of potential value in high tech comes from generative AI’s ability to increase the speed and efficiency of software development (Exhibit 5). In the banking industry, generative AI has the potential to improve on efficiencies already delivered by artificial intelligence by taking on lower-value tasks in risk management, such as required reporting, monitoring regulatory developments, and collecting data. In the life sciences industry, generative AI is poised to make significant contributions to drug discovery and development. We share our detailed analysis of these industries below. Generative AI supports key value drivers in retail and consumer packaged goods The technology could generate value for the retail and consumer packaged goods (CPG) industry by increasing productivity by 1.2 to 2.0 percent of annual revenues, or an additional $400 billion to $660 billion. 1 Vehicular retail is included as part of our overall retail analysis. To streamline processes, generative AI could automate key functions such as customer service, marketing and sales, and inventory and supply chain management. Technology has played an essential role in the retail and CPG industries for decades. Traditional AI and advanced analytics solutions have helped companies manage vast pools of data across large numbers of SKUs, expansive supply chain and warehousing networks, and complex product categories such as consumables. In addition, the industries are heavily customer facing, which offers opportunities for generative AI to complement previously existing artificial intelligence. For example, generative AI’s ability to personalize offerings could optimize marketing and sales activities already handled by existing AI solutions. Similarly, generative AI tools excel at data management and could support existing AI-driven pricing tools. Applying generative AI to such activities could be a step toward integrating applications across a full enterprise. Generative AI at work in retail and CPG Reinvention of the customer interaction pattern Consumers increasingly seek customization in everything from clothing and cosmetics to curated shopping experiences, personalized outreach, and food—and generative AI can improve that experience. Generative AI can aggregate market data to test concepts, ideas, and models. Stitch Fix, which uses algorithms to suggest style choices to its customers, has experimented with DALL·E to visualize products based on customer preferences regarding color, fabric, and style. Using text-to-image generation, the company’s stylists can visualize an article of clothing based on a consumer’s preferences and then identify a similar article among Stitch Fix’s inventory. Retailers can create applications that give shoppers a next-generation experience, creating a significant competitive advantage in an era when customers expect to have a single natural-language interface help them select products. For example, generative AI can improve the process of choosing and ordering ingredients for a meal or preparing food—imagine a chatbot that could pull up the most popular tips from the comments attached to a recipe. There is also a big opportunity to enhance customer value management by delivering personalized marketing campaigns through a chatbot. Such applications can have human-like conversations about products in ways that can increase customer satisfaction, traffic, and brand loyalty. Generative AI offers retailers and CPG companies many opportunities to cross-sell and upsell, collect insights to improve product offerings, and increase their customer base, revenue opportunities, and overall marketing ROI. Accelerating the creation of value in key areas Generative AI tools can facilitate copy writing for marketing and sales, help brainstorm creative marketing ideas, expedite consumer research, and accelerate content analysis and creation. The potential improvement in writing and visuals can increase awareness and improve sales conversion rates. Rapid resolution and enhanced insights in customer care The growth of e-commerce also elevates the importance of effective consumer interactions. Retailers can combine existing AI tools with generative AI to enhance the capabilities of chatbots, enabling them to better mimic the interaction style of human agents—for example, by responding directly to a customer’s query, tracking or canceling an order, offering discounts, and upselling. Automating repetitive tasks allows human agents to devote more time to handling complicated customer problems and obtaining contextual information. Disruptive and creative innovation Generative AI tools can enhance the process of developing new versions of products by digitally creating new designs rapidly. A designer can generate packaging designs from scratch or generate variations on an existing design. This technology is developing rapidly and has the potential to add text-to-video generation. Factors for retail and CPG organizations to consider As retail and CPG executives explore how to integrate generative AI in their operations, they should keep in mind several factors that could affect their ability to capture value from the technology: To address these concerns, retail and CPG companies will need to strategically keep humans in the loop and ensure security and privacy are top considerations for any implementation. Companies will need to institute new quality checks for processes previously handled by humans, such as emails written by customer reps, and perform more-detailed quality checks on AI-assisted processes such as product design. Why banks could realize significant value Generative AI could have a significant impact on the banking industry , generating value from increased productivity of 2.8 to 4.7 percent of the industry’s annual revenues, or an additional $200 billion to $340 billion. On top of that impact, the use of generative AI tools could also enhance customer satisfaction, improve decision making and employee experience, and decrease risks through better monitoring of fraud and risk. Banking, a knowledge and technology-enabled industry, has already benefited significantly from previously existing applications of artificial intelligence in areas such as marketing and customer operations. 1 “ Building the AI bank of the future ,” McKinsey, May 2021. Generative AI applications could deliver additional benefits, especially because text modalities are prevalent in areas such as regulations and programming language, and the industry is customer facing, with many B2C and small-business customers. 2 McKinsey’s Global Banking Annual Review , December 1, 2022. Several characteristics position the industry for the integration of generative AI applications: Generative AI at work in banking Banks have started to grasp the potential of generative AI in their front lines and in their software activities. Early adopters are harnessing solutions such as ChatGPT as well as industry-specific solutions, primarily for software and knowledge applications. Three uses demonstrate its value potential to the industry. A virtual expert to augment employee performance A generative AI bot trained on proprietary knowledge such as policies, research, and customer interaction could provide always-on, deep technical support. Today, frontline spending is dedicated mostly to validating offers and interacting with clients, but giving frontline workers access to data as well could improve the customer experience. The technology could also monitor industries and clients and send alerts on semantic queries from public sources. For example, Morgan Stanley is building an AI assistant using GPT-4, with the aim of helping tens of thousands of wealth managers quickly find and synthesize answers from a massive internal knowledge base. 4 Hugh Son, “Morgan Stanley is testing an OpenAI-powered chatbot for its 16,000 financial advisors,” CNBC, March 14, 2023. The model combines search and content creation so wealth managers can find and tailor information for any client at any moment. One European bank has leveraged generative AI to develop an environmental, social, and governance (ESG) virtual expert by synthesizing and extracting from long documents with unstructured information. The model answers complex questions based on a prompt, identifying the source of each answer and extracting information from pictures and tables. Generative AI could reduce the significant costs associated with back-office operations. Such customer-facing chatbots could assess user requests and select the best service expert to address them based on characteristics such as topic, level of difficulty, and type of customer. Through generative AI assistants, service professionals could rapidly access all relevant information such as product guides and policies to instantaneously address customer requests. Code acceleration to reduce tech debt and deliver software faster Generative AI tools are useful for software development in four broad categories. First, they can draft code based on context via input code or natural language, helping developers code more quickly and with reduced friction while enabling automatic translations and no- and low-code tools. Second, such tools can automatically generate, prioritize, run, and review different code tests, accelerating testing and increasing coverage and effectiveness. Third, generative AI’s natural-language translation capabilities can optimize the integration and migration of legacy frameworks. Last, the tools can review code to identify defects and inefficiencies in computing. The result is more robust, effective code. Production of tailored content at scale Generative AI tools can draw on existing documents and data sets to substantially streamline content generation. These tools can create personalized marketing and sales content tailored to specific client profiles and histories as well as a multitude of alternatives for A/B testing. In addition, generative AI could automatically produce model documentation, identify missing documentation, and scan relevant regulatory updates to create alerts for relevant shifts. Factors for banks to consider When exploring how to integrate generative AI into operations, banks can be mindful of a number of factors: Pharmaceuticals and medical products could see benefits across the entire value chain Our analysis finds that generative AI could have a significant impact on the pharmaceutical and medical-product industries—from 2.6 to 4.5 percent of annual revenues across the pharmaceutical and medical-product industries, or $60 billion to $110 billion annually. This big potential reflects the resource-intensive process of discovering new drug compounds. Pharma companies typically spend approximately 20 percent of revenues on R&D, 1 Research and development in the pharmaceutical industry , Congressional Budget Office, April 2021. and the development of a new drug takes an average of ten to 15 years. With this level of spending and timeline, improving the speed and quality of R&D can generate substantial value. For example, lead identification—a step in the drug discovery process in which researchers identify a molecule that would best address the target for a potential new drug—can take several months even with “traditional” deep learning techniques. Foundation models and generative AI can enable organizations to complete this step in a matter of weeks. Generative AI at work in pharmaceuticals and medical products Drug discovery involves narrowing the universe of possible compounds to those that could effectively treat specific conditions. Generative AI’s ability to process massive amounts of data and model options can accelerate output across several use cases: Improve automation of preliminary screening In the lead identification stage of drug development, scientists can use foundation models to automate the preliminary screening of chemicals in the search for those that will produce specific effects on drug targets. To start, thousands of cell cultures are tested and paired with images of the corresponding experiment. Using an off-the-shelf foundation model, researchers can cluster similar images more precisely than they can with traditional models, enabling them to select the most promising chemicals for further analysis during lead optimization. Enhance indication finding An important phase of drug discovery involves the identification and prioritization of new indications—that is, diseases, symptoms, or circumstances that justify the use of a specific medication or other treatment, such as a test, procedure, or surgery. Possible indications for a given drug are based on a patient group’s clinical history and medical records, and they are then prioritized based on their similarities to established and evidence-backed indications. Researchers start by mapping the patient cohort’s clinical events and medical histories—including potential diagnoses, prescribed medications, and performed procedures—from real-world data. Using foundation models, researchers can quantify clinical events, establish relationships, and measure the similarity between the patient cohort and evidence-backed indications. The result is a short list of indications that have a better probability of success in clinical trials because they can be more accurately matched to appropriate patient groups. Pharma companies that have used this approach have reported high success rates in clinical trials for the top five indications recommended by a foundation model for a tested drug. This success has allowed these drugs to progress smoothly into Phase 3 trials, significantly accelerating the drug development process. Factors for pharmaceuticals and medical products organizations to consider Before integrating generative AI into operations, pharma executives should be aware of some factors that could limit their ability to capture its benefits: Work and productivity implications Technology has been changing the anatomy of work for decades. Over the years, machines have given human workers various “superpowers”; for instance, industrial-age machines enabled workers to accomplish physical tasks beyond the capabilities of their own bodies. More recently, computers have enabled knowledge workers to perform calculations that would have taken years to do manually. These examples illustrate how technology can augment work through the automation of individual activities that workers would have otherwise had to do themselves. At a conceptual level, the application of generative AI may follow the same pattern in the modern workplace, although as we show later in this chapter, the types of activities that generative AI could affect, and the types of occupations with activities that could change, will likely be different as a result of this technology than for older technologies. The McKinsey Global Institute began analyzing the impact of technological automation of work activities and modeling scenarios of adoption in 2017. At that time, we estimated that workers spent half of their time on activities that had the potential to be automated by adapting technology that existed at that time, or what we call technical automation potential. We also modeled a range of potential scenarios for the pace at which these technologies could be adopted and affect work activities throughout the global economy. Technology adoption at scale does not occur overnight. The potential of technological capabilities in a lab does not necessarily mean they can be immediately integrated into a solution that automates a specific work activity—developing such solutions takes time. Even when such a solution is developed, it might not be economically feasible to use if its costs exceed those of human labor. Additionally, even if economic incentives for deployment exist, it takes time for adoption to spread across the global economy. Hence, our adoption scenarios, which consider these factors together with the technical automation potential, provide a sense of the pace and scale at which workers’ activities could shift over time. About the research This analysis builds on the methodology we established in 2017. We began by examining the US Bureau of Labor Statistics O*Net breakdown of about 850 occupations into roughly 2,100 detailed work activities. For each of these activities, we scored the level of capability necessary to successfully perform the activity against a set of 18 capabilities that have the potential for automation. We also surveyed experts in the automation of each of these capabilities to estimate automation technologies’ current performance level against each of these capabilities, as well as how the technology’s performance might advance over time. Specifically, this year, we updated our assessments of technology’s performance in cognitive, language, and social and emotional capabilities based on a survey of generative AI experts. Based on these assessments of the technical automation potential of each detailed work activity at each point in time, we modeled potential scenarios for the adoption of work automation around the world. First, we estimated a range of time to implement a solution that could automate each specific detailed work activity, once all the capability requirements were met by the state of technology development. Second, we estimated a range of potential costs for this technology when it is first introduced, and then declining over time, based on historical precedents. We modeled the beginning of adoption for a specific detailed work activity in a particular occupation in a country (for 47 countries, accounting for more than 80 percent of the global workforce) when the cost of the automation technology reaches parity with the cost of human labor in that occupation. Based on a historical analysis of various technologies, we modeled a range of adoption timelines from eight to 27 years between the beginning of adoption and its plateau, using sigmoidal curves (S-curves). This range implicitly accounts for the many factors that could affect the pace at which adoption occurs, including regulation, levels of investment, and management decision making within firms. The modeled scenarios create a time range for the potential pace of automating current work activities. The “earliest” scenario flexes all parameters to the extremes of plausible assumptions, resulting in faster automation development and adoption, and the “latest” scenario flexes all parameters in the opposite direction. The reality is likely to fall somewhere between the two. The analyses in this paper incorporate the potential impact of generative AI on today’s work activities. The new capabilities of generative AI, combined with previous technologies and integrated into corporate operations around the world, could accelerate the potential for technical automation of individual activities and the adoption of technologies that augment the capabilities of the workforce. They could also have an impact on knowledge workers whose activities were not expected to shift as a result of these technologies until later in the future (see sidebar “About the research”). Automation potential has accelerated, but adoption to lag Based on developments in generative AI, technology performance is now expected to match median human performance and reach top-quartile human performance earlier than previously estimated across a wide range of capabilities (Exhibit 6). For example, MGI previously identified 2027 as the earliest year when median human performance for natural-language understanding might be achieved in technology, but in this new analysis, the corresponding point is 2023. As a result of these reassessments of technology capabilities due to generative AI, the total percentage of hours that could theoretically be automated by integrating technologies that exist today has increased from about 50 percent to 60–70 percent. The technical potential curve is quite steep because of the acceleration in generative AI’s natural-language capabilities. Interestingly, the range of times between the early and late scenarios has compressed compared with the expert assessments in 2017, reflecting a greater confidence that higher levels of technological capabilities will arrive by certain time periods (Exhibit 7). Our analysis of adoption scenarios accounts for the time required to integrate technological capabilities into solutions that can automate individual work activities; the cost of these technologies compared with that of human labor in different occupations and countries around the world; and the time it has taken for technologies to diffuse across the economy. With the acceleration in technical automation potential that generative AI enables, our scenarios for automation adoption have correspondingly accelerated. These scenarios encompass a wide range of outcomes, given that the pace at which solutions will be developed and adopted will vary based on decisions that will be made on investments, deployment, and regulation, among other factors. But they give an indication of the degree to which the activities that workers do each day may shift (Exhibit 8). As an example of how this might play out in a specific occupation, consider postsecondary English language and literature teachers, whose detailed work activities include preparing tests and evaluating student work. With generative AI’s enhanced natural-language capabilities, more of these activities could be done by machines, perhaps initially to create a first draft that is edited by teachers but perhaps eventually with far less human editing required. This could free up time for these teachers to spend more time on other work activities, such as guiding class discussions or tutoring students who need extra assistance. Our previously modeled adoption scenarios suggested that 50 percent of time spent on 2016 work activities would be automated sometime between 2035 and 2070, with a midpoint scenario around 2053. Our updated adoption scenarios, which account for developments in generative AI, models the time spent on 2023 work activities reaching 50 percent automation between 2030 and 2060, with a midpoint of 2045—an acceleration of roughly a decade compared with the previous estimate. 6 The comparison is not exact because the composition of work activities between 2016 and 2023 has changed; for example, some automation has occurred during that time period. Adoption is also likely to be faster in developed countries, where wages are higher and thus the economic feasibility of adopting automation occurs earlier. Even if the potential for technology to automate a particular work activity is high, the costs required to do so have to be compared with the cost of human wages. In countries such as China, India, and Mexico, where wage rates are lower, automation adoption is modeled to arrive more slowly than in higher-wage countries (Exhibit 9). Generative AI’s potential impact on knowledge work Previous generations of automation technology were particularly effective at automating data management tasks related to collecting and processing data. Generative AI’s natural-language capabilities increase the automation potential of these types of activities somewhat. But its impact on more physical work activities shifted much less, which isn’t surprising because its capabilities are fundamentally engineered to do cognitive tasks. As a result, generative AI is likely to have the biggest impact on knowledge work, particularly activities involving decision making and collaboration, which previously had the lowest potential for automation (Exhibit 10). Our estimate of the technical potential to automate the application of expertise jumped 34 percentage points, while the potential to automate management and develop talent increased from 16 percent in 2017 to 49 percent in 2023. Generative AI’s ability to understand and use natural language for a variety of activities and tasks largely explains why automation potential has risen so steeply. Some 40 percent of the activities that workers perform in the economy require at least a median level of human understanding of natural language. As a result, many of the work activities that involve communication, supervision, documentation, and interacting with people in general have the potential to be automated by generative AI, accelerating the transformation of work in occupations such as education and technology, for which automation potential was previously expected to emerge later (Exhibit 11). Labor economists have often noted that the deployment of automation technologies tends to have the most impact on workers with the lowest skill levels, as measured by educational attainment, or what is called skill biased. We find that generative AI has the opposite pattern—it is likely to have the most incremental impact through automating some of the activities of more-educated workers (Exhibit 12). Another way to interpret this result is that generative AI will challenge the attainment of multiyear degree credentials as an indicator of skills, and others have advocated for taking a more skills-based approach to workforce development in order to create more equitable, efficient workforce training and matching systems. 7 A more skills-based approach to workforce development predates the emergence of generative AI. Generative AI could still be described as skill-biased technological change, but with a different, perhaps more granular, description of skills that are more likely to be replaced than complemented by the activities that machines can do. Previous generations of automation technology often had the most impact on occupations with wages falling in the middle of the income distribution. For lower-wage occupations, making a case for work automation is more difficult because the potential benefits of automation compete against a lower cost of human labor. Additionally, some of the tasks performed in lower-wage occupations are technically difficult to automate—for example, manipulating fabric or picking delicate fruits. Some labor economists have observed a “hollowing out of the middle,” and our previous models have suggested that work automation would likely have the biggest midterm impact on lower-middle-income quintiles. However, generative AI’s impact is likely to most transform the work of higher-wage knowledge workers because of advances in the technical automation potential of their activities, which were previously considered to be relatively immune from automation (Exhibit 13). Generative AI could propel higher productivity growth Global economic growth was slower from 2012 to 2022 than in the two preceding decades. 8 Global economic prospects , World Bank, January 2023. Although the COVID-19 pandemic was a significant factor, long-term structural challenges—including declining birth rates and aging populations—are ongoing obstacles to growth. Declining employment is among those obstacles. Compound annual growth in the total number of workers worldwide slowed from 2.5 percent in 1972–82 to just 0.8 percent in 2012–22, largely because of aging. In many large countries, the size of the workforce is already declining. 9 Yaron Shamir, “Three factors contributing to fewer people in the workforce,” Forbes , April 7, 2022. Productivity, which measures output relative to input, or the value of goods and services produced divided by the amount of labor, capital, and other resources required to produce them, was the main engine of economic growth in the three decades from 1992 to 2022 (Exhibit 14). However, since then, productivity growth has slowed in tandem with slowing employment growth, confounding economists and policy makers. 10 “The U.S. productivity slowdown: an economy-wide and industry-level analysis,” Monthly Labor Review, US Bureau of Labor Statistics, April 2021; Kweilin Ellingrud, “ Turning around the productivity slowdown ,” McKinsey Global Institute, September 13, 2022. The deployment of generative AI and other technologies could help accelerate productivity growth, partially compensating for declining employment growth and enabling overall economic growth. Based on our estimates, the automation of individual work activities enabled by these technologies could provide the global economy with an annual productivity boost of 0.5 to 3.4 percent from 2023 to 2040, depending on the rate of automation adoption—with generative AI contributing 0.1 to 0.6 percentage points of that growth—but only if individuals affected by the technology were to shift to other work activities that at least match their 2022 productivity levels (Exhibit 15). In some cases, workers will stay in the same occupations, but their mix of activities will shift; in others, workers will need to shift occupations. Considerations for business and society History has shown that new technologies have the potential to reshape societies. Artificial intelligence has already changed the way we live and work—for example, it can help our phones (mostly) understand what we say, or draft emails. Mostly, however, AI has remained behind the scenes, optimizing business processes or making recommendations about the next product to buy. The rapid development of generative AI is likely to significantly augment the impact of AI overall, generating trillions of dollars of additional value each year and transforming the nature of work. But the technology could also deliver new and significant challenges. Stakeholders must act—and quickly, given the pace at which generative AI could be adopted—to prepare to address both the opportunities and the risks. Risks have already surfaced, including concerns about the content that generative AI systems produce: Will they infringe upon intellectual property due to “plagiarism” in the training data used to create foundation models? Will the answers that LLMs produce when questioned be accurate, and can they be explained? Will the content generative AI creates be fair or biased in ways that users do not want by, say, producing content that reflects harmful stereotypes? Using generative AI responsibly Generative AI poses a variety of risks. Stakeholders will want to address these risks from the start. Fairness: Models may generate algorithmic bias due to imperfect training data or decisions made by the engineers developing the models. Intellectual property (IP): Training data and model outputs can generate significant IP risks, including infringing on copyrighted, trademarked, patented, or otherwise legally protected materials. Even when using a provider’s generative AI tool, organizations will need to understand what data went into training and how it’s used in tool outputs. Privacy: Privacy concerns could arise if users input information that later ends up in model outputs in a form that makes individuals identifiable. Generative AI could also be used to create and disseminate malicious content such as disinformation, deepfakes, and hate speech. Security: Generative AI may be used by bad actors to accelerate the sophistication and speed of cyberattacks. It also can be manipulated to provide malicious outputs. For example, through a technique called prompt injection, a third party gives a model new instructions that trick the model into delivering an output unintended by the model producer and end user. Explainability: Generative AI relies on neural networks with billions of parameters, challenging our ability to explain how any given answer is produced. Reliability: Models can produce different answers to the same prompts, impeding the user’s ability to assess the accuracy and reliability of outputs. Organizational impact: Generative AI may significantly affect the workforce, and the impact on specific groups and local communities could be disproportionately negative. Social and environmental impact: The development and training of foundation models may lead to detrimental social and environmental consequences, including an increase in carbon emissions (for example, training one large language model can emit about 315 tons of carbon dioxide). 1 Ananya Ganesh, Andrew McCallum, and Emma Strubell, “Energy and policy considerations for deep learning in NLP,” Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , June 5, 2019. There are economic challenges too: the scale and the scope of the workforce transitions described in this report are considerable. In the midpoint adoption scenario, about a quarter to a third of work activities could change in the coming decade. The task before us is to manage the potential positives and negatives of the technology simultaneously (see sidebar “Using generative AI responsibly”). Here are some of the critical questions we will need to address while balancing our enthusiasm for the potential benefits of the technology with the new challenges it can introduce. Companies and business leaders How can companies move quickly to capture the potential value at stake highlighted in this report, while managing the risks that generative AI presents? How will the mix of occupations and skills needed across a company’s workforce be transformed by generative AI and other artificial intelligence over the coming years? How will a company enable these transitions in its hiring plans, retraining programs, and other aspects of human resources? Do companies have a role to play in ensuring the technology is not deployed in “negative use cases” that could harm society? How can businesses transparently share their experiences with scaling the use of generative AI within and across industries—and also with governments and society? Policy makers What will the future of work look like at the level of an economy in terms of occupations and skills? What does this mean for workforce planning? How can workers be supported as their activities shift over time? What retraining programs can be put in place? What incentives are needed to support private companies as they invest in human capital? Are there earn-while-you-learn programs such as apprenticeships that could enable people to retrain while continuing to support themselves and their families? What steps can policy makers take to prevent generative AI from being used in ways that harm society or vulnerable populations? Can new policies be developed and existing policies amended to ensure human-centric AI development and deployment that includes human oversight and diverse perspectives and accounts for societal values? Individuals as workers, consumers, and citizens How concerned should individuals be about the advent of generative AI? While companies can assess how the technology will affect their bottom lines, where can citizens turn for accurate, unbiased information about how it will affect their lives and livelihoods? How can individuals as workers and consumers balance the conveniences generative AI delivers with its impact in their workplaces? Can citizens have a voice in the decisions that will shape the deployment and integration of generative AI into the fabric of their lives? Technological innovation can inspire equal parts awe and concern. When that innovation seems to materialize fully formed and becomes widespread seemingly overnight, both responses can be amplified. The arrival of generative AI in the fall of 2022 was the most recent example of this phenomenon, due to its unexpectedly rapid adoption as well as the ensuing scramble among companies and consumers to deploy, integrate, and play with it. All of us are at the beginning of a journey to understand this technology’s power, reach, and capabilities. If the past eight months are any guide, the next several years will take us on a roller-coaster ride featuring fast-paced innovation and technological breakthroughs that force us to recalibrate our understanding of AI’s impact on our work and our lives. It is important to properly understand this phenomenon and anticipate its impact. Given the speed of generative AI’s deployment so far, the need to accelerate digital transformation and reskill labor forces is great. These tools have the potential to create enormous value for the global economy at a time when it is pondering the huge costs of adapting and mitigating climate change. At the same time, they also have the potential to be more destabilizing than previous generations of artificial intelligence. They are capable of that most human of abilities, language, which is a fundamental requirement of most work activities linked to expertise and knowledge as well as a skill that can be used to hurt feelings, create misunderstandings, obscure truth, and incite violence and even wars. We hope this research has contributed to a better understanding of generative AI’s capacity to add value to company operations and fuel economic growth and prosperity as well as its potential to dramatically transform how we work and our purpose in society. Companies, policy makers, consumers, and citizens can work together to ensure that generative AI delivers on its promise to create significant value while limiting its potential to upset lives and livelihoods. The time to act is now. 11 The research, analysis, and writing in this report was entirely done by humans. Michael Chui is a partner in McKinsey’s Bay Area office, where Roger Roberts is a partner and Lareina Yee is a senior partner; Eric Hazan is a senior partner in McKinsey’s Paris office; Alex Singla is a senior partner in the Chicago office; Kate Smaje and Alex Sukharevsky are senior partners in the London office; and Rodney Zemmel is a senior partner in the New York office. The authors wish to thank Pedro Abreu, Rohit Agarwal, Steven Aronowitz, Arun Arora, Charles Atkins, Elia Berteletti, Onno Boer, Albert Bollard, Xavier Bosquet, Benjamin Braverman, Charles Carcenac, Sebastien Chaigne, Peter Crispeels, Santiago Comella-Dorda, Eleonore Depardon, Kweilin Ellingrud, Thierry Ethevenin, Dmitry Gafarov, Neel Gandhi, Eric Goldberg, Liz Grennan, Shivani Gupta, Vinay Gupta, Dan Hababou, Bryan Hancock, Lisa Harkness, Leila Harouchi, Jake Hart, Heiko Heimes, Jeff Jacobs, Begum Karaci Deniz, Tarun Khurana, Malgorzata Kmicinska, Jan-Christoph Köstring, Andreas Kremer, Kathryn Kuhn, Jessica Lamb, Maxim Lampe, John Larson, Swan Leroi, Damian Lewandowski, Richard Li, Sonja Lindberg, Kerin Lo, Guillaume Lurenbaum, Matej Macak, Dana Maor, Julien Mauhourat, Marco Piccitto, Carolyn Pierce, Olivier Plantefeve, Alexandre Pons, Kathryn Rathje, Emily Reasor, Werner Rehm, Steve Reis, Kelsey Robinson, Martin Rosendahl, Christoph Sandler, Saurab Sanghvi, Boudhayan Sen, Joanna Si, Alok Singh, Gurneet Singh Dandona, François Soubien, Eli Stein, Stephanie Strom, Michele Tam, Robert Tas, Maribel Tejada, Wilbur Wang, Georg Winkler, Jane Wong, and Romain Zilahi for their contributions to this report. For the full list of acknowledgments, see the downloadable PDF . Explore a career with us Related Articles What every CEO should know about generative AI Exploring opportunities in the generative AI value chain What is generative AI?'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:41 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:41 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:41 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:41 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:41 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:41 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:42 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'1323'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'183310'), (b'x-ratelimit-reset-requests', b'1m5.663s'), (b'x-ratelimit-reset-tokens', b'5.007s'), (b'x-request-id', b'req_d670c9c6378b026c418ff7235879e679'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c41d9bd1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:42 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:42 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:42 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:42 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:42 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:42 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '1323', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9992', 'x-ratelimit-remaining-tokens': '183310', 'x-ratelimit-reset-requests': '1m5.663s', 'x-ratelimit-reset-tokens': '5.007s', 'x-request-id': 'req_d670c9c6378b026c418ff7235879e679', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c41d9bd1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:42 [openai._base_client] DEBUG: request_id: req_d670c9c6378b026c418ff7235879e679
2024-08-20 02:07:42 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Generative AI has significant economic potential, estimated to add $2.6 trillion to $4.4 trillion annually by enhancing productivity across various sectors. Its applications can transform roles in customer service, marketing, R&D, and software engineering, necessitating
2024-08-20 02:07:42 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:42 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:42 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:43 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:43 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A7%3AG7 HTTP/11" 200 None
2024-08-20 02:07:43 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A7%3AG7?valueInputOption=RAW HTTP/11" 400 None
2024-08-20 02:07:43 [scrapy.core.scraper] ERROR: Error processing {'title': 'The economic potential of generative AI: The next productivity frontier', 'description': 'Generative AI is poised to unleash the next wave of productivity. We take a first look at where business value could accrue and...', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20economic%20potential%20of%20generative%20ai%20the%20next%20productivity%20frontier/the-economic-potential-of-generative-ai-1324915617-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2023-06-14T12:00:00Z', 'article_text': 'The economic potential of generative AI: The next productivity frontier The economic potential of generative AI: The next productivity frontier AI has permeated our lives incrementally, through everything from the tech powering our smartphones to autonomous-driving features on cars to the tools retailers use to surprise and delight consumers. As a result, its progress has been almost imperceptible. Clear milestones, such as when AlphaGo, an AI-based program developed by DeepMind, defeated a world champion Go player in 2016, were celebrated but then quickly faded from the public’s consciousness. Generative AI applications such as ChatGPT, GitHub Copilot, Stable Diffusion, and others have captured the imagination of people around the world in a way AlphaGo did not, thanks to their broad utility—almost anyone can use them to communicate and create—and preternatural ability to have a conversation with a user. The latest generative AI applications can perform a range of routine tasks, such as the reorganization and classification of data. But it is their ability to write text, compose music, and create digital art that has garnered headlines and persuaded consumers and households to experiment on their own. As a result, a broader set of stakeholders are grappling with generative AI’s impact on business and society but without much context to help them make sense of it. About the authors This article is a collaborative effort by Michael Chui , Eric Hazan , Roger Roberts , Alex Singla , Kate Smaje , Alex Sukharevsky , Lareina Yee , and Rodney Zemmel , representing views from QuantumBlack, AI by McKinsey; McKinsey Digital; the McKinsey Technology Council; the McKinsey Global Institute; and McKinsey’s Growth, Marketing & Sales Practice. The speed at which generative AI technology is developing isn’t making this task any easier. ChatGPT was released in November 2022. Four months later, OpenAI released a new large language model, or LLM, called GPT-4 with markedly improved capabilities. 1 “Introducing ChatGPT,” OpenAI, November 30, 2022; “GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses,” OpenAI, accessed June 1, 2023. Similarly, by May 2023, Anthropic’s generative AI, Claude, was able to process 100,000 tokens of text, equal to about 75,000 words in a minute—the length of the average novel—compared with roughly 9,000 tokens when it was introduced in March 2023. 2 “Introducing Claude,” Anthropic PBC, March 14, 2023; “Introducing 100K Context Windows,” Anthropic PBC, May 11, 2023. And in May 2023, Google announced several new features powered by generative AI, including Search Generative Experience and a new LLM called PaLM 2 that will power its Bard chatbot, among other Google products. 3 Emma Roth, “The nine biggest announcements from Google I/O 2023,” The Verge , May 10, 2023. To grasp what lies ahead requires an understanding of the breakthroughs that have enabled the rise of generative AI, which were decades in the making. For the purposes of this report, we define generative AI as applications typically built using foundation models. These models contain expansive artificial neural networks inspired by the billions of neurons connected in the human brain. Foundation models are part of what is called deep learning, a term that alludes to the many deep layers within neural networks. Deep learning has powered many of the recent advances in AI, but the foundation models powering generative AI applications are a step-change evolution within deep learning. Unlike previous deep learning models, they can process extremely large and varied sets of unstructured data and perform more than one task. Foundation models have enabled new capabilities and vastly improved existing ones across a broad range of modalities, including images, video, audio, and computer code. AI trained on these models can perform several functions; it can classify, edit, summarize, answer questions, and draft new content, among other tasks. All of us are at the beginning of a journey to understand generative AI’s power, reach, and capabilities. This research is the latest in our efforts to assess the impact of this new era of AI. It suggests that generative AI is poised to transform roles and boost performance across functions such as sales and marketing, customer operations, and software development. In the process, it could unlock trillions of dollars in value across sectors from banking to life sciences. The following sections share our initial findings. For the full version of this report, download the PDF . Key insights Generative AI’s impact on productivity could add trillions of dollars in value to the global economy. Our latest research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases we analyzed—by comparison, the United Kingdom’s entire GDP in 2021 was $3.1 trillion. This would increase the impact of all artificial intelligence by 15 to 40 percent. This estimate would roughly double if we include the impact of embedding generative AI into software that is currently used for other tasks beyond those use cases. About 75 percent of the value that generative AI use cases could deliver falls across four areas: Customer operations, marketing and sales, software engineering, and R&D. Across 16 business functions, we examined 63 use cases in which the technology can address specific business challenges in ways that produce one or more measurable outcomes. Examples include generative AI’s ability to support interactions with customers, generate creative content for marketing and sales, and draft computer code based on natural-language prompts, among many other tasks. Generative AI will have a significant impact across all industry sectors. Banking, high tech, and life sciences are among the industries that could see the biggest impact as a percentage of their revenues from generative AI. Across the banking industry, for example, the technology could deliver value equal to an additional $200 billion to $340 billion annually if the use cases were fully implemented. In retail and consumer packaged goods, the potential impact is also significant at $400 billion to $660 billion a year. Generative AI has the potential to change the anatomy of work, augmenting the capabilities of individual workers by automating some of their individual activities. Current generative AI and other technologies have the potential to automate work activities that absorb 60 to 70 percent of employees’ time today. In contrast, we previously estimated that technology has the potential to automate half of the time employees spend working. 4 “ Harnessing automation for a future that works ,” McKinsey Global Institute, January 12, 2017. The acceleration in the potential for technical automation is largely due to generative AI’s increased ability to understand natural language, which is required for work activities that account for 25 percent of total work time. Thus, generative AI has more impact on knowledge work associated with occupations that have higher wages and educational requirements than on other types of work. The pace of workforce transformation is likely to accelerate, given increases in the potential for technical automation. Our updated adoption scenarios, including technology development, economic feasibility, and diffusion timelines, lead to estimates that half of today’s work activities could be automated between 2030 and 2060, with a midpoint in 2045, or roughly a decade earlier than in our previous estimates. Generative AI can substantially increase labor productivity across the economy, but that will require investments to support workers as they shift work activities or change jobs. Generative AI could enable labor productivity growth of 0.1 to 0.6 percent annually through 2040, depending on the rate of technology adoption and redeployment of worker time into other activities. Combining generative AI with all other technologies, work automation could add 0.5 to 3.4 percentage points annually to productivity growth. However, workers will need support in learning new skills, and some will change occupations. If worker transitions and other risks can be managed, generative AI could contribute substantively to economic growth and support a more sustainable, inclusive world. The era of generative AI is just beginning. Excitement over this technology is palpable, and early pilots are compelling. But a full realization of the technology’s benefits will take time, and leaders in business and society still have considerable challenges to address. These include managing the risks inherent in generative AI, determining what new skills and capabilities the workforce will need, and rethinking core business processes such as retraining and developing new skills. Where business value lies Generative AI is a step change in the evolution of artificial intelligence. As companies rush to adapt and implement it, understanding the technology’s potential to deliver value to the economy and society at large will help shape critical decisions. We have used two complementary lenses to determine where generative AI, with its current capabilities, could deliver the biggest value and how big that value could be (Exhibit 1). The first lens scans use cases for generative AI that organizations could adopt. We define a “use case” as a targeted application of generative AI to a specific business challenge, resulting in one or more measurable outcomes. For example, a use case in marketing is the application of generative AI to generate creative content such as personalized emails, the measurable outcomes of which potentially include reductions in the cost of generating such content and increases in revenue from the enhanced effectiveness of higher-quality content at scale. We identified 63 generative AI use cases spanning 16 business functions that could deliver total value in the range of $2.6 trillion to $4.4 trillion in economic benefits annually when applied across industries. That would add 15 to 40 percent to the $11 trillion to $17.7 trillion of economic value that we now estimate nongenerative artificial intelligence and analytics could unlock. (Our previous estimate from 2017 was that AI could deliver $9.5 trillion to $15.4 trillion in economic value.) Our second lens complements the first by analyzing generative AI’s potential impact on the work activities required in some 850 occupations. We modeled scenarios to estimate when generative AI could perform each of more than 2,100 “detailed work activities”—such as “communicating with others about operational plans or activities”—that make up those occupations across the world economy. This enables us to estimate how the current capabilities of generative AI could affect labor productivity across all work currently done by the global workforce. Some of this impact will overlap with cost reductions in the use case analysis described above, which we assume are the result of improved labor productivity. Netting out this overlap, the total economic benefits of generative AI —including the major use cases we explored and the myriad increases in productivity that are likely to materialize when the technology is applied across knowledge workers’ activities—amounts to $6.1 trillion to $7.9 trillion annually (Exhibit 2). How we estimated the value potential of generative AI use cases To assess the potential value of generative AI, we updated a proprietary McKinsey database of potential AI use cases and drew on the experience of more than 100 experts in industries and their business functions. 1 ” Notes from the AI frontier: Applications and value of deep learning ,” McKinsey Global Institute, April 17, 2018. Our updates examined use cases of generative AI—specifically, how generative AI techniques (primarily transformer-based neural networks) can be used to solve problems not well addressed by previous technologies. We analyzed only use cases for which generative AI could deliver a significant improvement in the outputs that drive key value. In particular, our estimates of the primary value the technology could unlock do not include use cases for which the sole benefit would be its ability to use natural language. For example, natural-language capabilities would be the key driver of value in a customer service use case but not in a use case optimizing a logistics network, where value primarily arises from quantitative analysis. We then estimated the potential annual value of these generative AI use cases if they were adopted across the entire economy. For use cases aimed at increasing revenue, such as some of those in sales and marketing, we estimated the economy-wide value generative AI could deliver by increasing the productivity of sales and marketing expenditures. Our estimates are based on the structure of the global economy in 2022 and do not consider the value generative AI could create if it produced entirely new product or service categories. While generative AI is an exciting and rapidly advancing technology, the other applications of AI discussed in our previous report continue to account for the majority of the overall potential value of AI. Traditional advanced-analytics and machine learning algorithms are highly effective at performing numerical and optimization tasks such as predictive modeling, and they continue to find new applications in a wide range of industries. However, as generative AI continues to develop and mature, it has the potential to open wholly new frontiers in creativity and innovation. It has already expanded the possibilities of what AI overall can achieve (see sidebar “How we estimated the value potential of generative AI use cases”). In this section, we highlight the value potential of generative AI across business functions. Generative AI could have an impact on most business functions; however, a few stand out when measured by the technology’s impact as a share of functional cost (Exhibit 3). Our analysis of 16 business functions identified just four—customer operations, marketing and sales, software engineering, and research and development—that could account for approximately 75 percent of the total annual value from generative AI use cases. Notably, the potential value of using generative AI for several functions that were prominent in our previous sizing of AI use cases, including manufacturing and supply chain functions, is now much lower. 5 Pitchbook. This is largely explained by the nature of generative AI use cases, which exclude most of the numerical and optimization applications that were the main value drivers for previous applications of AI. In addition to the potential value generative AI can deliver in function-specific use cases, the technology could drive value across an entire organization by revolutionizing internal knowledge management systems. Generative AI’s impressive command of natural-language processing can help employees retrieve stored internal knowledge by formulating queries in the same way they might ask a human a question and engage in continuing dialogue. This could empower teams to quickly access relevant information, enabling them to rapidly make better-informed decisions and develop effective strategies. In 2012, the McKinsey Global Institute (MGI) estimated that knowledge workers spent about a fifth of their time, or one day each work week, searching for and gathering information. If generative AI could take on such tasks, increasing the efficiency and effectiveness of the workers doing them, the benefits would be huge. Such virtual expertise could rapidly “read” vast libraries of corporate information stored in natural language and quickly scan source material in dialogue with a human who helps fine-tune and tailor its research, a more scalable solution than hiring a team of human experts for the task. In other cases, generative AI can drive value by working in partnership with workers, augmenting their work in ways that accelerate their productivity. Its ability to rapidly digest mountains of data and draw conclusions from it enables the technology to offer insights and options that can dramatically enhance knowledge work. This can significantly speed up the process of developing a product and allow employees to devote more time to higher-impact tasks. Following are four examples of how generative AI could produce operational benefits in a handful of use cases across the business functions that could deliver a majority of the potential value we identified in our analysis of 63 generative AI use cases. In the first two examples, it serves as a virtual expert, while in the following two, it lends a hand as a virtual collaborator. Customer operations: Improving customer and agent experiences Generative AI has the potential to revolutionize the entire customer operations function, improving the customer experience and agent productivity through digital self-service and enhancing and augmenting agent skills. The technology has already gained traction in customer service because of its ability to automate interactions with customers using natural language. Research found that at one company with 5,000 customer service agents, the application of generative AI increased issue resolution by 14 percent an hour and reduced the time spent handling an issue by 9 percent. 1 Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work , National Bureau of Economic Research working paper number 31161, April 2023. It also reduced agent attrition and requests to speak to a manager by 25 percent. Crucially, productivity and quality of service improved most among less-experienced agents, while the AI assistant did not increase—and sometimes decreased—the productivity and quality metrics of more highly skilled agents. This is because AI assistance helped less-experienced agents communicate using techniques similar to those of their higher-skilled counterparts. The following are examples of the operational improvements generative AI can have for specific use cases: We estimate that applying generative AI to customer care functions could increase productivity at a value ranging from 30 to 45 percent of current function costs. Our analysis captures only the direct impact generative AI might have on the productivity of customer operations. It does not account for potential knock-on effects the technology may have on customer satisfaction and retention arising from an improved experience, including better understanding of the customer’s context that can assist human agents in providing more personalized help and recommendations. Marketing and sales: Boosting personalization, content creation, and sales productivity Generative AI has taken hold rapidly in marketing and sales functions, in which text-based communications and personalization at scale are driving forces. The technology can create personalized messages tailored to individual customer interests, preferences, and behaviors, as well as do tasks such as producing first drafts of brand advertising, headlines, slogans, social media posts, and product descriptions. Marketing Introducing generative AI to marketing functions requires careful consideration. For one thing, mathematical models trained on publicly available data without sufficient safeguards against plagiarism, copyright violations, and branding recognition risks infringing on intellectual property rights. A virtual try-on application may produce biased representations of certain demographics because of limited or biased training data. Thus, significant human oversight is required for conceptual and strategic thinking specific to each company’s needs. Potential operational benefits from using generative AI for marketing include the following: We estimate that generative AI could increase the productivity of the marketing function with a value between 5 and 15 percent of total marketing spending. Our analysis of the potential use of generative AI in marketing doesn’t account for knock-on effects beyond the direct impacts on productivity. Generative AI–enabled synthesis could provide higher-quality data insights, leading to new ideas for marketing campaigns and better-targeted customer segments. Marketing functions could shift resources to producing higher-quality content for owned channels, potentially reducing spending on external channels and agencies. Sales Generative AI could also change the way both B2B and B2C companies approach sales. The following are two use cases for sales: Our analysis suggests that implementing generative AI could increase sales productivity by approximately 3 to 5 percent of current global sales expenditures. This analysis may not fully account for additional revenue that generative AI could bring to sales functions. For instance, generative AI’s ability to identify leads and follow-up capabilities could uncover new leads and facilitate more effective outreach that would bring in additional revenue. Also, the time saved by sales representatives due to generative AI’s capabilities could be invested in higher-quality customer interactions, resulting in increased sales success. Software engineering: Speeding developer work as a coding assistant Treating computer languages as just another language opens new possibilities for software engineering. Software engineers can use generative AI in pair programming and to do augmented coding and train LLMs to develop applications that generate code when given a natural-language prompt describing what that code should do. Software engineering is a significant function in most companies, and it continues to grow as all large companies, not just tech titans, embed software in a wide array of products and services. For example, much of the value of new vehicles comes from digital features such as adaptive cruise control, parking assistance, and IoT connectivity. According to our analysis, the direct impact of AI on the productivity of software engineering could range from 20 to 45 percent of current annual spending on the function. This value would arise primarily from reducing time spent on certain activities, such as generating initial code drafts, code correction and refactoring, root-cause analysis, and generating new system designs. By accelerating the coding process, generative AI could push the skill sets and capabilities needed in software engineering toward code and architecture design. One study found that software developers using Microsoft’s GitHub Copilot completed tasks 56 percent faster than those not using the tool. 1 Peter Cihon et al., The impact of AI on developer productivity: Evidence from GitHub Copilot , Cornell University arXiv software engineering working paper, arXiv:2302.06590, February 13, 2023. An internal McKinsey empirical study of software engineering teams found those who were trained to use generative AI tools rapidly reduced the time needed to generate and refactor code—and engineers also reported a better work experience, citing improvements in happiness, flow, and fulfillment. Our analysis did not account for the increase in application quality and the resulting boost in productivity that generative AI could bring by improving code or enhancing IT architecture—which can improve productivity across the IT value chain. However, the quality of IT architecture still largely depends on software architects, rather than on initial drafts that generative AI’s current capabilities allow it to produce. Large technology companies are already selling generative AI for software engineering, including GitHub Copilot, which is now integrated with OpenAI’s GPT-4, and Replit, used by more than 20 million coders. 2 Michael Nuñez, “Google and Replit join forces to challenge Microsoft in coding tools,” VentureBeat, March 28, 2023. Product R&D: Reducing research and design time, improving simulation and testing Generative AI’s potential in R&D is perhaps less well recognized than its potential in other business functions. Still, our research indicates the technology could deliver productivity with a value ranging from 10 to 15 percent of overall R&D costs. For example, the life sciences and chemical industries have begun using generative AI foundation models in their R&D for what is known as generative design. Foundation models can generate candidate molecules, accelerating the process of developing new drugs and materials. Entos, a biotech pharmaceutical company, has paired generative AI with automated synthetic development tools to design small-molecule therapeutics. But the same principles can be applied to the design of many other products, including larger-scale physical products and electrical circuits, among others. While other generative design techniques have already unlocked some of the potential to apply AI in R&D, their cost and data requirements, such as the use of “traditional” machine learning, can limit their application. Pretrained foundation models that underpin generative AI, or models that have been enhanced with fine-tuning, have much broader areas of application than models optimized for a single task. They can therefore accelerate time to market and broaden the types of products to which generative design can be applied. For now, however, foundation models lack the capabilities to help design products across all industries. In addition to the productivity gains that result from being able to quickly produce candidate designs, generative design can also enable improvements in the designs themselves, as in the following examples of the operational improvements generative AI could bring: We also identified a new R&D use case for nongenerative AI: deep learning surrogates, the use of which has grown since our earlier research, can be paired with generative AI to produce even greater benefits. To be sure, integration will require the development of specific solutions, but the value could be significant because deep learning surrogates have the potential to accelerate the testing of designs proposed by generative AI. While we have estimated the potential direct impacts of generative AI on the R&D function, we did not attempt to estimate the technology’s potential to create entirely novel product categories. These are the types of innovations that can produce step changes not only in the performance of individual companies but in economic growth overall. Industry impacts Across the 63 use cases we analyzed, generative AI has the potential to generate $2.6 trillion to $4.4 trillion in value across industries. Its precise impact will depend on a variety of factors, such as the mix and importance of different functions, as well as the scale of an industry’s revenue (Exhibit 4). For example, our analysis estimates generative AI could contribute roughly $310 billion in additional value for the retail industry (including auto dealerships) by boosting performance in functions such as marketing and customer interactions. By comparison, the bulk of potential value in high tech comes from generative AI’s ability to increase the speed and efficiency of software development (Exhibit 5). In the banking industry, generative AI has the potential to improve on efficiencies already delivered by artificial intelligence by taking on lower-value tasks in risk management, such as required reporting, monitoring regulatory developments, and collecting data. In the life sciences industry, generative AI is poised to make significant contributions to drug discovery and development. We share our detailed analysis of these industries below. Generative AI supports key value drivers in retail and consumer packaged goods The technology could generate value for the retail and consumer packaged goods (CPG) industry by increasing productivity by 1.2 to 2.0 percent of annual revenues, or an additional $400 billion to $660 billion. 1 Vehicular retail is included as part of our overall retail analysis. To streamline processes, generative AI could automate key functions such as customer service, marketing and sales, and inventory and supply chain management. Technology has played an essential role in the retail and CPG industries for decades. Traditional AI and advanced analytics solutions have helped companies manage vast pools of data across large numbers of SKUs, expansive supply chain and warehousing networks, and complex product categories such as consumables. In addition, the industries are heavily customer facing, which offers opportunities for generative AI to complement previously existing artificial intelligence. For example, generative AI’s ability to personalize offerings could optimize marketing and sales activities already handled by existing AI solutions. Similarly, generative AI tools excel at data management and could support existing AI-driven pricing tools. Applying generative AI to such activities could be a step toward integrating applications across a full enterprise. Generative AI at work in retail and CPG Reinvention of the customer interaction pattern Consumers increasingly seek customization in everything from clothing and cosmetics to curated shopping experiences, personalized outreach, and food—and generative AI can improve that experience. Generative AI can aggregate market data to test concepts, ideas, and models. Stitch Fix, which uses algorithms to suggest style choices to its customers, has experimented with DALL·E to visualize products based on customer preferences regarding color, fabric, and style. Using text-to-image generation, the company’s stylists can visualize an article of clothing based on a consumer’s preferences and then identify a similar article among Stitch Fix’s inventory. Retailers can create applications that give shoppers a next-generation experience, creating a significant competitive advantage in an era when customers expect to have a single natural-language interface help them select products. For example, generative AI can improve the process of choosing and ordering ingredients for a meal or preparing food—imagine a chatbot that could pull up the most popular tips from the comments attached to a recipe. There is also a big opportunity to enhance customer value management by delivering personalized marketing campaigns through a chatbot. Such applications can have human-like conversations about products in ways that can increase customer satisfaction, traffic, and brand loyalty. Generative AI offers retailers and CPG companies many opportunities to cross-sell and upsell, collect insights to improve product offerings, and increase their customer base, revenue opportunities, and overall marketing ROI. Accelerating the creation of value in key areas Generative AI tools can facilitate copy writing for marketing and sales, help brainstorm creative marketing ideas, expedite consumer research, and accelerate content analysis and creation. The potential improvement in writing and visuals can increase awareness and improve sales conversion rates. Rapid resolution and enhanced insights in customer care The growth of e-commerce also elevates the importance of effective consumer interactions. Retailers can combine existing AI tools with generative AI to enhance the capabilities of chatbots, enabling them to better mimic the interaction style of human agents—for example, by responding directly to a customer’s query, tracking or canceling an order, offering discounts, and upselling. Automating repetitive tasks allows human agents to devote more time to handling complicated customer problems and obtaining contextual information. Disruptive and creative innovation Generative AI tools can enhance the process of developing new versions of products by digitally creating new designs rapidly. A designer can generate packaging designs from scratch or generate variations on an existing design. This technology is developing rapidly and has the potential to add text-to-video generation. Factors for retail and CPG organizations to consider As retail and CPG executives explore how to integrate generative AI in their operations, they should keep in mind several factors that could affect their ability to capture value from the technology: To address these concerns, retail and CPG companies will need to strategically keep humans in the loop and ensure security and privacy are top considerations for any implementation. Companies will need to institute new quality checks for processes previously handled by humans, such as emails written by customer reps, and perform more-detailed quality checks on AI-assisted processes such as product design. Why banks could realize significant value Generative AI could have a significant impact on the banking industry , generating value from increased productivity of 2.8 to 4.7 percent of the industry’s annual revenues, or an additional $200 billion to $340 billion. On top of that impact, the use of generative AI tools could also enhance customer satisfaction, improve decision making and employee experience, and decrease risks through better monitoring of fraud and risk. Banking, a knowledge and technology-enabled industry, has already benefited significantly from previously existing applications of artificial intelligence in areas such as marketing and customer operations. 1 “ Building the AI bank of the future ,” McKinsey, May 2021. Generative AI applications could deliver additional benefits, especially because text modalities are prevalent in areas such as regulations and programming language, and the industry is customer facing, with many B2C and small-business customers. 2 McKinsey’s Global Banking Annual Review , December 1, 2022. Several characteristics position the industry for the integration of generative AI applications: Generative AI at work in banking Banks have started to grasp the potential of generative AI in their front lines and in their software activities. Early adopters are harnessing solutions such as ChatGPT as well as industry-specific solutions, primarily for software and knowledge applications. Three uses demonstrate its value potential to the industry. A virtual expert to augment employee performance A generative AI bot trained on proprietary knowledge such as policies, research, and customer interaction could provide always-on, deep technical support. Today, frontline spending is dedicated mostly to validating offers and interacting with clients, but giving frontline workers access to data as well could improve the customer experience. The technology could also monitor industries and clients and send alerts on semantic queries from public sources. For example, Morgan Stanley is building an AI assistant using GPT-4, with the aim of helping tens of thousands of wealth managers quickly find and synthesize answers from a massive internal knowledge base. 4 Hugh Son, “Morgan Stanley is testing an OpenAI-powered chatbot for its 16,000 financial advisors,” CNBC, March 14, 2023. The model combines search and content creation so wealth managers can find and tailor information for any client at any moment. One European bank has leveraged generative AI to develop an environmental, social, and governance (ESG) virtual expert by synthesizing and extracting from long documents with unstructured information. The model answers complex questions based on a prompt, identifying the source of each answer and extracting information from pictures and tables. Generative AI could reduce the significant costs associated with back-office operations. Such customer-facing chatbots could assess user requests and select the best service expert to address them based on characteristics such as topic, level of difficulty, and type of customer. Through generative AI assistants, service professionals could rapidly access all relevant information such as product guides and policies to instantaneously address customer requests. Code acceleration to reduce tech debt and deliver software faster Generative AI tools are useful for software development in four broad categories. First, they can draft code based on context via input code or natural language, helping developers code more quickly and with reduced friction while enabling automatic translations and no- and low-code tools. Second, such tools can automatically generate, prioritize, run, and review different code tests, accelerating testing and increasing coverage and effectiveness. Third, generative AI’s natural-language translation capabilities can optimize the integration and migration of legacy frameworks. Last, the tools can review code to identify defects and inefficiencies in computing. The result is more robust, effective code. Production of tailored content at scale Generative AI tools can draw on existing documents and data sets to substantially streamline content generation. These tools can create personalized marketing and sales content tailored to specific client profiles and histories as well as a multitude of alternatives for A/B testing. In addition, generative AI could automatically produce model documentation, identify missing documentation, and scan relevant regulatory updates to create alerts for relevant shifts. Factors for banks to consider When exploring how to integrate generative AI into operations, banks can be mindful of a number of factors: Pharmaceuticals and medical products could see benefits across the entire value chain Our analysis finds that generative AI could have a significant impact on the pharmaceutical and medical-product industries—from 2.6 to 4.5 percent of annual revenues across the pharmaceutical and medical-product industries, or $60 billion to $110 billion annually. This big potential reflects the resource-intensive process of discovering new drug compounds. Pharma companies typically spend approximately 20 percent of revenues on R&D, 1 Research and development in the pharmaceutical industry , Congressional Budget Office, April 2021. and the development of a new drug takes an average of ten to 15 years. With this level of spending and timeline, improving the speed and quality of R&D can generate substantial value. For example, lead identification—a step in the drug discovery process in which researchers identify a molecule that would best address the target for a potential new drug—can take several months even with “traditional” deep learning techniques. Foundation models and generative AI can enable organizations to complete this step in a matter of weeks. Generative AI at work in pharmaceuticals and medical products Drug discovery involves narrowing the universe of possible compounds to those that could effectively treat specific conditions. Generative AI’s ability to process massive amounts of data and model options can accelerate output across several use cases: Improve automation of preliminary screening In the lead identification stage of drug development, scientists can use foundation models to automate the preliminary screening of chemicals in the search for those that will produce specific effects on drug targets. To start, thousands of cell cultures are tested and paired with images of the corresponding experiment. Using an off-the-shelf foundation model, researchers can cluster similar images more precisely than they can with traditional models, enabling them to select the most promising chemicals for further analysis during lead optimization. Enhance indication finding An important phase of drug discovery involves the identification and prioritization of new indications—that is, diseases, symptoms, or circumstances that justify the use of a specific medication or other treatment, such as a test, procedure, or surgery. Possible indications for a given drug are based on a patient group’s clinical history and medical records, and they are then prioritized based on their similarities to established and evidence-backed indications. Researchers start by mapping the patient cohort’s clinical events and medical histories—including potential diagnoses, prescribed medications, and performed procedures—from real-world data. Using foundation models, researchers can quantify clinical events, establish relationships, and measure the similarity between the patient cohort and evidence-backed indications. The result is a short list of indications that have a better probability of success in clinical trials because they can be more accurately matched to appropriate patient groups. Pharma companies that have used this approach have reported high success rates in clinical trials for the top five indications recommended by a foundation model for a tested drug. This success has allowed these drugs to progress smoothly into Phase 3 trials, significantly accelerating the drug development process. Factors for pharmaceuticals and medical products organizations to consider Before integrating generative AI into operations, pharma executives should be aware of some factors that could limit their ability to capture its benefits: Work and productivity implications Technology has been changing the anatomy of work for decades. Over the years, machines have given human workers various “superpowers”; for instance, industrial-age machines enabled workers to accomplish physical tasks beyond the capabilities of their own bodies. More recently, computers have enabled knowledge workers to perform calculations that would have taken years to do manually. These examples illustrate how technology can augment work through the automation of individual activities that workers would have otherwise had to do themselves. At a conceptual level, the application of generative AI may follow the same pattern in the modern workplace, although as we show later in this chapter, the types of activities that generative AI could affect, and the types of occupations with activities that could change, will likely be different as a result of this technology than for older technologies. The McKinsey Global Institute began analyzing the impact of technological automation of work activities and modeling scenarios of adoption in 2017. At that time, we estimated that workers spent half of their time on activities that had the potential to be automated by adapting technology that existed at that time, or what we call technical automation potential. We also modeled a range of potential scenarios for the pace at which these technologies could be adopted and affect work activities throughout the global economy. Technology adoption at scale does not occur overnight. The potential of technological capabilities in a lab does not necessarily mean they can be immediately integrated into a solution that automates a specific work activity—developing such solutions takes time. Even when such a solution is developed, it might not be economically feasible to use if its costs exceed those of human labor. Additionally, even if economic incentives for deployment exist, it takes time for adoption to spread across the global economy. Hence, our adoption scenarios, which consider these factors together with the technical automation potential, provide a sense of the pace and scale at which workers’ activities could shift over time. About the research This analysis builds on the methodology we established in 2017. We began by examining the US Bureau of Labor Statistics O*Net breakdown of about 850 occupations into roughly 2,100 detailed work activities. For each of these activities, we scored the level of capability necessary to successfully perform the activity against a set of 18 capabilities that have the potential for automation. We also surveyed experts in the automation of each of these capabilities to estimate automation technologies’ current performance level against each of these capabilities, as well as how the technology’s performance might advance over time. Specifically, this year, we updated our assessments of technology’s performance in cognitive, language, and social and emotional capabilities based on a survey of generative AI experts. Based on these assessments of the technical automation potential of each detailed work activity at each point in time, we modeled potential scenarios for the adoption of work automation around the world. First, we estimated a range of time to implement a solution that could automate each specific detailed work activity, once all the capability requirements were met by the state of technology development. Second, we estimated a range of potential costs for this technology when it is first introduced, and then declining over time, based on historical precedents. We modeled the beginning of adoption for a specific detailed work activity in a particular occupation in a country (for 47 countries, accounting for more than 80 percent of the global workforce) when the cost of the automation technology reaches parity with the cost of human labor in that occupation. Based on a historical analysis of various technologies, we modeled a range of adoption timelines from eight to 27 years between the beginning of adoption and its plateau, using sigmoidal curves (S-curves). This range implicitly accounts for the many factors that could affect the pace at which adoption occurs, including regulation, levels of investment, and management decision making within firms. The modeled scenarios create a time range for the potential pace of automating current work activities. The “earliest” scenario flexes all parameters to the extremes of plausible assumptions, resulting in faster automation development and adoption, and the “latest” scenario flexes all parameters in the opposite direction. The reality is likely to fall somewhere between the two. The analyses in this paper incorporate the potential impact of generative AI on today’s work activities. The new capabilities of generative AI, combined with previous technologies and integrated into corporate operations around the world, could accelerate the potential for technical automation of individual activities and the adoption of technologies that augment the capabilities of the workforce. They could also have an impact on knowledge workers whose activities were not expected to shift as a result of these technologies until later in the future (see sidebar “About the research”). Automation potential has accelerated, but adoption to lag Based on developments in generative AI, technology performance is now expected to match median human performance and reach top-quartile human performance earlier than previously estimated across a wide range of capabilities (Exhibit 6). For example, MGI previously identified 2027 as the earliest year when median human performance for natural-language understanding might be achieved in technology, but in this new analysis, the corresponding point is 2023. As a result of these reassessments of technology capabilities due to generative AI, the total percentage of hours that could theoretically be automated by integrating technologies that exist today has increased from about 50 percent to 60–70 percent. The technical potential curve is quite steep because of the acceleration in generative AI’s natural-language capabilities. Interestingly, the range of times between the early and late scenarios has compressed compared with the expert assessments in 2017, reflecting a greater confidence that higher levels of technological capabilities will arrive by certain time periods (Exhibit 7). Our analysis of adoption scenarios accounts for the time required to integrate technological capabilities into solutions that can automate individual work activities; the cost of these technologies compared with that of human labor in different occupations and countries around the world; and the time it has taken for technologies to diffuse across the economy. With the acceleration in technical automation potential that generative AI enables, our scenarios for automation adoption have correspondingly accelerated. These scenarios encompass a wide range of outcomes, given that the pace at which solutions will be developed and adopted will vary based on decisions that will be made on investments, deployment, and regulation, among other factors. But they give an indication of the degree to which the activities that workers do each day may shift (Exhibit 8). As an example of how this might play out in a specific occupation, consider postsecondary English language and literature teachers, whose detailed work activities include preparing tests and evaluating student work. With generative AI’s enhanced natural-language capabilities, more of these activities could be done by machines, perhaps initially to create a first draft that is edited by teachers but perhaps eventually with far less human editing required. This could free up time for these teachers to spend more time on other work activities, such as guiding class discussions or tutoring students who need extra assistance. Our previously modeled adoption scenarios suggested that 50 percent of time spent on 2016 work activities would be automated sometime between 2035 and 2070, with a midpoint scenario around 2053. Our updated adoption scenarios, which account for developments in generative AI, models the time spent on 2023 work activities reaching 50 percent automation between 2030 and 2060, with a midpoint of 2045—an acceleration of roughly a decade compared with the previous estimate. 6 The comparison is not exact because the composition of work activities between 2016 and 2023 has changed; for example, some automation has occurred during that time period. Adoption is also likely to be faster in developed countries, where wages are higher and thus the economic feasibility of adopting automation occurs earlier. Even if the potential for technology to automate a particular work activity is high, the costs required to do so have to be compared with the cost of human wages. In countries such as China, India, and Mexico, where wage rates are lower, automation adoption is modeled to arrive more slowly than in higher-wage countries (Exhibit 9). Generative AI’s potential impact on knowledge work Previous generations of automation technology were particularly effective at automating data management tasks related to collecting and processing data. Generative AI’s natural-language capabilities increase the automation potential of these types of activities somewhat. But its impact on more physical work activities shifted much less, which isn’t surprising because its capabilities are fundamentally engineered to do cognitive tasks. As a result, generative AI is likely to have the biggest impact on knowledge work, particularly activities involving decision making and collaboration, which previously had the lowest potential for automation (Exhibit 10). Our estimate of the technical potential to automate the application of expertise jumped 34 percentage points, while the potential to automate management and develop talent increased from 16 percent in 2017 to 49 percent in 2023. Generative AI’s ability to understand and use natural language for a variety of activities and tasks largely explains why automation potential has risen so steeply. Some 40 percent of the activities that workers perform in the economy require at least a median level of human understanding of natural language. As a result, many of the work activities that involve communication, supervision, documentation, and interacting with people in general have the potential to be automated by generative AI, accelerating the transformation of work in occupations such as education and technology, for which automation potential was previously expected to emerge later (Exhibit 11). Labor economists have often noted that the deployment of automation technologies tends to have the most impact on workers with the lowest skill levels, as measured by educational attainment, or what is called skill biased. We find that generative AI has the opposite pattern—it is likely to have the most incremental impact through automating some of the activities of more-educated workers (Exhibit 12). Another way to interpret this result is that generative AI will challenge the attainment of multiyear degree credentials as an indicator of skills, and others have advocated for taking a more skills-based approach to workforce development in order to create more equitable, efficient workforce training and matching systems. 7 A more skills-based approach to workforce development predates the emergence of generative AI. Generative AI could still be described as skill-biased technological change, but with a different, perhaps more granular, description of skills that are more likely to be replaced than complemented by the activities that machines can do. Previous generations of automation technology often had the most impact on occupations with wages falling in the middle of the income distribution. For lower-wage occupations, making a case for work automation is more difficult because the potential benefits of automation compete against a lower cost of human labor. Additionally, some of the tasks performed in lower-wage occupations are technically difficult to automate—for example, manipulating fabric or picking delicate fruits. Some labor economists have observed a “hollowing out of the middle,” and our previous models have suggested that work automation would likely have the biggest midterm impact on lower-middle-income quintiles. However, generative AI’s impact is likely to most transform the work of higher-wage knowledge workers because of advances in the technical automation potential of their activities, which were previously considered to be relatively immune from automation (Exhibit 13). Generative AI could propel higher productivity growth Global economic growth was slower from 2012 to 2022 than in the two preceding decades. 8 Global economic prospects , World Bank, January 2023. Although the COVID-19 pandemic was a significant factor, long-term structural challenges—including declining birth rates and aging populations—are ongoing obstacles to growth. Declining employment is among those obstacles. Compound annual growth in the total number of workers worldwide slowed from 2.5 percent in 1972–82 to just 0.8 percent in 2012–22, largely because of aging. In many large countries, the size of the workforce is already declining. 9 Yaron Shamir, “Three factors contributing to fewer people in the workforce,” Forbes , April 7, 2022. Productivity, which measures output relative to input, or the value of goods and services produced divided by the amount of labor, capital, and other resources required to produce them, was the main engine of economic growth in the three decades from 1992 to 2022 (Exhibit 14). However, since then, productivity growth has slowed in tandem with slowing employment growth, confounding economists and policy makers. 10 “The U.S. productivity slowdown: an economy-wide and industry-level analysis,” Monthly Labor Review, US Bureau of Labor Statistics, April 2021; Kweilin Ellingrud, “ Turning around the productivity slowdown ,” McKinsey Global Institute, September 13, 2022. The deployment of generative AI and other technologies could help accelerate productivity growth, partially compensating for declining employment growth and enabling overall economic growth. Based on our estimates, the automation of individual work activities enabled by these technologies could provide the global economy with an annual productivity boost of 0.5 to 3.4 percent from 2023 to 2040, depending on the rate of automation adoption—with generative AI contributing 0.1 to 0.6 percentage points of that growth—but only if individuals affected by the technology were to shift to other work activities that at least match their 2022 productivity levels (Exhibit 15). In some cases, workers will stay in the same occupations, but their mix of activities will shift; in others, workers will need to shift occupations. Considerations for business and society History has shown that new technologies have the potential to reshape societies. Artificial intelligence has already changed the way we live and work—for example, it can help our phones (mostly) understand what we say, or draft emails. Mostly, however, AI has remained behind the scenes, optimizing business processes or making recommendations about the next product to buy. The rapid development of generative AI is likely to significantly augment the impact of AI overall, generating trillions of dollars of additional value each year and transforming the nature of work. But the technology could also deliver new and significant challenges. Stakeholders must act—and quickly, given the pace at which generative AI could be adopted—to prepare to address both the opportunities and the risks. Risks have already surfaced, including concerns about the content that generative AI systems produce: Will they infringe upon intellectual property due to “plagiarism” in the training data used to create foundation models? Will the answers that LLMs produce when questioned be accurate, and can they be explained? Will the content generative AI creates be fair or biased in ways that users do not want by, say, producing content that reflects harmful stereotypes? Using generative AI responsibly Generative AI poses a variety of risks. Stakeholders will want to address these risks from the start. Fairness: Models may generate algorithmic bias due to imperfect training data or decisions made by the engineers developing the models. Intellectual property (IP): Training data and model outputs can generate significant IP risks, including infringing on copyrighted, trademarked, patented, or otherwise legally protected materials. Even when using a provider’s generative AI tool, organizations will need to understand what data went into training and how it’s used in tool outputs. Privacy: Privacy concerns could arise if users input information that later ends up in model outputs in a form that makes individuals identifiable. Generative AI could also be used to create and disseminate malicious content such as disinformation, deepfakes, and hate speech. Security: Generative AI may be used by bad actors to accelerate the sophistication and speed of cyberattacks. It also can be manipulated to provide malicious outputs. For example, through a technique called prompt injection, a third party gives a model new instructions that trick the model into delivering an output unintended by the model producer and end user. Explainability: Generative AI relies on neural networks with billions of parameters, challenging our ability to explain how any given answer is produced. Reliability: Models can produce different answers to the same prompts, impeding the user’s ability to assess the accuracy and reliability of outputs. Organizational impact: Generative AI may significantly affect the workforce, and the impact on specific groups and local communities could be disproportionately negative. Social and environmental impact: The development and training of foundation models may lead to detrimental social and environmental consequences, including an increase in carbon emissions (for example, training one large language model can emit about 315 tons of carbon dioxide). 1 Ananya Ganesh, Andrew McCallum, and Emma Strubell, “Energy and policy considerations for deep learning in NLP,” Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , June 5, 2019. There are economic challenges too: the scale and the scope of the workforce transitions described in this report are considerable. In the midpoint adoption scenario, about a quarter to a third of work activities could change in the coming decade. The task before us is to manage the potential positives and negatives of the technology simultaneously (see sidebar “Using generative AI responsibly”). Here are some of the critical questions we will need to address while balancing our enthusiasm for the potential benefits of the technology with the new challenges it can introduce. Companies and business leaders How can companies move quickly to capture the potential value at stake highlighted in this report, while managing the risks that generative AI presents? How will the mix of occupations and skills needed across a company’s workforce be transformed by generative AI and other artificial intelligence over the coming years? How will a company enable these transitions in its hiring plans, retraining programs, and other aspects of human resources? Do companies have a role to play in ensuring the technology is not deployed in “negative use cases” that could harm society? How can businesses transparently share their experiences with scaling the use of generative AI within and across industries—and also with governments and society? Policy makers What will the future of work look like at the level of an economy in terms of occupations and skills? What does this mean for workforce planning? How can workers be supported as their activities shift over time? What retraining programs can be put in place? What incentives are needed to support private companies as they invest in human capital? Are there earn-while-you-learn programs such as apprenticeships that could enable people to retrain while continuing to support themselves and their families? What steps can policy makers take to prevent generative AI from being used in ways that harm society or vulnerable populations? Can new policies be developed and existing policies amended to ensure human-centric AI development and deployment that includes human oversight and diverse perspectives and accounts for societal values? Individuals as workers, consumers, and citizens How concerned should individuals be about the advent of generative AI? While companies can assess how the technology will affect their bottom lines, where can citizens turn for accurate, unbiased information about how it will affect their lives and livelihoods? How can individuals as workers and consumers balance the conveniences generative AI delivers with its impact in their workplaces? Can citizens have a voice in the decisions that will shape the deployment and integration of generative AI into the fabric of their lives? Technological innovation can inspire equal parts awe and concern. When that innovation seems to materialize fully formed and becomes widespread seemingly overnight, both responses can be amplified. The arrival of generative AI in the fall of 2022 was the most recent example of this phenomenon, due to its unexpectedly rapid adoption as well as the ensuing scramble among companies and consumers to deploy, integrate, and play with it. All of us are at the beginning of a journey to understand this technology’s power, reach, and capabilities. If the past eight months are any guide, the next several years will take us on a roller-coaster ride featuring fast-paced innovation and technological breakthroughs that force us to recalibrate our understanding of AI’s impact on our work and our lives. It is important to properly understand this phenomenon and anticipate its impact. Given the speed of generative AI’s deployment so far, the need to accelerate digital transformation and reskill labor forces is great. These tools have the potential to create enormous value for the global economy at a time when it is pondering the huge costs of adapting and mitigating climate change. At the same time, they also have the potential to be more destabilizing than previous generations of artificial intelligence. They are capable of that most human of abilities, language, which is a fundamental requirement of most work activities linked to expertise and knowledge as well as a skill that can be used to hurt feelings, create misunderstandings, obscure truth, and incite violence and even wars. We hope this research has contributed to a better understanding of generative AI’s capacity to add value to company operations and fuel economic growth and prosperity as well as its potential to dramatically transform how we work and our purpose in society. Companies, policy makers, consumers, and citizens can work together to ensure that generative AI delivers on its promise to create significant value while limiting its potential to upset lives and livelihoods. The time to act is now. 11 The research, analysis, and writing in this report was entirely done by humans. Michael Chui is a partner in McKinsey’s Bay Area office, where Roger Roberts is a partner and Lareina Yee is a senior partner; Eric Hazan is a senior partner in McKinsey’s Paris office; Alex Singla is a senior partner in the Chicago office; Kate Smaje and Alex Sukharevsky are senior partners in the London office; and Rodney Zemmel is a senior partner in the New York office. The authors wish to thank Pedro Abreu, Rohit Agarwal, Steven Aronowitz, Arun Arora, Charles Atkins, Elia Berteletti, Onno Boer, Albert Bollard, Xavier Bosquet, Benjamin Braverman, Charles Carcenac, Sebastien Chaigne, Peter Crispeels, Santiago Comella-Dorda, Eleonore Depardon, Kweilin Ellingrud, Thierry Ethevenin, Dmitry Gafarov, Neel Gandhi, Eric Goldberg, Liz Grennan, Shivani Gupta, Vinay Gupta, Dan Hababou, Bryan Hancock, Lisa Harkness, Leila Harouchi, Jake Hart, Heiko Heimes, Jeff Jacobs, Begum Karaci Deniz, Tarun Khurana, Malgorzata Kmicinska, Jan-Christoph Köstring, Andreas Kremer, Kathryn Kuhn, Jessica Lamb, Maxim Lampe, John Larson, Swan Leroi, Damian Lewandowski, Richard Li, Sonja Lindberg, Kerin Lo, Guillaume Lurenbaum, Matej Macak, Dana Maor, Julien Mauhourat, Marco Piccitto, Carolyn Pierce, Olivier Plantefeve, Alexandre Pons, Kathryn Rathje, Emily Reasor, Werner Rehm, Steve Reis, Kelsey Robinson, Martin Rosendahl, Christoph Sandler, Saurab Sanghvi, Boudhayan Sen, Joanna Si, Alok Singh, Gurneet Singh Dandona, François Soubien, Eli Stein, Stephanie Strom, Michele Tam, Robert Tas, Maribel Tejada, Wilbur Wang, Georg Winkler, Jane Wong, and Romain Zilahi for their contributions to this report. For the full list of acknowledgments, see the downloadable PDF . Explore a career with us Related Articles What every CEO should know about generative AI Exploring opportunities in the generative AI value chain What is generative AI?', 'summary': 'Generative AI has significant economic potential, estimated to add $2.6 trillion to $4.4 trillion annually by enhancing productivity across various sectors. Its applications can transform roles in customer service, marketing, R&D, and software engineering, necessitating'}
Traceback (most recent call last):
  File "C:\Users\R9000P\web_scraper_Hasmo\venv\Lib\site-packages\twisted\internet\defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\R9000P\web_scraper_Hasmo\venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\R9000P\web_scraper_Hasmo\mckinsey_scraper\mckinsey_scraper\pipelines.py", line 299, in process_item
    self.update_worksheet(self.worksheet, item)
  File "C:\Users\R9000P\web_scraper_Hasmo\mckinsey_scraper\mckinsey_scraper\pipelines.py", line 271, in update_worksheet
    self.retry_api_call(worksheet.update_cells, cell_list)
  File "C:\Users\R9000P\web_scraper_Hasmo\mckinsey_scraper\mckinsey_scraper\pipelines.py", line 292, in retry_api_call
    raise e
  File "C:\Users\R9000P\web_scraper_Hasmo\mckinsey_scraper\mckinsey_scraper\pipelines.py", line 278, in retry_api_call
    return func(*args, **kwargs)
  File "C:\Users\R9000P\web_scraper_Hasmo\venv\Lib\site-packages\gspread\worksheet.py", line 811, in update_cells
    data = self.client.values_update(
  File "C:\Users\R9000P\web_scraper_Hasmo\venv\Lib\site-packages\gspread\http_client.py", line 173, in values_update
    r = self.request("put", url, params=params, json=body)
  File "C:\Users\R9000P\web_scraper_Hasmo\venv\Lib\site-packages\gspread\http_client.py", line 128, in request
    raise APIError(response)
gspread.exceptions.APIError: APIError: [400]: Your input contains more than the maximum of 50000 characters in a single cell.
2024-08-20 02:07:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/rewired-to-outcompete> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:43 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nRewired to outcompete How companies navigate the technology world to achieve sustainable competitive advantage is the defining business challenge of our time. To be fair, this challenge isn’t new. But it’s an increasingly pressing one, with deep implications for how companies navigate a world where digital and AI are fundamentally reshaping how we work and live. Companies understand they need to meet the challenge, but most of them are struggling. McKinsey research shows that while 90 percent of companies have launched some flavor of digital transformation, only a third of the expected revenue benefits, on average, have been realized . 1 “ Three new mandates for capturing a digital transformation’s full value ,” McKinsey, June 15, 2022. Yet it’s also a challenge with enormous potential for the companies that get it right. In the banking sector, for example, where digital and AI transformations have been under way for the past decade, compelling empirical data shows that digitally transformed banks outperform their peers. We leveraged a unique data set, Finalta by McKinsey, to analyze 20 digital leaders and 20 digital laggards in retail banking between 2018 and 2022. The results were startling. Digital leaders improved their return on tangible equity, their P/E ratio, and their total shareholder returns materially more than digital laggards (Exhibit 1). Digital excellence is translating into financial outperformance. This outperformance was propelled by a deeper integration of technology across end-to-end core business processes. This, in turn, drove higher digital sales and lower costs in branches and operations. How did the digital leaders accomplish this? By bringing business, technology, and operations more closely together to digitally innovate; by upskilling their organizations; and by building a distributed technology and data environment to empower hundreds if not thousands of teams to digitally innovate, day in, day out. This gets at the nub of why digital and AI transformations are so difficult—companies need to get a lot of things right. Clearly, for digital and AI to deliver on their business transformation potential, the top team needs to be ready and willing to undertake the organizational “surgery” required to become a digitally capable enterprise. There are no quick fixes. You can’t simply implement a system or a technology and be done. Instead, success means having hundreds of technology-driven solutions (proprietary and off the shelf) working together that you continually improve to create great customer and employee experiences, lower unit costs, and generate value. But creating, managing, and evolving these solutions at enterprise scale requires a fundamental rewiring of how a company operates. That means getting thousands of people across different units of the organization working together and working differently to digitally innovate, constantly. Creating value beyond the hype The lessons learned from our work with more than 200 large companies across multiple industries show that capturing this kind of value from digital and AI requires building six critical enterprise capabilities (Exhibit 2). These allow rewired companies to integrate new technologies, such as generative AI, and harness them to create value. While companies may understand this at a high level, they struggle with how to build these capabilities successfully and ensure that they work together across the enterprise. Our new book, Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI , is all about the how . This article is adapted from that book and delineates the core aspects of what it takes for leaders to spur transformation across all six capabilities. Before we go into detail, it’s worth highlighting two key findings. First, no digital and AI transformation can be successful without building a baseline of competence across all six capabilities. Second, these elements are interconnected and need to be managed that way: a good operating model, for example, can’t work without the right talent. Similarly, great technology won’t make much of an impact if users don’t adopt it. You do not have to be a tech company to achieve excellence in digital and AI. Large, established companies can outcompete and capture value, but only when they are willing to commit to the hard work of rewiring their enterprise. This is a job for the entire C-suite, not just the CEO or the chief information officer (CIO). The cross-functional nature of a digital and AI transformation requires an unparalleled level of collaboration across the C-suite, with everyone having an important part to play in building these enterprise capabilities. Rewiring the business is an ongoing journey of improvement, not a destination. Let’s dig into the details of that journey. Align the C-suite around a business-led road map When evaluating stalled digital and AI transformations, we find that many of the issues that impede a program’s success can be traced back to insufficient planning and alignment. Misunderstanding among leadership at the strategic-planning stage will invariably lead to muddled execution in a company’s transformation. Because digital and AI transformations affect so many parts of the business, investing the necessary time to help make the transformation a success pays significant dividends in terms of clarity and unified action. The best companies make sure to get three early moves right. Inspire and align the top team. Take the time to establish a common digital language, learn from other companies that are further along the journey, develop a shared vision among the C-suite, and explicitly agree on a set of commitments that match your ambitions. Consider the example of DBS Bank, one of the world’s most successful digitally transformed banks . CEO Piyush Gupta and his top leaders visited and learned from top tech companies around the globe and used those lessons to shape a vision around “Making Banking Joyful” and to commit to making DBS a tech leader. This kind of leadership alignment is crucial to ensuring a successful digital and AI transformation. Get the ‘bite’ size right: business domains. Some companies struggle from the start of their digital and AI transformation by getting the scope of the change wrong. They start too small—believing that implementing a few use cases will lower risk—or they spread bets and resources too thinly across an uncoordinated set of initiatives. Both approaches typically produce little value. Successful companies, on the other hand, focus their efforts on a few important business domains, such as a production process or the customer journey, and transform them from end to end. As many as 80 percent of successful interventions in struggling digital and AI transformations are based on reanchoring the scope to spur a concerted effort against a few well-defined domains. Commit to a contract with the C-suite. Effective rewiring requires companies to tie the transformation outcomes of each business domain to specific improvements in operational KPIs, such as reduction in customer churn or improvements in process yield. The team builds a road map where the digital solutions that underpin these KPI improvements are sequenced in a way to produce meaningful value in the short term (say, 12 to 18 months) and transformational value in the medium term (three to five years, for example). The plan explicitly accounts for the build-out of enterprise capabilities, such as hiring digital talent or modernizing data architecture. C-suite leaders commit to these KPI improvements, and the expected benefits are baked into their business objectives. Our rule of thumb is that a robust digital road map should deliver EBIT improvement of\n20 percent or more. When business leaders define an ambitious yet realistic transformation of their business domains with technology, they set in motion the flywheel of digital change. The resulting digital road map is their signature move and effectively acts as a contract that they commit to implementing. When business leaders define an ambitious yet realistic transformation of their business domains with technology, they set in motion the flywheel of digital change. Build your talent bench No company can outsource its way to digital excellence. Being digital means having your own bench of digital talent—product owners, experience designers, cloud engineers, software developers, and so on—working side by side with your business colleagues. Digital transformations are, first and foremost, people transformations. The following are three actions that digital leaders take. Create a cleansheet for your talent. Most companies have digital technologists, but many still face the hard work of reskilling their technology and IT organization. The aspiration should be to have 70 to 80 percent of your digital talent in-house, with 20 to 30 percent coming from outside the company and focused on specialized skills, flexibility, or both. Your talent pyramid should shift to a diamond shape, with more competent technologists and fewer novices. That’s because there is a step change in productivity from more experienced technologists. You should also have a healthy ratio of hands-on-keyboard technologists versus managerial roles. Rewired leaders target a 4:1 ratio (or better) of engineers to managers, versus the 1:1 found at many companies. Get religion about skills. Rewired companies develop very granular skill progression grids supported by credentials. For example, Big Tech companies have up to ten levels of data engineers, each with different skill levels and compensation ranges. Without a precise calibration of skills, it becomes difficult to recognize distinctive technologists and compensate them accordingly. Skill progression also gets built into expert-based career tracks and in learning and development programs. In short, the whole digital-talent model revolves around fostering excellence in people devoted to their craft. Build the team that will build your digital bench. Many HR organizations are hampered by slow recruiting and onboarding processes, rigid compensation frameworks, and outdated learning and development programs for digital talent. But transforming your entire HR organization and underlying HR processes to make them digital ready may not be practical. Setting up a special team focused on adapting current HR processes to win digital talent is the most pragmatic—and successful—way forward. We call this designated team the Talent Win Room (TWR). The primary mission of a TWR is to find technologists with the right skills and to build and continually improve all facets of both the candidate and employee experience. These shifts in talent practices are not simple, but they are fundamental to becoming rewired with the right talent. While every C-suite executive will have a part to play in this talent reinvention, this is often the chief human resources officer’s signature contribution to the enterprise’s digital transformation. Adopt a new operating model that can scale Most companies have succeeded in standing up a handful of cross-functional agile teams. But scaling up so that hundreds or even thousands of teams work that way, as rewired businesses do, is a daunting challenge. Developing the right operating model to bring business, technology, and operations closer together is perhaps the most complex aspect of a digital and AI transformation because it touches the core of the organization and how people work. Developing the right operating model to bring business, technology, and operations closer together is perhaps the most complex aspect of a digital and AI transformation. Three leading models have emerged: digital factory, product and platform, and enterprise-wide agile. Each of these models is built on two core ideas. The first is that small, multidisciplinary agile teams, or pods, are the most effective and efficient way to develop software. Second, pods work together most effectively when some are focused on directly improving a customer or user experience (generally called product pods, although they can also be called experience or journey pods) while others focus on creating reusable services to accelerate the work of all pods (called platform pods). Examples of such services could include a customer-360 data set or an easy way for teams to provision compute and storage capacity. The implementation of a new operating model is, in our opinion, one of the most significant pivots a company can make to become a rewired enterprise. There are two key moves to getting this right. Select an operating model that supports your strategy. The digital factory is a separate organizational unit where people work together to build digital solutions for the business units or functions that fund the digital factory. Companies often initially select the digital-factory model because it is a self-contained operating unit and can be implemented relatively quickly (typically 12 to 18 months before it’s fully operational, though it can get started in a matter of weeks). BHP and Scotiabank, for example, have implemented this model. The product and platform model is a more evolved version of the digital factory. While the digital factory might contain 20 to 50 pods, the product and platform model will typically have a few hundred pods, sometimes thousands for large companies. When companies move to a product and platform model, they are making a major strategic decision to realign large parts of the organization to better exploit technology in their core business. Amazon, Google, Itaú Unibanco, and JPMorgan Chase have all implemented this model. Finally, the enterprise-wide agile model builds on the product and platform model and extends the benefit of agile to the entire business, not just the technology-intensive areas. For example, key account sales and R&D can also benefit from working in small, cross-functional teams. Companies adopt this model when they believe that customer centricity, collaboration, and flexible resource deployment are key performance differentiators across the entire enterprise. ING and Spark New Zealand have successfully implemented this model. Professionalize product management. A crucial difference between tech companies and their peers in other sectors is the degree to which they have embedded product management capabilities in their operating models. This capability, in our opinion, makes or breaks the implementation of a new operating model. Some 75 percent of business leaders in a McKinsey survey responded that product management best practices aren’t being adopted at their companies, that product management is a nascent function within their organizations, or that it doesn’t exist at all. 2 Chandra Gnanasambandam, Martin Harrysson, Jeremy Schneider, and Rikki Singh, “ What separates top product managers from the rest of the pack ,” McKinsey, January 20, 2023. That’s a problem. It’s also hard to recruit great product managers because understanding the industry and the company context matters. Most companies end up reskilling and building new career tracks for this rare talent, but this requires substantial investments to ensure good results. The shift to a new operating model is the signature move of CEOs in rewiring the company. Only they can catalyze such large-scale organizational change. Technology for speed and distributed innovation The main purpose of technology within a rewired company is to make it easy for hundreds, if not thousands, of pods to constantly develop and release digital innovations. This requires a distributed technology environment where every pod can access the software development tools, data, and applications they need. While leaders hoping to create that environment have a raft of decisions to make, three priorities stand out. Kit out a technology toolbox. Just like woodworkers, surgeons, or plumbers, software developers need the proper tools to do their work. As an organization scales from five agile pods to 100, or even more than 1,000, it doesn’t make sense for pod members to be calling IT every time they have a basic request, such as additional storage capacity or access to a collaboration tool. Leading companies build a developer platform: a self-service portal that makes it easy to access and use all the standardized and company-approved tools. Use APIs without exception. Once developers have their tools, they need access to data and existing app functionalities to build their solutions. Application programming interfaces (APIs) do that by systematically minimizing dependencies in the architecture by making application functionalities and data easily accessible. Without it, pods will constantly find themselves depending on other pods. Amazon’s Jeff Bezos was so adamant about using APIs that he wrote a famous memo about it, which fundamentally changed Amazon and the world of software. The memo essentially said that all teams were expected to expose their data and functionality through service interfaces (that is, APIs) and to communicate with one another through only these interfaces. No other form of inter-process communication would be allowed. No exceptions. Automate software delivery. Have you ever wondered how an app on your phone can be upgraded so frequently? That seamless functionality is made possible by software delivery automation, also known as CI/CD: continuous integration and continuous delivery. This is the method for systematically automating all steps, including quality checks, testing, packaging (that is, containerization), and staged deployment of the solution to the user. With CI/CD, updates that used to take weeks or months can now be completed in minutes, allowing pods to release incremental improvements weekly or even daily and thus unleash much faster innovation cycles. You won’t be able to achieve distributed digital and AI innovation if pods aren’t able to release code to a production environment quickly and easily. This fixation on automation needs to carry over to AI and machine-learning (ML) models. These models are like living organisms—they need to be constantly recalibrated as new data accumulate and then monitored in real time for drift and biases. When this doesn’t happen, AI/ML models fail to transition to full-scale production. Solving for this has required a specialized type of automation called machine learning operations (MLOps). For example, Vistra, a leading energy company, built MLOps automation to support more than 400 AI/ML models deployed to optimize different parts of its power plant operations. Most CIOs have started their companies’ journey to build a robust developer platform, decouple the components of the architecture from one another through APIs, and automate their software delivery pipeline. But we know very few companies that have scaled this across their enterprise. The change management efforts are significant, and the software engineering talent required is in short supply. Creating a technology environment that enables distributed digital and AI innovations is a cornerstone capability of rewired enterprises and a signature contribution by the CIO, the chief data officer (CDO), or both. Embed data everywhere In established companies, data is often a source of frustration. As much as 70 percent of the effort involved in developing AI-based solutions can be attributed to wrangling and harmonizing data. Unless data is thoughtfully sorted and organized for easy consumption and reuse, scaling solutions can be a big challenge. The ability to constantly improve customer experience and drive down unit cost depends on giving each digital and AI team (near) real-time access to data. Companies can focus on three areas to achieve this. Turn to reusable building blocks: data products. Data products are the secret sauce for scaling AI. They help deliver data-intensive applications as much as 90 percent faster, at 30 percent lower cost, and with a reduced risk and data governance burden. A data product delivers a high-quality, ready-to-use set of data in a way that people and applications across the organization can easily access and consume. For example, a data product could provide a 360-degree view of an important entity, such as customers, employees, product lines, or stores. Companies can prioritize building data products that have the broadest application, that are critical for teams developing priority solutions, and that are unique. Building data products requires dedicated teams and investments. Install the data architecture ‘plumbing.’ Data architecture is the system of “pipes” that deliver data from where it is stored to where it is used. When implemented well, data architecture hastens a company’s ability to build reusable and high-quality data products and to put data within reach of any team in the organization. We have seen very rapid technological progress in this field. The emergence of new architectural patterns such as the “data lakehouse” (an innovation that combines the capabilities of a data lake and a data warehouse into a single, integrated platform) makes it easier for companies to solve for both their business intelligence and their AI needs. Federate data governance. Data touches all aspects of an organization, so its governance needs to account for that complexity. Rewired companies deploy a federated model where a central function (that is, a data management office) sets policies and standards and provides support and oversight, while business units and functions manage activities such as developing data products and building data pipelines to enable consumption. A data environment that allows for easy data consumption by hundreds of distributed teams is another signature move of the CIO in collaboration with the CDO. It enables data-driven decisions, feeds real-time decision-making systems, and propels faster continuous-improvement loops. Unlocking adoption and scaling Developing a good digital solution can be complex and difficult. But getting customers or business users to adopt that solution as part of their day-to-day activities and then scaling that solution across the enterprise are often the biggest challenges. Successful companies concentrate on the following three moves. Focus equally on adoption and development. User adoption starts with developing great technology solutions that offer an excellent customer experience. But companies often underestimate all the additional elements of the business model that need to be changed to secure adoption. For instance, an insurance company that developed analytic solutions to help agents upsell customers on policies also needed to make changes to pricing algorithms, sales force incentives, distribution and customer engagement models, and metrics and performance indicators. That end-to-end system approach, with a focus on the people side of the equation, is what differentiates digital leaders. They achieve this by making the business accountable for the end-to-end transformation of the domain. As a rule, for every $1 spent on developing digital and AI solutions, plan to spend at least another $1 to ensure full user adoption and scaling across the enterprise. Scale with ‘assetizing.’ Replicating the adoption of a solution in different environments, such as a network of plants, or in different geographic markets, customer segments, or organizational groups is challenging. Companies often find themselves redoing a lot of work and struggling to tailor solutions to local environments. All this extra work is a scale killer, and that’s why 72 percent of companies stall at this stage. Digital leaders solve this by “assetizing” solutions, which typically allows 60 to 90 percent of a digital and AI solution to be reused, leaving just 10 to 40 percent in need of local customization. Track what matters. No one will debate the need to measure the progress of a digital transformation. But the question is what to measure and how. Performance tracking that is poorly designed and lacking the right supporting tools can quickly crumble under its own weight. Rewired companies take the pods responsible for objectives and key results and link them to operational KPIs, tracking the progression of each pod in a disciplined stage gate review process. The ability to capture the full economic potential of digital innovations is a core differentiator between digital leaders and laggards. Building this capability is the signature move of business unit and function leaders. The capabilities we have laid out for a successful digital and AI transformation present a rich “how to” agenda. You may be wondering where to start your rewiring journey. Why not start where we began this article: by bringing the top team together and having them reflect on your journey thus far? A digital and AI transformation is ultimately an exercise in constant evolution and improvement. If you accept this premise, it will change your perspective on how you approach this critical challenge. To borrow Jeff Bezos’s expression to Amazon shareholders about the importance of operating like a digital native: it’s always day one for digital and AI transformation. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles Rewired Author Talks: What is the key to unlocking digital transformation? Three new mandates for capturing a digital transformation’s full value'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:43 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:43 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:43 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:43 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:43 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:43 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:45 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'1013'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'190559'), (b'x-ratelimit-reset-requests', b'1m11.495s'), (b'x-ratelimit-reset-tokens', b'2.832s'), (b'x-request-id', b'req_74851e02680ef98101ca09958bd1033f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c53af991131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:45 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:45 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:45 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:45 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:45 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:45 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '1013', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '190559', 'x-ratelimit-reset-requests': '1m11.495s', 'x-ratelimit-reset-tokens': '2.832s', 'x-request-id': 'req_74851e02680ef98101ca09958bd1033f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c53af991131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:45 [openai._base_client] DEBUG: request_id: req_74851e02680ef98101ca09958bd1033f
2024-08-20 02:07:45 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Companies face the challenge of navigating digital transformation to achieve sustainable competitive advantage, yet many struggle to realize benefits. Successful transformation requires integrating technology, upskilling talent, and adopting a new operating model. Collaboration across the C-suite is essential, with ongoing improvements
2024-08-20 02:07:45 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:45 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:45 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:45 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:45 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A7%3AG7 HTTP/11" 200 None
2024-08-20 02:07:45 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A7%3AG7?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/rewired-to-outcompete>
{'title': 'Rewired to outcompete', 'description': 'Six signature moves led by the C-suite can build organizations that will outperform in the age of digital and AI.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/rewired-to-outcompete', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/rewired%20to%20outcompete/qweb-rewired-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2023-06-20T12:00:00Z', 'article_text': 'Rewired to outcompete How companies navigate the technology world to achieve sustainable competitive advantage is the defining business challenge of our time. To be fair, this challenge isn’t new. But it’s an increasingly pressing one, with deep implications for how companies navigate a world where digital and AI are fundamentally reshaping how we work and live. Companies understand they need to meet the challenge, but most of them are struggling. McKinsey research shows that while 90 percent of companies have launched some flavor of digital transformation, only a third of the expected revenue benefits, on average, have been realized . 1 “ Three new mandates for capturing a digital transformation’s full value ,” McKinsey, June 15, 2022. Yet it’s also a challenge with enormous potential for the companies that get it right. In the banking sector, for example, where digital and AI transformations have been under way for the past decade, compelling empirical data shows that digitally transformed banks outperform their peers. We leveraged a unique data set, Finalta by McKinsey, to analyze 20 digital leaders and 20 digital laggards in retail banking between 2018 and 2022. The results were startling. Digital leaders improved their return on tangible equity, their P/E ratio, and their total shareholder returns materially more than digital laggards (Exhibit 1). Digital excellence is translating into financial outperformance. This outperformance was propelled by a deeper integration of technology across end-to-end core business processes. This, in turn, drove higher digital sales and lower costs in branches and operations. How did the digital leaders accomplish this? By bringing business, technology, and operations more closely together to digitally innovate; by upskilling their organizations; and by building a distributed technology and data environment to empower hundreds if not thousands of teams to digitally innovate, day in, day out. This gets at the nub of why digital and AI transformations are so difficult—companies need to get a lot of things right. Clearly, for digital and AI to deliver on their business transformation potential, the top team needs to be ready and willing to undertake the organizational “surgery” required to become a digitally capable enterprise. There are no quick fixes. You can’t simply implement a system or a technology and be done. Instead, success means having hundreds of technology-driven solutions (proprietary and off the shelf) working together that you continually improve to create great customer and employee experiences, lower unit costs, and generate value. But creating, managing, and evolving these solutions at enterprise scale requires a fundamental rewiring of how a company operates. That means getting thousands of people across different units of the organization working together and working differently to digitally innovate, constantly. Creating value beyond the hype The lessons learned from our work with more than 200 large companies across multiple industries show that capturing this kind of value from digital and AI requires building six critical enterprise capabilities (Exhibit 2). These allow rewired companies to integrate new technologies, such as generative AI, and harness them to create value. While companies may understand this at a high level, they struggle with how to build these capabilities successfully and ensure that they work together across the enterprise. Our new book, Rewired: The McKinsey Guide to Outcompeting in the Age of Digital and AI , is all about the how . This article is adapted from that book and delineates the core aspects of what it takes for leaders to spur transformation across all six capabilities. Before we go into detail, it’s worth highlighting two key findings. First, no digital and AI transformation can be successful without building a baseline of competence across all six capabilities. Second, these elements are interconnected and need to be managed that way: a good operating model, for example, can’t work without the right talent. Similarly, great technology won’t make much of an impact if users don’t adopt it. You do not have to be a tech company to achieve excellence in digital and AI. Large, established companies can outcompete and capture value, but only when they are willing to commit to the hard work of rewiring their enterprise. This is a job for the entire C-suite, not just the CEO or the chief information officer (CIO). The cross-functional nature of a digital and AI transformation requires an unparalleled level of collaboration across the C-suite, with everyone having an important part to play in building these enterprise capabilities. Rewiring the business is an ongoing journey of improvement, not a destination. Let’s dig into the details of that journey. Align the C-suite around a business-led road map When evaluating stalled digital and AI transformations, we find that many of the issues that impede a program’s success can be traced back to insufficient planning and alignment. Misunderstanding among leadership at the strategic-planning stage will invariably lead to muddled execution in a company’s transformation. Because digital and AI transformations affect so many parts of the business, investing the necessary time to help make the transformation a success pays significant dividends in terms of clarity and unified action. The best companies make sure to get three early moves right. Inspire and align the top team. Take the time to establish a common digital language, learn from other companies that are further along the journey, develop a shared vision among the C-suite, and explicitly agree on a set of commitments that match your ambitions. Consider the example of DBS Bank, one of the world’s most successful digitally transformed banks . CEO Piyush Gupta and his top leaders visited and learned from top tech companies around the globe and used those lessons to shape a vision around “Making Banking Joyful” and to commit to making DBS a tech leader. This kind of leadership alignment is crucial to ensuring a successful digital and AI transformation. Get the ‘bite’ size right: business domains. Some companies struggle from the start of their digital and AI transformation by getting the scope of the change wrong. They start too small—believing that implementing a few use cases will lower risk—or they spread bets and resources too thinly across an uncoordinated set of initiatives. Both approaches typically produce little value. Successful companies, on the other hand, focus their efforts on a few important business domains, such as a production process or the customer journey, and transform them from end to end. As many as 80 percent of successful interventions in struggling digital and AI transformations are based on reanchoring the scope to spur a concerted effort against a few well-defined domains. Commit to a contract with the C-suite. Effective rewiring requires companies to tie the transformation outcomes of each business domain to specific improvements in operational KPIs, such as reduction in customer churn or improvements in process yield. The team builds a road map where the digital solutions that underpin these KPI improvements are sequenced in a way to produce meaningful value in the short term (say, 12 to 18 months) and transformational value in the medium term (three to five years, for example). The plan explicitly accounts for the build-out of enterprise capabilities, such as hiring digital talent or modernizing data architecture. C-suite leaders commit to these KPI improvements, and the expected benefits are baked into their business objectives. Our rule of thumb is that a robust digital road map should deliver EBIT improvement of\n20 percent or more. When business leaders define an ambitious yet realistic transformation of their business domains with technology, they set in motion the flywheel of digital change. The resulting digital road map is their signature move and effectively acts as a contract that they commit to implementing. When business leaders define an ambitious yet realistic transformation of their business domains with technology, they set in motion the flywheel of digital change. Build your talent bench No company can outsource its way to digital excellence. Being digital means having your own bench of digital talent—product owners, experience designers, cloud engineers, software developers, and so on—working side by side with your business colleagues. Digital transformations are, first and foremost, people transformations. The following are three actions that digital leaders take. Create a cleansheet for your talent. Most companies have digital technologists, but many still face the hard work of reskilling their technology and IT organization. The aspiration should be to have 70 to 80 percent of your digital talent in-house, with 20 to 30 percent coming from outside the company and focused on specialized skills, flexibility, or both. Your talent pyramid should shift to a diamond shape, with more competent technologists and fewer novices. That’s because there is a step change in productivity from more experienced technologists. You should also have a healthy ratio of hands-on-keyboard technologists versus managerial roles. Rewired leaders target a 4:1 ratio (or better) of engineers to managers, versus the 1:1 found at many companies. Get religion about skills. Rewired companies develop very granular skill progression grids supported by credentials. For example, Big Tech companies have up to ten levels of data engineers, each with different skill levels and compensation ranges. Without a precise calibration of skills, it becomes difficult to recognize distinctive technologists and compensate them accordingly. Skill progression also gets built into expert-based career tracks and in learning and development programs. In short, the whole digital-talent model revolves around fostering excellence in people devoted to their craft. Build the team that will build your digital bench. Many HR organizations are hampered by slow recruiting and onboarding processes, rigid compensation frameworks, and outdated learning and development programs for digital talent. But transforming your entire HR organization and underlying HR processes to make them digital ready may not be practical. Setting up a special team focused on adapting current HR processes to win digital talent is the most pragmatic—and successful—way forward. We call this designated team the Talent Win Room (TWR). The primary mission of a TWR is to find technologists with the right skills and to build and continually improve all facets of both the candidate and employee experience. These shifts in talent practices are not simple, but they are fundamental to becoming rewired with the right talent. While every C-suite executive will have a part to play in this talent reinvention, this is often the chief human resources officer’s signature contribution to the enterprise’s digital transformation. Adopt a new operating model that can scale Most companies have succeeded in standing up a handful of cross-functional agile teams. But scaling up so that hundreds or even thousands of teams work that way, as rewired businesses do, is a daunting challenge. Developing the right operating model to bring business, technology, and operations closer together is perhaps the most complex aspect of a digital and AI transformation because it touches the core of the organization and how people work. Developing the right operating model to bring business, technology, and operations closer together is perhaps the most complex aspect of a digital and AI transformation. Three leading models have emerged: digital factory, product and platform, and enterprise-wide agile. Each of these models is built on two core ideas. The first is that small, multidisciplinary agile teams, or pods, are the most effective and efficient way to develop software. Second, pods work together most effectively when some are focused on directly improving a customer or user experience (generally called product pods, although they can also be called experience or journey pods) while others focus on creating reusable services to accelerate the work of all pods (called platform pods). Examples of such services could include a customer-360 data set or an easy way for teams to provision compute and storage capacity. The implementation of a new operating model is, in our opinion, one of the most significant pivots a company can make to become a rewired enterprise. There are two key moves to getting this right. Select an operating model that supports your strategy. The digital factory is a separate organizational unit where people work together to build digital solutions for the business units or functions that fund the digital factory. Companies often initially select the digital-factory model because it is a self-contained operating unit and can be implemented relatively quickly (typically 12 to 18 months before it’s fully operational, though it can get started in a matter of weeks). BHP and Scotiabank, for example, have implemented this model. The product and platform model is a more evolved version of the digital factory. While the digital factory might contain 20 to 50 pods, the product and platform model will typically have a few hundred pods, sometimes thousands for large companies. When companies move to a product and platform model, they are making a major strategic decision to realign large parts of the organization to better exploit technology in their core business. Amazon, Google, Itaú Unibanco, and JPMorgan Chase have all implemented this model. Finally, the enterprise-wide agile model builds on the product and platform model and extends the benefit of agile to the entire business, not just the technology-intensive areas. For example, key account sales and R&D can also benefit from working in small, cross-functional teams. Companies adopt this model when they believe that customer centricity, collaboration, and flexible resource deployment are key performance differentiators across the entire enterprise. ING and Spark New Zealand have successfully implemented this model. Professionalize product management. A crucial difference between tech companies and their peers in other sectors is the degree to which they have embedded product management capabilities in their operating models. This capability, in our opinion, makes or breaks the implementation of a new operating model. Some 75 percent of business leaders in a McKinsey survey responded that product management best practices aren’t being adopted at their companies, that product management is a nascent function within their organizations, or that it doesn’t exist at all. 2 Chandra Gnanasambandam, Martin Harrysson, Jeremy Schneider, and Rikki Singh, “ What separates top product managers from the rest of the pack ,” McKinsey, January 20, 2023. That’s a problem. It’s also hard to recruit great product managers because understanding the industry and the company context matters. Most companies end up reskilling and building new career tracks for this rare talent, but this requires substantial investments to ensure good results. The shift to a new operating model is the signature move of CEOs in rewiring the company. Only they can catalyze such large-scale organizational change. Technology for speed and distributed innovation The main purpose of technology within a rewired company is to make it easy for hundreds, if not thousands, of pods to constantly develop and release digital innovations. This requires a distributed technology environment where every pod can access the software development tools, data, and applications they need. While leaders hoping to create that environment have a raft of decisions to make, three priorities stand out. Kit out a technology toolbox. Just like woodworkers, surgeons, or plumbers, software developers need the proper tools to do their work. As an organization scales from five agile pods to 100, or even more than 1,000, it doesn’t make sense for pod members to be calling IT every time they have a basic request, such as additional storage capacity or access to a collaboration tool. Leading companies build a developer platform: a self-service portal that makes it easy to access and use all the standardized and company-approved tools. Use APIs without exception. Once developers have their tools, they need access to data and existing app functionalities to build their solutions. Application programming interfaces (APIs) do that by systematically minimizing dependencies in the architecture by making application functionalities and data easily accessible. Without it, pods will constantly find themselves depending on other pods. Amazon’s Jeff Bezos was so adamant about using APIs that he wrote a famous memo about it, which fundamentally changed Amazon and the world of software. The memo essentially said that all teams were expected to expose their data and functionality through service interfaces (that is, APIs) and to communicate with one another through only these interfaces. No other form of inter-process communication would be allowed. No exceptions. Automate software delivery. Have you ever wondered how an app on your phone can be upgraded so frequently? That seamless functionality is made possible by software delivery automation, also known as CI/CD: continuous integration and continuous delivery. This is the method for systematically automating all steps, including quality checks, testing, packaging (that is, containerization), and staged deployment of the solution to the user. With CI/CD, updates that used to take weeks or months can now be completed in minutes, allowing pods to release incremental improvements weekly or even daily and thus unleash much faster innovation cycles. You won’t be able to achieve distributed digital and AI innovation if pods aren’t able to release code to a production environment quickly and easily. This fixation on automation needs to carry over to AI and machine-learning (ML) models. These models are like living organisms—they need to be constantly recalibrated as new data accumulate and then monitored in real time for drift and biases. When this doesn’t happen, AI/ML models fail to transition to full-scale production. Solving for this has required a specialized type of automation called machine learning operations (MLOps). For example, Vistra, a leading energy company, built MLOps automation to support more than 400 AI/ML models deployed to optimize different parts of its power plant operations. Most CIOs have started their companies’ journey to build a robust developer platform, decouple the components of the architecture from one another through APIs, and automate their software delivery pipeline. But we know very few companies that have scaled this across their enterprise. The change management efforts are significant, and the software engineering talent required is in short supply. Creating a technology environment that enables distributed digital and AI innovations is a cornerstone capability of rewired enterprises and a signature contribution by the CIO, the chief data officer (CDO), or both. Embed data everywhere In established companies, data is often a source of frustration. As much as 70 percent of the effort involved in developing AI-based solutions can be attributed to wrangling and harmonizing data. Unless data is thoughtfully sorted and organized for easy consumption and reuse, scaling solutions can be a big challenge. The ability to constantly improve customer experience and drive down unit cost depends on giving each digital and AI team (near) real-time access to data. Companies can focus on three areas to achieve this. Turn to reusable building blocks: data products. Data products are the secret sauce for scaling AI. They help deliver data-intensive applications as much as 90 percent faster, at 30 percent lower cost, and with a reduced risk and data governance burden. A data product delivers a high-quality, ready-to-use set of data in a way that people and applications across the organization can easily access and consume. For example, a data product could provide a 360-degree view of an important entity, such as customers, employees, product lines, or stores. Companies can prioritize building data products that have the broadest application, that are critical for teams developing priority solutions, and that are unique. Building data products requires dedicated teams and investments. Install the data architecture ‘plumbing.’ Data architecture is the system of “pipes” that deliver data from where it is stored to where it is used. When implemented well, data architecture hastens a company’s ability to build reusable and high-quality data products and to put data within reach of any team in the organization. We have seen very rapid technological progress in this field. The emergence of new architectural patterns such as the “data lakehouse” (an innovation that combines the capabilities of a data lake and a data warehouse into a single, integrated platform) makes it easier for companies to solve for both their business intelligence and their AI needs. Federate data governance. Data touches all aspects of an organization, so its governance needs to account for that complexity. Rewired companies deploy a federated model where a central function (that is, a data management office) sets policies and standards and provides support and oversight, while business units and functions manage activities such as developing data products and building data pipelines to enable consumption. A data environment that allows for easy data consumption by hundreds of distributed teams is another signature move of the CIO in collaboration with the CDO. It enables data-driven decisions, feeds real-time decision-making systems, and propels faster continuous-improvement loops. Unlocking adoption and scaling Developing a good digital solution can be complex and difficult. But getting customers or business users to adopt that solution as part of their day-to-day activities and then scaling that solution across the enterprise are often the biggest challenges. Successful companies concentrate on the following three moves. Focus equally on adoption and development. User adoption starts with developing great technology solutions that offer an excellent customer experience. But companies often underestimate all the additional elements of the business model that need to be changed to secure adoption. For instance, an insurance company that developed analytic solutions to help agents upsell customers on policies also needed to make changes to pricing algorithms, sales force incentives, distribution and customer engagement models, and metrics and performance indicators. That end-to-end system approach, with a focus on the people side of the equation, is what differentiates digital leaders. They achieve this by making the business accountable for the end-to-end transformation of the domain. As a rule, for every $1 spent on developing digital and AI solutions, plan to spend at least another $1 to ensure full user adoption and scaling across the enterprise. Scale with ‘assetizing.’ Replicating the adoption of a solution in different environments, such as a network of plants, or in different geographic markets, customer segments, or organizational groups is challenging. Companies often find themselves redoing a lot of work and struggling to tailor solutions to local environments. All this extra work is a scale killer, and that’s why 72 percent of companies stall at this stage. Digital leaders solve this by “assetizing” solutions, which typically allows 60 to 90 percent of a digital and AI solution to be reused, leaving just 10 to 40 percent in need of local customization. Track what matters. No one will debate the need to measure the progress of a digital transformation. But the question is what to measure and how. Performance tracking that is poorly designed and lacking the right supporting tools can quickly crumble under its own weight. Rewired companies take the pods responsible for objectives and key results and link them to operational KPIs, tracking the progression of each pod in a disciplined stage gate review process. The ability to capture the full economic potential of digital innovations is a core differentiator between digital leaders and laggards. Building this capability is the signature move of business unit and function leaders. The capabilities we have laid out for a successful digital and AI transformation present a rich “how to” agenda. You may be wondering where to start your rewiring journey. Why not start where we began this article: by bringing the top team together and having them reflect on your journey thus far? A digital and AI transformation is ultimately an exercise in constant evolution and improvement. If you accept this premise, it will change your perspective on how you approach this critical challenge. To borrow Jeff Bezos’s expression to Amazon shareholders about the importance of operating like a digital native: it’s always day one for digital and AI transformation. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles Rewired Author Talks: What is the key to unlocking digital transformation? Three new mandates for capturing a digital transformation’s full value', 'summary': 'Companies face the challenge of navigating digital transformation to achieve sustainable competitive advantage, yet many struggle to realize benefits. Successful transformation requires integrating technology, upskilling talent, and adopting a new operating model. Collaboration across the C-suite is essential, with ongoing improvements'}
2024-08-20 02:07:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/technologys-generational-moment-with-generative-ai-a-cio-and-cto-guide> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:46 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nTechnology’s generational moment with generative AI: A CIO and CTO guide Hardly a day goes by without some new business-busting development related to generative AI surfacing in the media. The excitement is well deserved— McKinsey research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion of value annually. 1 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. About the authors This article is a collaborative effort by Aamer Baig , Sven Blumberg , Eva Li, Douglas Merrill, Adi Pradhan, Megha Sinha, Alexander Sukharevsky , and Stephen Xu, representing views from McKinsey Digital. CIOs and chief technology officers (CTOs) have a critical role in capturing that value, but it’s worth remembering we’ve seen this movie before. New technologies emerged—the internet, mobile, social media—that set off a melee of experiments and pilots, though significant business value often proved harder to come by. Many of the lessons learned from those developments still apply, especially when it comes to getting past the pilot stage to reach scale. For the CIO and CTO, the generative AI boom presents a unique opportunity to apply those lessons to guide the C-suite in turning the promise of generative AI into sustainable value for the business. A quick primer on key terms Generative AI is a type of AI that can create new content (text, code, images, video) using patterns it has learned by training on extensive (public) data with machine learning (ML) techniques. Foundation models (FMs) are deep learning models trained on vast quantities of unstructured, unlabeled data that can be used for a wide range of tasks out of the box or adapted to specific tasks through fine-tuning. Examples of these models are GPT-4, PaLM 2, DALL·E 2, and Stable Diffusion. Large language models (LLMs) make up a class of foundation models that can process massive amounts of unstructured text and learn the relationships between words or portions of words, known as tokens. This enables LLMs to generate natural-language text, performing tasks such as summarization or knowledge extraction. Cohere Command is one type of LLM; LaMDA is the LLM behind Bard. Fine-tuning is the process of adapting a pretrained foundation model to perform better in a specific task. This entails a relatively short period of training on a labeled data set, which is much smaller than the data set the model was initially trained on. This additional training allows the model to learn and adapt to the nuances, terminology, and specific patterns found in the smaller data set. Prompt engineering refers to the process of designing, refining, and optimizing input prompts to guide a generative AI model toward producing desired (that is, accurate) outputs. Through conversations with dozens of tech leaders and an analysis of generative AI initiatives at more than 50 companies (including our own), we have identified nine actions all technology leaders can take to create value, orchestrate technology and data, scale solutions, and manage risk for generative AI (see sidebar, “A quick primer on key terms”): Creating value beyond the hype 1. Determine the company’s posture for the adoption of generative AI As use of generative AI becomes increasingly widespread, we have seen CIOs and CTOs respond by blocking employee access to publicly available applications to limit risk. In doing so, these companies risk missing out on opportunities for innovation, with some employees even perceiving these moves as limiting their ability to build important new skills. Instead, CIOs and CTOs should work with risk leaders to balance the real need for risk mitigation with the importance of building generative AI skills in the business. This requires establishing the company’s posture regarding generative AI by building consensus around the levels of risk with which the business is comfortable and how generative AI fits into the business’s overall strategy. This step allows the business to quickly determine company-wide policies and guidelines. Once policies are clearly defined, leaders should communicate them to the business, with the CIO and CTO providing the organization with appropriate access and user-friendly guidelines. Some companies have rolled out firmwide communications about generative AI, provided broad access to generative AI for specific user groups, created pop-ups that warn users any time they input internal data into a model, and built a guidelines page that appears each time users access a publicly available generative AI service. 2. Identify use cases that build value through improved productivity, growth, and new business models CIOs and CTOs should be the antidote to the “death by use case” frenzy that we already see in many companies. They can be most helpful by working with the CEO, CFO, and other business leaders to think through how generative AI challenges existing business models, opens doors to new ones, and creates new sources of value. With a deep understanding of the technical possibilities, the CIO and CTO should identify the most valuable opportunities and issues across the company that can benefit from generative AI—and those that can’t. In some cases, generative AI is not the best option. McKinsey research , for example, shows generative AI can lift productivity for certain marketing use cases (for example, by analyzing unstructured and abstract data for customer preference) by roughly 10 percent and customer support (for example, through intelligent bots) by up to 40 percent. 2 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. The CIO and CTO can be particularly helpful in developing a perspective on how best to cluster use cases either by domain (such as customer journey or business process) or use case type (such as creative content creation or virtual agents) so that generative AI will have the most value. Identifying opportunities won’t be the most strategic task—there are many generative AI use cases out there—but, given initial limitations of talent and capabilities, the CIO and CTO will need to provide feasibility and resource estimates to help the business sequence generative AI priorities. Providing this level of counsel requires tech leaders to work with the business to develop a FinAI capability to estimate the true costs and returns on generative AI initiatives. Cost calculations can be particularly complex because the unit economics must account for multiple model and vendor costs, model interactions (where a query might require input from multiple models, each with its own fee), ongoing usage fees, and human oversight costs. 3. Reimagine the technology function Generative AI has the potential to completely remake how the tech function works. CIOs and CTOs need to make a comprehensive review of the potential impact of generative AI on all areas of tech, but it’s important to take action quickly to build experience and expertise. There are three areas where they can focus their initial energies: 4. Take advantage of existing services or adapt open-source generative AI models A variation of the classic “rent, buy, or build” decision exists when it comes to strategies for developing generative AI capabilities. The basic rule holds true: a company should invest in a generative AI capability where it can create a proprietary advantage for the business and access existing services for those that are more like commodities. The CIO and CTO can think through the implications of these options as three archetypes: Each archetype has its own costs that tech leaders will need to consider (Exhibit 1). While new developments, such as efficient model training approaches and lower graphics processing unit (GPU) compute costs over time, are driving costs down, the inherent complexity of the Maker archetype means that few organizations will adopt it in the short term. Instead, most will turn to some combination of Taker, to quickly access a commodity service, and Shaper, to build a proprietary capability on top of foundation models. 5. Upgrade your enterprise technology architecture to integrate and manage generative AI models Organizations will use many generative AI models of varying size, complexity, and capability. To generate value, these models need to be able to work both together and with the business’s existing systems or applications. For this reason, building a separate tech stack for generative AI creates more complexities than it solves. As an example, we can look at a consumer querying customer service at a travel company to resolve a booking issue (Exhibit 2). In interacting with the customer, the generative AI model needs to access multiple applications and data sources. For the Taker archetype, this level of coordination isn’t necessary. But for companies looking to scale the advantages of generative AI as Shapers or Makers, CIOs and CTOs need to upgrade their technology architecture. The prime goal is to integrate generative AI models into internal systems and enterprise applications and to build pipelines to various data sources. Ultimately, it’s the maturity of the business’s enterprise technology architecture that allows it to integrate and scale its generative AI capabilities. Recent advances in integration and orchestration frameworks, such as LangChain and LlamaIndex, have significantly reduced the effort required to connect different generative AI models with other applications and data sources. Several integration patterns are also emerging, including those that enable models to call APIs when responding to a user query—GPT-4, for example, can invoke functions—and provide contextual data from an external data set as part of a user query, a technique known as retrieval augmented generation. Tech leaders will need to define reference architectures and standard integration patterns for their organization (such as standard API formats and parameters that identify the user and the model invoking the API). There are five key elements that need to be incorporated into the technology architecture to integrate generative AI effectively (Exhibit 3): In evolving the architecture, CIOs and CTOs will need to navigate a rapidly growing ecosystem of generative AI providers and tooling. Cloud providers provide extensive access to at-scale hardware and foundation models, as well as a proliferating set of services. MLOps and model hub providers, meanwhile, offer the tools, technologies, and practices to adapt a foundation model and deploy it into production, while other companies provide applications directly accessed by users built on top of foundation models to perform specific tasks. CIOs and CTOs will need to assess how these various capabilities are assembled and integrated to deploy and operate generative AI models. 6. Develop a data architecture to enable access to quality data The ability of a business to generate and scale value, including cost reductions and improved data and knowledge protections, from generative AI models will depend on how well it takes advantage of its own data. Creating that advantage relies on a data architecture that connects generative AI models to internal data sources, which provide context or help fine-tune the models to create more relevant outputs. In this context, CIOs, CTOs, and chief data officers need to work closely together to do the following: McKinsey launches new product suite to help clients scale AI 7. Create a centralized, cross-functional generative AI platform team Most tech organizations are on a journey to a product and platform operating model . CIOs and CTOs need to integrate generative AI capabilities into this operating model to build on the existing infrastructure and help to rapidly scale adoption of generative AI. The first step is setting up a generative AI platform team whose core focus is developing and maintaining a platform service where approved generative AI models can be provisioned on demand for use by product and application teams. The platform team also defines protocols for how generative AI models integrate with internal systems, enterprise applications, and tools, and also develops and implements standardized approaches to manage risk, such as responsible AI frameworks. CIOs and CTOs need to ensure that the platform team is staffed with people who have the right skills. This team requires a senior technical leader who acts as the general manager. Key roles include software engineers to integrate generative AI models into existing systems, applications, and tools; data engineers to build pipelines that connect models to various systems of record and data sources; data scientists to select models and engineer prompts; MLOps engineers to manage deployment and monitoring of multiple models and model versions; ML engineers to fine-tune models with new data sources; and risk experts to manage security issues such as data leakage, access controls, output accuracy, and bias. The exact composition of the platform team will depend on the use cases being served across the enterprise. In some instances, such as creating a customer-facing chatbot, strong product management and user experience (UX) resources will be required. Realistically, the platform team will need to work initially on a narrow set of priority use cases, gradually expanding the scope of their work as they build reusable capabilities and learn what works best. Technology leaders should work closely with business leads to evaluate which business cases to fund and support. 8. Tailor upskilling programs by roles and proficiency levels Generative AI has the potential to massively lift employees’ productivity and augment their capabilities. But the benefits are unevenly distributed depending on roles and skill levels, requiring leaders to rethink how to build the actual skills people need. Our latest empirical research using the generative AI tool GitHub Copilot, for example, helped software engineers write code 35 to 45 percent faster. 5 “ Unleashing developer productivity with generative AI ,” June 27, 2023. The benefits, however, varied. Highly skilled developers saw gains of up to 50 to 80 percent, while junior developers experienced a 7 to 10 percent decline in speed. That’s because the output of the generative AI tools requires engineers to critique, validate, and improve the code, which inexperienced software engineers struggle to do. Conversely, in less technical roles, such as customer service, generative AI helps low-skill workers significantly, with productivity increasing by 14 percent and staff turnover dropping as well, according to one study. 6 Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work , National Bureau of Economic Research (NBER) working paper, number 31161, April 2023. These disparities underscore the need for technology leaders, working with the chief human resources officer (CHRO), to rethink their talent management strategy to build the workforce of the future. Hiring a core set of top generative AI talent will be important, and, given the increasing scarcity and strategic importance of that talent, tech leaders should put in place retention mechanisms, such as competitive salaries and opportunities to be involved in important strategic work for the business. Tech leaders, however, cannot stop at hiring. Because nearly every existing role will be affected by generative AI, a crucial focus should be on upskilling people based on a clear view of what skills are needed by role, proficiency level, and business goals. Let’s look at software developers as an example. Training for novices needs to emphasize accelerating their path to become top code reviewers in addition to code generators. Similar to the difference between writing and editing, code review requires a different skill set. Software engineers will need to understand what good code looks like; review the code created by generative AI for functionality, complexity, quality, and readability; and scan for vulnerabilities while ensuring they do not themselves introduce quality or security issues in the code. Furthermore, software developers will need to learn to think differently when it comes to coding, by better understanding user intent so they can create prompts and define contextual data that help generative AI tools provide better answers. Beyond training up tech talent, the CIO and CTO can play an important role in building generative AI skills among nontech talent as well. Besides understanding how to use generative AI tools for such basic tasks as email generation and task management, people across the business will need to become comfortable using an array of capabilities to improve performance and outputs. The CIO and CTO can help adapt academy models to provide this training and corresponding certifications. The decreasing value of inexperienced engineers should accelerate the move away from a classic talent pyramid, where the greatest number of people are at a junior level, to a structure more like a diamond, where the bulk of the technical workforce is made up of experienced people. Practically speaking, that will mean building the skills of junior employees as quickly as possible while reducing roles dedicated to low-complexity manual tasks (such as writing unit tests). 9. Evaluate the new risk landscape and establish ongoing mitigation practices Generative AI presents a fresh set of ethical questions and risks, including “hallucinations,” whereby the generative AI model presents an incorrect response based on the highest-probability response; the accidental release of confidential personally identifiable information; inherent bias in the large data sets the models use; and high degrees of uncertainty related to intellectual property (IP). CIOs and CTOs will need to become fluent in ethics, humanitarian, and compliance issues to adhere not just to the letter of the law (which will vary by country) but also to the spirit of responsibly managing their business’s reputation. Addressing this new landscape requires a significant review of cyber practices and updating the software development process to evaluate risk and identify mitigation actions before model development begins, which will both reduce issues and ensure the process doesn’t slow down. Proven risk-mitigation actions for hallucinations can include adjusting the level of creativity (known as the “temperature”) of a model when it generates responses; augmenting the model with relevant internal data to provide more context; using libraries that impose guardrails on what can be generated; using “moderation” models to check outputs; and adding clear disclaimers. Early generative AI use cases should focus on areas where the cost of error is low, to allow the organization to work through inevitable setbacks and incorporate learnings. To protect data privacy, it will be critical to establish and enforce sensitive data tagging protocols, set up data access controls in different domains (such as HR compensation data), add extra protection when data is used externally, and include privacy safeguards. For example, to mitigate access control risk, some organizations have set up a policy-management layer that restricts access by role once a prompt is given to the model. To mitigate risk to intellectual property, CIOs and CTOs should insist that providers of foundation models maintain transparency regarding the IP (data sources, licensing, and ownership rights) of the data sets used. Generative AI is poised to be one of the fastest-growing technology categories we’ve ever seen. Tech leaders cannot afford unnecessary delays in defining and shaping a generative AI strategy. While the space will continue to evolve rapidly, these nine actions can help CIOs and CTOs responsibly and effectively harness the power of generative AI at scale. Aamer Baig is a senior partner in McKinsey’s Chicago office; Sven Blumberg is a senior partner in the Düsseldorf office; Eva Li is a consultant in the Bay Area office, where Megha Sinha is a partner; Douglas Merrill is a partner in the Southern California office; Adi Pradhan and Stephen Xu are associate partners in the Toronto office; and Alexander Sukharevsky is a senior partner in the London office. The authors wish to thank Stephanie Brauckmann, Anusha Dhasarathy, Martin Harrysson, Klemens Hjartar, Alharith Hussin, Naufal Khan, Sam Nie, Chandrasekhar Panda, Henning Soller, Nikhil Srinidhi, Asin Tavakoli, Niels Van der Wildt, and Anna Wiesinger for their contributions to this article. Explore a career with us Related Articles Unleashing developer productivity with generative AI The economic potential of generative AI: The next productivity frontier What every CEO should know about generative AI'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:46 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:46 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:46 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:46 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:46 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:46 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:47 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'880'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'194675'), (b'x-ratelimit-reset-requests', b'1m17.66s'), (b'x-ratelimit-reset-tokens', b'1.597s'), (b'x-request-id', b'req_7e8eaacfa667e0d42ef202905b962c1e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c630b781131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:47 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:47 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:47 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:47 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:47 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:47 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '880', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '194675', 'x-ratelimit-reset-requests': '1m17.66s', 'x-ratelimit-reset-tokens': '1.597s', 'x-request-id': 'req_7e8eaacfa667e0d42ef202905b962c1e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c630b781131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:47 [openai._base_client] DEBUG: request_id: req_7e8eaacfa667e0d42ef202905b962c1e
2024-08-20 02:07:47 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Generative AI could add $2.6 to $4.4 trillion in annual value, presenting CIOs and CTOs with opportunities to drive innovation. To harness this potential, tech leaders should adopt strategic actions, including establishing generative AI policies,
2024-08-20 02:07:47 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:47 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:47 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:48 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:48 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A8%3AG8 HTTP/11" 200 None
2024-08-20 02:07:48 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A8%3AG8?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/technologys-generational-moment-with-generative-ai-a-cio-and-cto-guide>
{'title': 'Technology’s generational moment with generative AI: A CIO and CTO guide', 'description': 'CIOs and CTOs can take nine actions to reimagine business and technology with generative AI.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/technologys-generational-moment-with-generative-ai-a-cio-and-cto-guide', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/technologys%20generational%20moment%20with%20generative%20ai%20a%20cio%20and%20cto%20guide/thumb-gettyimages-1470777844.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2023-07-11T12:00:00Z', 'article_text': 'Technology’s generational moment with generative AI: A CIO and CTO guide Hardly a day goes by without some new business-busting development related to generative AI surfacing in the media. The excitement is well deserved— McKinsey research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion of value annually. 1 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. About the authors This article is a collaborative effort by Aamer Baig , Sven Blumberg , Eva Li, Douglas Merrill, Adi Pradhan, Megha Sinha, Alexander Sukharevsky , and Stephen Xu, representing views from McKinsey Digital. CIOs and chief technology officers (CTOs) have a critical role in capturing that value, but it’s worth remembering we’ve seen this movie before. New technologies emerged—the internet, mobile, social media—that set off a melee of experiments and pilots, though significant business value often proved harder to come by. Many of the lessons learned from those developments still apply, especially when it comes to getting past the pilot stage to reach scale. For the CIO and CTO, the generative AI boom presents a unique opportunity to apply those lessons to guide the C-suite in turning the promise of generative AI into sustainable value for the business. A quick primer on key terms Generative AI is a type of AI that can create new content (text, code, images, video) using patterns it has learned by training on extensive (public) data with machine learning (ML) techniques. Foundation models (FMs) are deep learning models trained on vast quantities of unstructured, unlabeled data that can be used for a wide range of tasks out of the box or adapted to specific tasks through fine-tuning. Examples of these models are GPT-4, PaLM 2, DALL·E 2, and Stable Diffusion. Large language models (LLMs) make up a class of foundation models that can process massive amounts of unstructured text and learn the relationships between words or portions of words, known as tokens. This enables LLMs to generate natural-language text, performing tasks such as summarization or knowledge extraction. Cohere Command is one type of LLM; LaMDA is the LLM behind Bard. Fine-tuning is the process of adapting a pretrained foundation model to perform better in a specific task. This entails a relatively short period of training on a labeled data set, which is much smaller than the data set the model was initially trained on. This additional training allows the model to learn and adapt to the nuances, terminology, and specific patterns found in the smaller data set. Prompt engineering refers to the process of designing, refining, and optimizing input prompts to guide a generative AI model toward producing desired (that is, accurate) outputs. Through conversations with dozens of tech leaders and an analysis of generative AI initiatives at more than 50 companies (including our own), we have identified nine actions all technology leaders can take to create value, orchestrate technology and data, scale solutions, and manage risk for generative AI (see sidebar, “A quick primer on key terms”): Creating value beyond the hype 1. Determine the company’s posture for the adoption of generative AI As use of generative AI becomes increasingly widespread, we have seen CIOs and CTOs respond by blocking employee access to publicly available applications to limit risk. In doing so, these companies risk missing out on opportunities for innovation, with some employees even perceiving these moves as limiting their ability to build important new skills. Instead, CIOs and CTOs should work with risk leaders to balance the real need for risk mitigation with the importance of building generative AI skills in the business. This requires establishing the company’s posture regarding generative AI by building consensus around the levels of risk with which the business is comfortable and how generative AI fits into the business’s overall strategy. This step allows the business to quickly determine company-wide policies and guidelines. Once policies are clearly defined, leaders should communicate them to the business, with the CIO and CTO providing the organization with appropriate access and user-friendly guidelines. Some companies have rolled out firmwide communications about generative AI, provided broad access to generative AI for specific user groups, created pop-ups that warn users any time they input internal data into a model, and built a guidelines page that appears each time users access a publicly available generative AI service. 2. Identify use cases that build value through improved productivity, growth, and new business models CIOs and CTOs should be the antidote to the “death by use case” frenzy that we already see in many companies. They can be most helpful by working with the CEO, CFO, and other business leaders to think through how generative AI challenges existing business models, opens doors to new ones, and creates new sources of value. With a deep understanding of the technical possibilities, the CIO and CTO should identify the most valuable opportunities and issues across the company that can benefit from generative AI—and those that can’t. In some cases, generative AI is not the best option. McKinsey research , for example, shows generative AI can lift productivity for certain marketing use cases (for example, by analyzing unstructured and abstract data for customer preference) by roughly 10 percent and customer support (for example, through intelligent bots) by up to 40 percent. 2 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. The CIO and CTO can be particularly helpful in developing a perspective on how best to cluster use cases either by domain (such as customer journey or business process) or use case type (such as creative content creation or virtual agents) so that generative AI will have the most value. Identifying opportunities won’t be the most strategic task—there are many generative AI use cases out there—but, given initial limitations of talent and capabilities, the CIO and CTO will need to provide feasibility and resource estimates to help the business sequence generative AI priorities. Providing this level of counsel requires tech leaders to work with the business to develop a FinAI capability to estimate the true costs and returns on generative AI initiatives. Cost calculations can be particularly complex because the unit economics must account for multiple model and vendor costs, model interactions (where a query might require input from multiple models, each with its own fee), ongoing usage fees, and human oversight costs. 3. Reimagine the technology function Generative AI has the potential to completely remake how the tech function works. CIOs and CTOs need to make a comprehensive review of the potential impact of generative AI on all areas of tech, but it’s important to take action quickly to build experience and expertise. There are three areas where they can focus their initial energies: 4. Take advantage of existing services or adapt open-source generative AI models A variation of the classic “rent, buy, or build” decision exists when it comes to strategies for developing generative AI capabilities. The basic rule holds true: a company should invest in a generative AI capability where it can create a proprietary advantage for the business and access existing services for those that are more like commodities. The CIO and CTO can think through the implications of these options as three archetypes: Each archetype has its own costs that tech leaders will need to consider (Exhibit 1). While new developments, such as efficient model training approaches and lower graphics processing unit (GPU) compute costs over time, are driving costs down, the inherent complexity of the Maker archetype means that few organizations will adopt it in the short term. Instead, most will turn to some combination of Taker, to quickly access a commodity service, and Shaper, to build a proprietary capability on top of foundation models. 5. Upgrade your enterprise technology architecture to integrate and manage generative AI models Organizations will use many generative AI models of varying size, complexity, and capability. To generate value, these models need to be able to work both together and with the business’s existing systems or applications. For this reason, building a separate tech stack for generative AI creates more complexities than it solves. As an example, we can look at a consumer querying customer service at a travel company to resolve a booking issue (Exhibit 2). In interacting with the customer, the generative AI model needs to access multiple applications and data sources. For the Taker archetype, this level of coordination isn’t necessary. But for companies looking to scale the advantages of generative AI as Shapers or Makers, CIOs and CTOs need to upgrade their technology architecture. The prime goal is to integrate generative AI models into internal systems and enterprise applications and to build pipelines to various data sources. Ultimately, it’s the maturity of the business’s enterprise technology architecture that allows it to integrate and scale its generative AI capabilities. Recent advances in integration and orchestration frameworks, such as LangChain and LlamaIndex, have significantly reduced the effort required to connect different generative AI models with other applications and data sources. Several integration patterns are also emerging, including those that enable models to call APIs when responding to a user query—GPT-4, for example, can invoke functions—and provide contextual data from an external data set as part of a user query, a technique known as retrieval augmented generation. Tech leaders will need to define reference architectures and standard integration patterns for their organization (such as standard API formats and parameters that identify the user and the model invoking the API). There are five key elements that need to be incorporated into the technology architecture to integrate generative AI effectively (Exhibit 3): In evolving the architecture, CIOs and CTOs will need to navigate a rapidly growing ecosystem of generative AI providers and tooling. Cloud providers provide extensive access to at-scale hardware and foundation models, as well as a proliferating set of services. MLOps and model hub providers, meanwhile, offer the tools, technologies, and practices to adapt a foundation model and deploy it into production, while other companies provide applications directly accessed by users built on top of foundation models to perform specific tasks. CIOs and CTOs will need to assess how these various capabilities are assembled and integrated to deploy and operate generative AI models. 6. Develop a data architecture to enable access to quality data The ability of a business to generate and scale value, including cost reductions and improved data and knowledge protections, from generative AI models will depend on how well it takes advantage of its own data. Creating that advantage relies on a data architecture that connects generative AI models to internal data sources, which provide context or help fine-tune the models to create more relevant outputs. In this context, CIOs, CTOs, and chief data officers need to work closely together to do the following: McKinsey launches new product suite to help clients scale AI 7. Create a centralized, cross-functional generative AI platform team Most tech organizations are on a journey to a product and platform operating model . CIOs and CTOs need to integrate generative AI capabilities into this operating model to build on the existing infrastructure and help to rapidly scale adoption of generative AI. The first step is setting up a generative AI platform team whose core focus is developing and maintaining a platform service where approved generative AI models can be provisioned on demand for use by product and application teams. The platform team also defines protocols for how generative AI models integrate with internal systems, enterprise applications, and tools, and also develops and implements standardized approaches to manage risk, such as responsible AI frameworks. CIOs and CTOs need to ensure that the platform team is staffed with people who have the right skills. This team requires a senior technical leader who acts as the general manager. Key roles include software engineers to integrate generative AI models into existing systems, applications, and tools; data engineers to build pipelines that connect models to various systems of record and data sources; data scientists to select models and engineer prompts; MLOps engineers to manage deployment and monitoring of multiple models and model versions; ML engineers to fine-tune models with new data sources; and risk experts to manage security issues such as data leakage, access controls, output accuracy, and bias. The exact composition of the platform team will depend on the use cases being served across the enterprise. In some instances, such as creating a customer-facing chatbot, strong product management and user experience (UX) resources will be required. Realistically, the platform team will need to work initially on a narrow set of priority use cases, gradually expanding the scope of their work as they build reusable capabilities and learn what works best. Technology leaders should work closely with business leads to evaluate which business cases to fund and support. 8. Tailor upskilling programs by roles and proficiency levels Generative AI has the potential to massively lift employees’ productivity and augment their capabilities. But the benefits are unevenly distributed depending on roles and skill levels, requiring leaders to rethink how to build the actual skills people need. Our latest empirical research using the generative AI tool GitHub Copilot, for example, helped software engineers write code 35 to 45 percent faster. 5 “ Unleashing developer productivity with generative AI ,” June 27, 2023. The benefits, however, varied. Highly skilled developers saw gains of up to 50 to 80 percent, while junior developers experienced a 7 to 10 percent decline in speed. That’s because the output of the generative AI tools requires engineers to critique, validate, and improve the code, which inexperienced software engineers struggle to do. Conversely, in less technical roles, such as customer service, generative AI helps low-skill workers significantly, with productivity increasing by 14 percent and staff turnover dropping as well, according to one study. 6 Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work , National Bureau of Economic Research (NBER) working paper, number 31161, April 2023. These disparities underscore the need for technology leaders, working with the chief human resources officer (CHRO), to rethink their talent management strategy to build the workforce of the future. Hiring a core set of top generative AI talent will be important, and, given the increasing scarcity and strategic importance of that talent, tech leaders should put in place retention mechanisms, such as competitive salaries and opportunities to be involved in important strategic work for the business. Tech leaders, however, cannot stop at hiring. Because nearly every existing role will be affected by generative AI, a crucial focus should be on upskilling people based on a clear view of what skills are needed by role, proficiency level, and business goals. Let’s look at software developers as an example. Training for novices needs to emphasize accelerating their path to become top code reviewers in addition to code generators. Similar to the difference between writing and editing, code review requires a different skill set. Software engineers will need to understand what good code looks like; review the code created by generative AI for functionality, complexity, quality, and readability; and scan for vulnerabilities while ensuring they do not themselves introduce quality or security issues in the code. Furthermore, software developers will need to learn to think differently when it comes to coding, by better understanding user intent so they can create prompts and define contextual data that help generative AI tools provide better answers. Beyond training up tech talent, the CIO and CTO can play an important role in building generative AI skills among nontech talent as well. Besides understanding how to use generative AI tools for such basic tasks as email generation and task management, people across the business will need to become comfortable using an array of capabilities to improve performance and outputs. The CIO and CTO can help adapt academy models to provide this training and corresponding certifications. The decreasing value of inexperienced engineers should accelerate the move away from a classic talent pyramid, where the greatest number of people are at a junior level, to a structure more like a diamond, where the bulk of the technical workforce is made up of experienced people. Practically speaking, that will mean building the skills of junior employees as quickly as possible while reducing roles dedicated to low-complexity manual tasks (such as writing unit tests). 9. Evaluate the new risk landscape and establish ongoing mitigation practices Generative AI presents a fresh set of ethical questions and risks, including “hallucinations,” whereby the generative AI model presents an incorrect response based on the highest-probability response; the accidental release of confidential personally identifiable information; inherent bias in the large data sets the models use; and high degrees of uncertainty related to intellectual property (IP). CIOs and CTOs will need to become fluent in ethics, humanitarian, and compliance issues to adhere not just to the letter of the law (which will vary by country) but also to the spirit of responsibly managing their business’s reputation. Addressing this new landscape requires a significant review of cyber practices and updating the software development process to evaluate risk and identify mitigation actions before model development begins, which will both reduce issues and ensure the process doesn’t slow down. Proven risk-mitigation actions for hallucinations can include adjusting the level of creativity (known as the “temperature”) of a model when it generates responses; augmenting the model with relevant internal data to provide more context; using libraries that impose guardrails on what can be generated; using “moderation” models to check outputs; and adding clear disclaimers. Early generative AI use cases should focus on areas where the cost of error is low, to allow the organization to work through inevitable setbacks and incorporate learnings. To protect data privacy, it will be critical to establish and enforce sensitive data tagging protocols, set up data access controls in different domains (such as HR compensation data), add extra protection when data is used externally, and include privacy safeguards. For example, to mitigate access control risk, some organizations have set up a policy-management layer that restricts access by role once a prompt is given to the model. To mitigate risk to intellectual property, CIOs and CTOs should insist that providers of foundation models maintain transparency regarding the IP (data sources, licensing, and ownership rights) of the data sets used. Generative AI is poised to be one of the fastest-growing technology categories we’ve ever seen. Tech leaders cannot afford unnecessary delays in defining and shaping a generative AI strategy. While the space will continue to evolve rapidly, these nine actions can help CIOs and CTOs responsibly and effectively harness the power of generative AI at scale. Aamer Baig is a senior partner in McKinsey’s Chicago office; Sven Blumberg is a senior partner in the Düsseldorf office; Eva Li is a consultant in the Bay Area office, where Megha Sinha is a partner; Douglas Merrill is a partner in the Southern California office; Adi Pradhan and Stephen Xu are associate partners in the Toronto office; and Alexander Sukharevsky is a senior partner in the London office. The authors wish to thank Stephanie Brauckmann, Anusha Dhasarathy, Martin Harrysson, Klemens Hjartar, Alharith Hussin, Naufal Khan, Sam Nie, Chandrasekhar Panda, Henning Soller, Nikhil Srinidhi, Asin Tavakoli, Niels Van der Wildt, and Anna Wiesinger for their contributions to this article. Explore a career with us Related Articles Unleashing developer productivity with generative AI The economic potential of generative AI: The next productivity frontier What every CEO should know about generative AI', 'summary': 'Generative AI could add $2.6 to $4.4 trillion in annual value, presenting CIOs and CTOs with opportunities to drive innovation. To harness this potential, tech leaders should adopt strategic actions, including establishing generative AI policies,'}
2024-08-20 02:07:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/cloud/cloud-insights/all-insights> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:48 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nCloud Insights Featured Insights Building an engineering culture and resilient technology Ending the confusion in cloud transformations: The dashboards and metrics everyone needs The state of cloud computing in Europe: Increasing adoption, low returns, huge potential From legacy to cloud: Lessons learned The Middle East public cloud: A multibillion-dollar prize waiting to be captured Featured podcast Getting ahead in the cloud There is $3 trillion worth of business value at stake for companies that successfully use cloud technology—yet many are still in a fog. Here’s a clear path toward cloud adoption. Featured collection Cloud Value Radio Three elements for capturing value Featured videos Security as code: How to embrace the cloud securely Insights to impact Cloud value in cash management Establishing the next-generation infrastructure organization to support hybrid cloud Top cloud myths debunked More Insights Lessons from a successful cloud journey: Empathy, community, and a smart approach to value Africa’s leap ahead into cloud: Opportunities and barriers Building the cloud-ready enterprise network In search of cloud value: Can generative AI transform cloud ROI? Cloud-powered technologies for sustainability It’s time for cloud tech to meet operational tech at industrial sites Cloud as the ultimate digital enabler The new era of resiliency in the cloud Banks’ core technology conundrum reaches an inflection point A cloud migration in wartime Focusing on developer experience and embedded security for cloud Migrating two banks to the cloud after a merger Bringing data platforms to cloud Projecting the global value of cloud: $3 trillion is up for grabs for companies that go beyond adoption More for less: Five ways to lower cloud costs without destroying value Five learnings from CTOs and tech leaders on their cloud strategies The future of automotive computing: Cloud and edge What every insurance leader should know about cloud Three big moves that can decide a financial institution’s future in the cloud What is cloud computing? Getting the most from cloud services and containers Cloud in China: The outlook for 2025 The cloud as a strategic ecosystem for innovation and growth Cloud economics and the six most damaging mistakes to avoid It’s cloud time for boards—in seven charts Cloud foundations: Ten commandments for faster—and more profitable—cloud migrations The business value of innovation in the cloud Six practical actions for building the cloud talent you need The benefits of being a cloud trailblazer Boards and the cloud The case for cloud in life sciences Cloud 2030: Capturing Poland’s potential for accelerated digital growth Cloud-migration opportunity: Business value grows, but missteps abound Cloud cost-optimization simulator Fast forward: How cloud computing could transform risk management Security as code: The best (and maybe only) path to securing cloud applications and systems What payers and providers can learn from successful cloud transformations in other industries Lessons from a high-ROI cloud transformation journey Four ways boards can shape the cloud agenda SaaS, open source, and serverless: A winning combination to build and scale new businesses Five Fifty: Cloudy with a chance of billions Building a cloud-ready operating model for agility and resiliency Cloud’s trillion-dollar prize is up for grabs Clearing the air on cloud: How industrial companies can capture cloud technology’s full business value McKinsey acquires Candid Partners, a leader in cloud consulting Agile’s next level: ABN AMRO’s hybrid cloud–DevSecOps transformation Unlocking value: Four lessons in cloud sourcing and consumption How public-sector tech leaders can speed up the journey to the cloud Debunking seven common myths about cloud Making the cloud pay: How industrial companies can accelerate impact from the cloud How CIOs and CTOs can accelerate digital transformations through cloud platforms Three actions CEOs can take to get value from cloud computing How the cloud has moved advanced analytics from exclusive to accessible Deutsche Börse unlocks the benefits of moving to the cloud Unlocking business acceleration in a hybrid cloud world Making a secure transition to the public cloud Connect with Cloud by McKinsey'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:48 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:48 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:48 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:48 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:48 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:48 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:49 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'871'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'198841'), (b'x-ratelimit-reset-requests', b'1m24.023s'), (b'x-ratelimit-reset-tokens', b'347ms'), (b'x-request-id', b'req_bfe67b4c14ea207d897889a2ed008a07'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c715dfa1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:49 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:49 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:49 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:49 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:49 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:49 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '871', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '198841', 'x-ratelimit-reset-requests': '1m24.023s', 'x-ratelimit-reset-tokens': '347ms', 'x-request-id': 'req_bfe67b4c14ea207d897889a2ed008a07', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c715dfa1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:49 [openai._base_client] DEBUG: request_id: req_bfe67b4c14ea207d897889a2ed008a07
2024-08-20 02:07:49 [mckinsey_capabilities_digital_insights] INFO: Generated summary: The content discusses insights and strategies for successful cloud adoption, highlighting the significant business value at stake, the challenges faced by companies, and lessons learned from various industries. It emphasizes the importance of building a resilient infrastructure and maximizing cloud technology's potential for innovation and
2024-08-20 02:07:49 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:50 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:50 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:50 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:50 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A9%3AG9 HTTP/11" 200 None
2024-08-20 02:07:50 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A9%3AG9?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/cloud/cloud-insights/all-insights>
{'title': 'Cloud by McKinsey', 'description': 'The cloud is revolutionizing how businesses create value, but only when tech organizations, and the business, understand how...', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/cloud/cloud-insights/all-insights', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/cloud%20by%20mckinsey/overview/standard-capturing-value-in-cloud.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': 'No date found', 'article_text': 'Cloud Insights Featured Insights Building an engineering culture and resilient technology Ending the confusion in cloud transformations: The dashboards and metrics everyone needs The state of cloud computing in Europe: Increasing adoption, low returns, huge potential From legacy to cloud: Lessons learned The Middle East public cloud: A multibillion-dollar prize waiting to be captured Featured podcast Getting ahead in the cloud There is $3 trillion worth of business value at stake for companies that successfully use cloud technology—yet many are still in a fog. Here’s a clear path toward cloud adoption. Featured collection Cloud Value Radio Three elements for capturing value Featured videos Security as code: How to embrace the cloud securely Insights to impact Cloud value in cash management Establishing the next-generation infrastructure organization to support hybrid cloud Top cloud myths debunked More Insights Lessons from a successful cloud journey: Empathy, community, and a smart approach to value Africa’s leap ahead into cloud: Opportunities and barriers Building the cloud-ready enterprise network In search of cloud value: Can generative AI transform cloud ROI? Cloud-powered technologies for sustainability It’s time for cloud tech to meet operational tech at industrial sites Cloud as the ultimate digital enabler The new era of resiliency in the cloud Banks’ core technology conundrum reaches an inflection point A cloud migration in wartime Focusing on developer experience and embedded security for cloud Migrating two banks to the cloud after a merger Bringing data platforms to cloud Projecting the global value of cloud: $3 trillion is up for grabs for companies that go beyond adoption More for less: Five ways to lower cloud costs without destroying value Five learnings from CTOs and tech leaders on their cloud strategies The future of automotive computing: Cloud and edge What every insurance leader should know about cloud Three big moves that can decide a financial institution’s future in the cloud What is cloud computing? Getting the most from cloud services and containers Cloud in China: The outlook for 2025 The cloud as a strategic ecosystem for innovation and growth Cloud economics and the six most damaging mistakes to avoid It’s cloud time for boards—in seven charts Cloud foundations: Ten commandments for faster—and more profitable—cloud migrations The business value of innovation in the cloud Six practical actions for building the cloud talent you need The benefits of being a cloud trailblazer Boards and the cloud The case for cloud in life sciences Cloud 2030: Capturing Poland’s potential for accelerated digital growth Cloud-migration opportunity: Business value grows, but missteps abound Cloud cost-optimization simulator Fast forward: How cloud computing could transform risk management Security as code: The best (and maybe only) path to securing cloud applications and systems What payers and providers can learn from successful cloud transformations in other industries Lessons from a high-ROI cloud transformation journey Four ways boards can shape the cloud agenda SaaS, open source, and serverless: A winning combination to build and scale new businesses Five Fifty: Cloudy with a chance of billions Building a cloud-ready operating model for agility and resiliency Cloud’s trillion-dollar prize is up for grabs Clearing the air on cloud: How industrial companies can capture cloud technology’s full business value McKinsey acquires Candid Partners, a leader in cloud consulting Agile’s next level: ABN AMRO’s hybrid cloud–DevSecOps transformation Unlocking value: Four lessons in cloud sourcing and consumption How public-sector tech leaders can speed up the journey to the cloud Debunking seven common myths about cloud Making the cloud pay: How industrial companies can accelerate impact from the cloud How CIOs and CTOs can accelerate digital transformations through cloud platforms Three actions CEOs can take to get value from cloud computing How the cloud has moved advanced analytics from exclusive to accessible Deutsche Börse unlocks the benefits of moving to the cloud Unlocking business acceleration in a hybrid cloud world Making a secure transition to the public cloud Connect with Cloud by McKinsey', 'summary': "The content discusses insights and strategies for successful cloud adoption, highlighting the significant business value at stake, the challenges faced by companies, and lessons learned from various industries. It emphasizes the importance of building a resilient infrastructure and maximizing cloud technology's potential for innovation and"}
2024-08-20 02:07:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/enterprise-softwares-growing-reach> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:50 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nEnterprise software’s growing reach How efficient growth can fuel enduring value creation in software Anaplan CEO: How decision excellence drives enterprise performance Navigating the generative AI disruption in software The growing importance of software product marketing managers Turning consumer and retail companies into software-driven innovators Software excellence How generative AI could accelerate software product time to market MLOps so AI can scale What’s driving the Nordic countries’ software export surge? Yes, you can measure software developer productivity From product-led growth to product-led sales: Beyond the PLG hype Where could $374 billion in dry powder go? Six themes to watch Unleashing developer productivity with generative AI The art of software pricing: Unleashing growth with data-driven insights Private equity turns to resiliency strategies for software investments What separates top product managers from the rest of the pack The digital reinvention of enterprise tech go-to-market Responsible product management: The critical tech challenge Reversal of fortune: How European software can play to its strengths SaaS and the Rule of 40: Keys to the critical value creation metric The next software disruption: How vendors must adapt to a new era How quote-to-cash excellence can fuel growth for B2B subscription businesses The product management talent dilemma Advanced analytics in software pricing: Enabling sales to price with confidence Introducing customer success 2.0: The new growth engine Product managers for the digital world Software transformation Taking industrial sector tech from cost center to competitive edge From start-up to centaur: Leadership lessons on scaling Embedded finance: The choices and trade-offs for US banks The generative AI opportunity in airline maintenance Five considerations for software private equity in 2024 Thoughtful M&A strategies are key to growth in tech, media, and telecom Tech talent in transition: Seven technology trends reshaping telcos Every company is a software company: Six ‘must dos’ to succeed Leadership lessons: Becoming a software company The SaaS factor: Six ways to drive growth by building new SaaS businesses Debugging the software talent gap in aerospace and defense Winning in software for industrial companies Reaching excellence in software procurement Moving beyond agile to become a software innovator Four myths about building a software business Hardware’s business-model shift: Finding a new path forward Developer Velocity at work: Key lessons from industry digital leaders When code is king: Mastering automotive software excellence Developer Velocity: How software excellence fuels business performance The case for an end-to-end automotive-software platform Executive voices Ya Xu on building AI and machine learning products The promise and the reality of gen AI agents in the enterprise Kareem Yusuf on building sustainability products for your customers Creating a European AI unicorn: Interview with Arthur Mensch, CEO of Mistral AI Thomas Dohmke on improving engineering experience using generative AI Alex Hardiman on product outside of pure technology companies Unlocking autonomous-vehicle development: TIER IV’s open-source blueprint Pali Bhat on building intelligent products Talking innovation in video games with Electronic Arts Gokul Rajaram on product thinking and the future of innovation The power of pace in technology Miro’s Andrey Khusid: Product-led growth in tech and beyond Making product inclusion and equity a core part of tech ‘Find the smartest technologist in the company and make them CEO’ Giving developers a leading role in cybersecurity Building a “digital operating rhythm” with OKR software Leading from the heart: How Freshworks’ CEO built a global tech unicorn Box’s Aaron Levie on navigating SaaS’ several stages of growth Net retention and customer success: Gainsight CEO Nick Mehta on winning at SaaS Turning India into a SaaS power Recovering from ransomware: a conversation with Veritas CEO Greg Hughes Managing growth and value creation in SaaS: An interview with a software leader Unleashing developers’ full talents: An interview with Twilio’s CEO Software and the next normal: A talk with Workday’s cofounder and co-CEO Talent and capabilities The human side of generative AI: Creating a path to productivity Attracting and retaining tech talent to sustain mobility’s growth HR rewired: An end-to-end approach to attracting and retaining top tech talent Cracking the code on digital talent How to close the Black tech talent gap Mining for tech-talent gold: Seven ways to find and keep diverse talent Overcoming the fear factor in hiring tech talent Tech talent tectonics: Ten new realities for finding, keeping, and developing talent Repairing the broken rung on the career ladder for women in technical roles Risk The cyber clock is ticking: Derisking emerging technologies in financial services Software bill of materials: Managing software cybersecurity risks Security as code: The best (and maybe only) path to securing cloud applications and systems Securing software as a service'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:50 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:50 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:50 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:50 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:50 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:50 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:51 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'703'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'198622'), (b'x-ratelimit-reset-requests', b'1m30.371s'), (b'x-ratelimit-reset-tokens', b'413ms'), (b'x-request-id', b'req_2d049eab495816c51c61e5fe48cb86db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c7fbff31131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:51 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:51 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:51 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:51 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:51 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:51 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '703', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '198622', 'x-ratelimit-reset-requests': '1m30.371s', 'x-ratelimit-reset-tokens': '413ms', 'x-request-id': 'req_2d049eab495816c51c61e5fe48cb86db', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c7fbff31131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:51 [openai._base_client] DEBUG: request_id: req_2d049eab495816c51c61e5fe48cb86db
2024-08-20 02:07:51 [mckinsey_capabilities_digital_insights] INFO: Generated summary: The content discusses various aspects of enterprise software, including growth strategies, the impact of generative AI, software product management, developer productivity, and the importance of effective pricing. It emphasizes the evolving role of software in businesses and highlights key challenges and opportunities in
2024-08-20 02:07:52 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:52 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:52 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:52 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:52 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A10%3AG10 HTTP/11" 200 None
2024-08-20 02:07:52 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A10%3AG10?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/enterprise-softwares-growing-reach>
{'title': 'Enterprise software’s growing reach', 'description': 'With software transforming so many industries, knowing what it takes to succeed in the dynamic sector is becoming critical for...', 'url': 'https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/enterprise-softwares-growing-reach', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/industries/technology%20media%20and%20telecommunications/high%20tech/our%20insights/enterprise%20softwares%20growing%20reach/thumb-gettyimages-939787416.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': 'No date found', 'article_text': 'Enterprise software’s growing reach How efficient growth can fuel enduring value creation in software Anaplan CEO: How decision excellence drives enterprise performance Navigating the generative AI disruption in software The growing importance of software product marketing managers Turning consumer and retail companies into software-driven innovators Software excellence How generative AI could accelerate software product time to market MLOps so AI can scale What’s driving the Nordic countries’ software export surge? Yes, you can measure software developer productivity From product-led growth to product-led sales: Beyond the PLG hype Where could $374 billion in dry powder go? Six themes to watch Unleashing developer productivity with generative AI The art of software pricing: Unleashing growth with data-driven insights Private equity turns to resiliency strategies for software investments What separates top product managers from the rest of the pack The digital reinvention of enterprise tech go-to-market Responsible product management: The critical tech challenge Reversal of fortune: How European software can play to its strengths SaaS and the Rule of 40: Keys to the critical value creation metric The next software disruption: How vendors must adapt to a new era How quote-to-cash excellence can fuel growth for B2B subscription businesses The product management talent dilemma Advanced analytics in software pricing: Enabling sales to price with confidence Introducing customer success 2.0: The new growth engine Product managers for the digital world Software transformation Taking industrial sector tech from cost center to competitive edge From start-up to centaur: Leadership lessons on scaling Embedded finance: The choices and trade-offs for US banks The generative AI opportunity in airline maintenance Five considerations for software private equity in 2024 Thoughtful M&A strategies are key to growth in tech, media, and telecom Tech talent in transition: Seven technology trends reshaping telcos Every company is a software company: Six ‘must dos’ to succeed Leadership lessons: Becoming a software company The SaaS factor: Six ways to drive growth by building new SaaS businesses Debugging the software talent gap in aerospace and defense Winning in software for industrial companies Reaching excellence in software procurement Moving beyond agile to become a software innovator Four myths about building a software business Hardware’s business-model shift: Finding a new path forward Developer Velocity at work: Key lessons from industry digital leaders When code is king: Mastering automotive software excellence Developer Velocity: How software excellence fuels business performance The case for an end-to-end automotive-software platform Executive voices Ya Xu on building AI and machine learning products The promise and the reality of gen AI agents in the enterprise Kareem Yusuf on building sustainability products for your customers Creating a European AI unicorn: Interview with Arthur Mensch, CEO of Mistral AI Thomas Dohmke on improving engineering experience using generative AI Alex Hardiman on product outside of pure technology companies Unlocking autonomous-vehicle development: TIER IV’s open-source blueprint Pali Bhat on building intelligent products Talking innovation in video games with Electronic Arts Gokul Rajaram on product thinking and the future of innovation The power of pace in technology Miro’s Andrey Khusid: Product-led growth in tech and beyond Making product inclusion and equity a core part of tech ‘Find the smartest technologist in the company and make them CEO’ Giving developers a leading role in cybersecurity Building a “digital operating rhythm” with OKR software Leading from the heart: How Freshworks’ CEO built a global tech unicorn Box’s Aaron Levie on navigating SaaS’ several stages of growth Net retention and customer success: Gainsight CEO Nick Mehta on winning at SaaS Turning India into a SaaS power Recovering from ransomware: a conversation with Veritas CEO Greg Hughes Managing growth and value creation in SaaS: An interview with a software leader Unleashing developers’ full talents: An interview with Twilio’s CEO Software and the next normal: A talk with Workday’s cofounder and co-CEO Talent and capabilities The human side of generative AI: Creating a path to productivity Attracting and retaining tech talent to sustain mobility’s growth HR rewired: An end-to-end approach to attracting and retaining top tech talent Cracking the code on digital talent How to close the Black tech talent gap Mining for tech-talent gold: Seven ways to find and keep diverse talent Overcoming the fear factor in hiring tech talent Tech talent tectonics: Ten new realities for finding, keeping, and developing talent Repairing the broken rung on the career ladder for women in technical roles Risk The cyber clock is ticking: Derisking emerging technologies in financial services Software bill of materials: Managing software cybersecurity risks Security as code: The best (and maybe only) path to securing cloud applications and systems Securing software as a service', 'summary': 'The content discusses various aspects of enterprise software, including growth strategies, the impact of generative AI, software product management, developer productivity, and the importance of effective pricing. It emphasizes the evolving role of software in businesses and highlights key challenges and opportunities in'}
2024-08-20 02:07:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/featured-insights/the-rise-of-quantum-computing> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:52 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nThe Rise of Quantum Computing Steady progress in approaching the quantum advantage Understanding quantum control’s role in scaling quantum computing Quantum sensing: Poised to realize immense potential in many sectors Blocking out the noise: An interview with a quantum computing expert Industry perspectives Quantum technology use cases as fuel for value in finance Gearing up for mobility’s future with quantum computing Pursuing quantum in pharma with purpose: An interview with Boehringer Ingelheim’s CTO Pharma’s digital Rx: Quantum computing in drug research and development More Insights Quantum computing: The time to act is now Bringing quantum computing to data centers Potential and challenges of quantum computing hardware technologies Early value: An introduction to quantum optimizers Is winter coming? Quantum computing’s trajectory in the years ahead Shooting for the moon: How PsiQuantum forged its own path Quantum technology sees record investments, progress on talent gap Five lessons from AI on closing quantum’s talent gap—before it’s too late From basic research to market: Why the recent Nobel Prize in physics matters Quantum computing funding remains strong, but talent gap raises concern How quantum computing can help tackle global warming Quantum computing just might save the planet When—and how—to prepare for post-quantum cryptography Shaping the long race in quantum communication and quantum sensing A quantum wake-up call for European CEOs Quantum computing use cases are getting real—what you need to know Separating the wheat from the chaff: Quantum technology in an era of hype The path forward for quantum computing The current state of quantum computing: Between hype and revolution How quantum computing could change financial services Will quantum computing drive the automotive future? Quantum computing is coming: How can your company prepare? A game plan for quantum computing The next big thing? Quantum computing’s potential impact on chemicals'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:52 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:52 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:52 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:52 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:52 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:52 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:53 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199415'), (b'x-ratelimit-reset-requests', b'1m37.012s'), (b'x-ratelimit-reset-tokens', b'175ms'), (b'x-request-id', b'req_99b9dedb7b3f9cb954a527a72aabfea0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c8c49051131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:53 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:53 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:53 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:53 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:53 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:53 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '609', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199415', 'x-ratelimit-reset-requests': '1m37.012s', 'x-ratelimit-reset-tokens': '175ms', 'x-request-id': 'req_99b9dedb7b3f9cb954a527a72aabfea0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c8c49051131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:53 [openai._base_client] DEBUG: request_id: req_99b9dedb7b3f9cb954a527a72aabfea0
2024-08-20 02:07:53 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Quantum computing is advancing rapidly, showing potential in various sectors like finance, pharmaceuticals, and mobility. Despite strong funding, the industry faces a talent gap. Key interviews and insights highlight the urgency for companies to prepare for quantum's transformative impact, while addressing challenges
2024-08-20 02:07:53 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:54 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:54 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:54 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:54 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A11%3AG11 HTTP/11" 200 None
2024-08-20 02:07:54 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A11%3AG11?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/featured-insights/the-rise-of-quantum-computing>
{'title': 'The Rise of Quantum Computing', 'description': 'Accelerating technological breakthroughs, increasing investment flows, start-up proliferation, and promises of capable quantum...', 'url': 'https://www.mckinsey.com/featured-insights/the-rise-of-quantum-computing', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/featured%20insights/the%20rise%20of%20quantum%20computing/1287074793-white-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': 'No date found', 'article_text': 'The Rise of Quantum Computing Steady progress in approaching the quantum advantage Understanding quantum control’s role in scaling quantum computing Quantum sensing: Poised to realize immense potential in many sectors Blocking out the noise: An interview with a quantum computing expert Industry perspectives Quantum technology use cases as fuel for value in finance Gearing up for mobility’s future with quantum computing Pursuing quantum in pharma with purpose: An interview with Boehringer Ingelheim’s CTO Pharma’s digital Rx: Quantum computing in drug research and development More Insights Quantum computing: The time to act is now Bringing quantum computing to data centers Potential and challenges of quantum computing hardware technologies Early value: An introduction to quantum optimizers Is winter coming? Quantum computing’s trajectory in the years ahead Shooting for the moon: How PsiQuantum forged its own path Quantum technology sees record investments, progress on talent gap Five lessons from AI on closing quantum’s talent gap—before it’s too late From basic research to market: Why the recent Nobel Prize in physics matters Quantum computing funding remains strong, but talent gap raises concern How quantum computing can help tackle global warming Quantum computing just might save the planet When—and how—to prepare for post-quantum cryptography Shaping the long race in quantum communication and quantum sensing A quantum wake-up call for European CEOs Quantum computing use cases are getting real—what you need to know Separating the wheat from the chaff: Quantum technology in an era of hype The path forward for quantum computing The current state of quantum computing: Between hype and revolution How quantum computing could change financial services Will quantum computing drive the automotive future? Quantum computing is coming: How can your company prepare? A game plan for quantum computing The next big thing? Quantum computing’s potential impact on chemicals', 'summary': "Quantum computing is advancing rapidly, showing potential in various sectors like finance, pharmaceuticals, and mobility. Despite strong funding, the industry faces a talent gap. Key interviews and insights highlight the urgency for companies to prepare for quantum's transformative impact, while addressing challenges"}
2024-08-20 02:07:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/leadership-and-digital-transformation> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:55 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nDigital transformation: Rewiring for digital and AI Featured Insights What it takes to rewire a CPG company to outcompete in digital and AI Implementing generative AI with speed and safety A generative AI reset: Rewiring to turn potential into value in 2024 Rewired and running ahead: Digital and AI leaders are leaving the rest behind Ten unsung digital and AI ideas shaping business Industry perspectives Freeport-McMoRan turns data into value On the brink: Realizing the value of analytics in insurance Clearing data-quality roadblocks: Unlocking AI in manufacturing Unlocking the industrial potential of robotics and automation Digital transformations in energy retail: A shift toward advanced platforms Getting digital transformation right in resource-heavy industries Interviews Embracing digital transformation with a digital factory The power of pace in technology What really works when it comes to digital and AI transformations? Digital transformation to achieve operational excellence How LEGO plays with data: An interview with chief data officer Orlando Machado Digital transformation on the CEO agenda The Committed Innovator: An interview with Anjali Sud, CEO of Vimeo Using ecosystems to reach higher: An interview with the co-CEO of Ping An How the CEO of Samsung SDS sets a course for ‘humble and speedy’ Building a digital New York Times: CEO Mark Thompson Transformation and resilience: An interview with Best Buy’s executive chairman Hubert Joly Make a digital vision real by learning and adapting along the way More insights Choose the right transformation ‘bite size’ MLOps so AI can scale The bottom-line benefit of the product operating model Rewired for value: Digital and AI transformations that work The rewired enterprise: How five companies built to outcompete Rewired to use AI’s superpower Rewired to outcompete What is digital transformation? The EU digital strategy: The impact of data privacy on global business Women in tech: The best bet to solve Europe’s talent shortage Digital transformations: The five talent factors that matter most Generative AI is here: How tools like ChatGPT could change your business Every company is a software company: Six ‘must dos’ to succeed The digital-value guardian: CEOs and digital transformations Scaling AI like a tech native: The CEO’s role How boards can help digital transformations How do you measure success in digital? Five metrics for CEOs The CEO’s new technology agenda A CEO guide for avoiding the ten traps that derail digital transformations'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:55 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:55 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:55 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:55 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:55 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:55 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:56 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'556'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199281'), (b'x-ratelimit-reset-requests', b'1m43.291s'), (b'x-ratelimit-reset-tokens', b'215ms'), (b'x-request-id', b'req_65496915de2a3177e656c7e74f342eac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608c9afbad1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:56 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:56 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:56 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:56 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:56 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:56 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '556', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199281', 'x-ratelimit-reset-requests': '1m43.291s', 'x-ratelimit-reset-tokens': '215ms', 'x-request-id': 'req_65496915de2a3177e656c7e74f342eac', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608c9afbad1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:56 [openai._base_client] DEBUG: request_id: req_65496915de2a3177e656c7e74f342eac
2024-08-20 02:07:56 [mckinsey_capabilities_digital_insights] INFO: Generated summary: The content discusses the necessity of digital transformation and AI integration for CPG companies to stay competitive. It highlights various insights, interviews, and strategies for effective implementation, emphasizing the importance of data utilization, overcoming challenges, and the CEO's role in fostering successful
2024-08-20 02:07:56 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:56 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:56 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:56 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:56 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A12%3AG12 HTTP/11" 200 None
2024-08-20 02:07:57 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A12%3AG12?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/leadership-and-digital-transformation>
{'title': 'Digital transformation: Rewiring for digital and AI', 'description': 'Explore our collection of insights on how to drive successful digital transformations.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/leadership-and-digital-transformation', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/leadership%20and%20digital%20transformation/standard-digital-transformation-page.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': 'No date found', 'article_text': 'Digital transformation: Rewiring for digital and AI Featured Insights What it takes to rewire a CPG company to outcompete in digital and AI Implementing generative AI with speed and safety A generative AI reset: Rewiring to turn potential into value in 2024 Rewired and running ahead: Digital and AI leaders are leaving the rest behind Ten unsung digital and AI ideas shaping business Industry perspectives Freeport-McMoRan turns data into value On the brink: Realizing the value of analytics in insurance Clearing data-quality roadblocks: Unlocking AI in manufacturing Unlocking the industrial potential of robotics and automation Digital transformations in energy retail: A shift toward advanced platforms Getting digital transformation right in resource-heavy industries Interviews Embracing digital transformation with a digital factory The power of pace in technology What really works when it comes to digital and AI transformations? Digital transformation to achieve operational excellence How LEGO plays with data: An interview with chief data officer Orlando Machado Digital transformation on the CEO agenda The Committed Innovator: An interview with Anjali Sud, CEO of Vimeo Using ecosystems to reach higher: An interview with the co-CEO of Ping An How the CEO of Samsung SDS sets a course for ‘humble and speedy’ Building a digital New York Times: CEO Mark Thompson Transformation and resilience: An interview with Best Buy’s executive chairman Hubert Joly Make a digital vision real by learning and adapting along the way More insights Choose the right transformation ‘bite size’ MLOps so AI can scale The bottom-line benefit of the product operating model Rewired for value: Digital and AI transformations that work The rewired enterprise: How five companies built to outcompete Rewired to use AI’s superpower Rewired to outcompete What is digital transformation? The EU digital strategy: The impact of data privacy on global business Women in tech: The best bet to solve Europe’s talent shortage Digital transformations: The five talent factors that matter most Generative AI is here: How tools like ChatGPT could change your business Every company is a software company: Six ‘must dos’ to succeed The digital-value guardian: CEOs and digital transformations Scaling AI like a tech native: The CEO’s role How boards can help digital transformations How do you measure success in digital? Five metrics for CEOs The CEO’s new technology agenda A CEO guide for avoiding the ten traps that derail digital transformations', 'summary': "The content discusses the necessity of digital transformation and AI integration for CPG companies to stay competitive. It highlights various insights, interviews, and strategies for effective implementation, emphasizing the importance of data utilization, overcoming challenges, and the CEO's role in fostering successful"}
2024-08-20 02:07:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-data-leaders-technical-guide-to-scaling-gen-ai> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:07:57 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nA data leader’s technical guide to scaling gen AI Data and AI leaders have been working feverishly on generative AI (gen AI) use cases for more than a year. Their experience has provided promising glimpses of the considerable value at stake in gen AI but has also exposed a variety of challenges in getting to scale. Managing data remains one of the main barriers to value creation from gen AI. In fact, 70 percent of top performers in a recent McKinsey survey said they have experienced difficulties integrating data into AI models, ranging from issues with data quality, defining processes for data governance, and having sufficient training data. 1 “ The state of AI in early 2024: Gen AI adoption spikes and starts to generate value ,” McKinsey, May 30, 2024. About the authors This article is a collaborative effort by Asin Tavakoli , Carlo Giovine , Joe Caserta , Jorge Machado , and Kayvaun Rowshankish , with Jon Boorstein and Nathan Westby, representing views from McKinsey Digital and QuantumBlack, AI by McKinsey. In our experience, organizations have been held back by a still maturing understanding of both how to evolve data capabilities to support gen AI cases at scale and how to use gen AI to improve data practices. This article will cover three actions that data and AI leaders can consider to help them move from gen AI pilots to scaling data solutions. The first focuses on how organizations can strengthen the quality and readiness of their data for gen AI use cases. The second looks at how organizations can use gen AI to build better data products with their modernized data platforms. The third explores key data-management considerations that enable reuse and accelerate the development of data solutions. It starts at the source: Improve your data While data quality has long been an important concern for data and AI leaders, the risks and costs of feeding poor data into gen AI models cannot be overstated, ranging from poor outcomes, costly fixes, and cyber breaches to a loss of user trust in the outputs. The 2024 McKinsey survey cited above, in fact, found that 63 percent of respondents—seven percentage points more than in the 2023 survey—said that output inaccuracy was the greatest risk they saw in their organizations’ use of gen AI. 2 “ The state of AI in early 2024 ,” May 30, 2024. Traditional methods of ensuring data quality aren’t enough; leaders should consider the following ways of improving and expanding their source data. Obtain better and more-accurate source data from complex data types About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Organizations are struggling to handle the increased complexity of unstructured data sets. For example, banks might want to look at both structured financial information, such as transaction history, as well as financial statements and market analyses to determine the creditworthiness of a corporate client. But processing combinations of structured and unstructured data often increases the chance of errors because, while internal teams and subject-matter experts have the relevant knowledge, they generally struggle to codify that knowledge so that data pipeline processes can be easily replicated. Tools have evolved to handle the relationship between different types and sources of data. For example, knowledge graphs can help capture complex relationships between entities, providing meaningful context for large language models (LLMs) and their downstream data sets. These kinds of capabilities make it easier to accurately map data points from unstructured to structured data. Even when data engineers understand the relationship between data sets, they still need to assign different methods to interpret that data based on attributes, such as the data format (PDF, PowerPoint, Word, or image files, for example). This is a challenge as companies integrate formats into their systems that are becoming increasingly complex. Multimodal models are sophisticated enough now to parse more complex types of documents that feature disparate data formats, such as extracting tabular data from unstructured documents. While these models are becoming easier to use, they can still make mistakes (and, in some cases, are expensive). Accuracy issues require constant review, which is often still manual. Some data engineers, for example, spend a lot of time checking two screens of an integrated development environment to observe the differences between outputs. As concurrent use cases increase, this manual approach quickly hits its limits. Data leaders need to focus resources on implementing automated evaluation methods, mechanisms to manage versioning, and data-relevancy scoring to enhance multimodal model output accuracy and consistency. An investment firm knew it needed to improve its data access and usage to implement a virtual assistant. In order to use product information from structured and unstructured data sources, it had to build data pipelines for parsing and processing unstructured data, identify which version of each document was most recent, and adapt the length of articles for mobile users. The firm’s data engineers used multimodal model capabilities to parse tabular data from documents into structured data and build a medallion architecture (a popular design pattern for organizing data that supports modular pipeline development). Additionally, they introduced versioning and relevancy scores to improve output accuracy. As a result, the company was able to quickly start work on use cases, such as due-diligence activities, with a production-grade gen AI environment within two weeks. Creating value beyond the hype Create data when they aren’t available Some gen AI use cases are difficult to pursue because the required data are difficult to obtain and process, which is often an issue in healthcare, life sciences, or other sectors that have stringent data security regulations. To overcome these challenges, in some cases, a data engineer can manually generate a file to test the efficacy of a use case. But the process can be time-consuming and inefficient. Instead, data and AI leaders are investing in gen AI tools to generate synthetic data as test data or to produce new values based completely on the column descriptions and context of the table, allowing them to either create a new data set or make revisions to an existing one. Some companies have already used synthetic data generators to create statistically similar data sets. Use gen AI to accelerate the building of reusable data products Data products , such as a 360-degree view of individual customers, are the cornerstone of how companies use data to generate value at scale for the business. 3 Veeral Desai, Tim Fountaine, and Kayvaun Rowshankish, “ How to unlock the full value of data? Manage it like a product ,” McKinsey, June 14, 2022. But such data products can be difficult and time-consuming to develop. With better data and new gen AI tools, however, companies are finding they can accelerate development and improve outputs. For example, one hospitality company expedited the creation of customer domain data models by up to 60 percent while increasing productivity in feature engineering by 50 percent. It was able to hit those marks by focusing on automatically generating both end-to-end data transformation pipelines in PySpark and robust documentation of all the complex transformations that occurred. Shift to end-to-end creation of data products Until recently, available technology has limited the creation of data pipelines (such as a medallion architecture) to a laborious step-by-step approach. While using gen AI to perform tasks, such as generating an individual table from natural language, may make data engineers more efficient, engineers still must complete a series of other upstream and downstream steps, such as combining all the tables. Data and AI leaders instead are starting to take an end-to-end approach to building data pipelines by automating all the steps, achieving, in some cases, time savings of 80 to 90 percent and enhanced scalability for specific use cases. Writing the data pipeline code to generate data products traditionally has been one of the most time-consuming tasks for data engineers. We now are seeing the automated creation of data pipelines, written in languages such as SQL or Python, to create entire models that can solve for multiple use cases at once. Rather than looking at a modest scope of work, such as generating an individual table from a natural-language prompt, the capabilities exist to generate dozens of tables as a cohesive target data model capable of providing solutions to multiple use cases. Before an organization can begin generating these types of capabilities, however, it needs to ensure it has trustworthy, easily understandable, and available data. For companies that have been building their data estate for many years, an important element of this process is understanding their legacy code bases and existing data. Many companies struggle, however, because of poor data lineage or cataloging, leading to a limited understanding of how their data are generated. In response, some companies are employing a variety of agents (gen AI applications) across multiple LLMs to analyze legacy code bases and generate natural-language text descriptions. This approach not only improves the organization’s understanding of its code base but also facilitates the creation of data catalog features, streamlining the identification and removal of redundant code segments. The state of AI in early 2024: Gen AI adoption spikes and starts to generate value Enhance consistency with better orchestration and data management Developing gen AI applications requires a level of orchestration and modularization that enables easy reuse of specific capabilities. Traditional continuous integration/continuous delivery (CI/CD) methods are often not up to the task, because they cannot maintain the necessary consistency between gen AI programs due to the introduction of gen AI–specific activities, such as prompt engineering. In response, some data and AI leaders are using agent-based frameworks, a structure that facilitates collaboration and coordination among multiple gen AI agents. These frameworks orchestrate gen AI agents and the complexities involved with scaling their use (and reuse). Agent-based frameworks are equipped with reasoning, code execution, tool usage, and planning abilities as well as enhanced workflow management. They can help address limitations associated with LLMs, such as process-management challenges, cross-verification errors, and end-to-end workflow design constraints. By incorporating these agents into a gen AI architecture, organizations can better manage complex tasks and improve overall performance, reliability, value, and user satisfaction. Some companies are employing agent-based frameworks in consumer-facing chatbots or enterprise knowledge retrieval systems. To better manage their data products, many companies are turning to a range of tools. Some are working with off-the-shelf tools, though these often have issues with complex scenarios, such as automatically generating insights from unstructured data. Organizations that use gen AI–augmented data catalogs can facilitate real-time metadata tagging, including automatically generating metadata from structured and unstructured content and creating smart tags. This has the effect of improving data discovery and assisting in the selection of appropriate structured and unstructured data for gen AI models. Migrate and modernize data products Before beginning the process of using gen AI capabilities, such as code translation, to migrate data products and their underlying pipelines from one platform to another, companies need to first determine the right LLM for the job. While many organizations use LLMs supplied by their cloud service provider, certain LLMs may be trained more proficiently on one set of coding languages than on others. For example, one LLM may be better suited to write PySpark code for pipelines, while another is more efficient at Terraform for developing infrastructure as code. Organizations can use these LLMs to facilitate smoother migration to platforms that use PySpark or SQL, though, in some cases, depending on the coding language or framework, fine-tuning a model may still be necessary. By understanding which LLMs to use for given coding languages—and how to automate code translation across languages—companies can better migrate pipelines from mainframes and legacy-managed services already in the cloud to more-modern cloud resources. Identifying the appropriate LLM, however, may require additional testing time, which data and AI leaders should account for in their project road maps. Scale gen AI with security and coding standards Data and AI leaders face big challenges in managing and governing the rapidly expanding use of unstructured data. The proliferation of gen AI models and applications not only introduces risks but also hampers getting to scale because teams often end up using different—and sometimes conflicting—tools and approaches. By protecting data at every stage of the development process and automating the integration of coding best practices, companies can mitigate risk as well as enforce standards to scale their gen AI solutions. Protect data at each step Unstructured data such as PDFs, video, and audio files hold a wealth of information for gen AI models, but they create significant security issues and require strong data-protection controls. Traditional access controls, however, may not suffice. Unstructured data, for example, must be converted into a format that a gen AI application can analyze to understand the context and to then generate metadata that help determine access rights to the data. To mitigate security risks, some data and AI leaders are designing modularized pipelines capable of automatically securing data. For example, extracting a revenue table with notes that span multiple pages in a PDF will require implementing traditional role-based access control, including hiding related sentences in the text. Because gen AI outputs are still often inconsistent, data and AI leaders should carefully build consistent, secure access controls and guardrails at each checkpoint in the data pipeline, from ingestion to vectorization to retrieval-augmented generation (RAG) to consumption by gen AI models. Integrate coding best practices into gen AI outputs A key feature of scale is ensuring the consistent adherence to approved standards and best practices when engineering data. This can be an issue when using code sourced directly from LLMs, where the quality may not meet expectations, because, for example, the code lacks organizational context or does not fit the standard frameworks an organization uses. To help overcome these issues and improve data quality, some organizations are integrating coding best practices into all their gen AI–generated code. Another approach is to use gen AI to analyze column values, determine appropriate rules for data quality based on existing rules, and then seamlessly integrate them into the pipeline generation process. Companies generally have a common set of data quality rules for data products, often with only slight changes across use cases. Organizations that define what those rules are—with the correct parameters for adjustments to different situations—can develop gen AI solutions that allow them to automatically add the rules to their pipelines. Gen AI tools are available to accelerate the development of data products and data platforms and improve their performance. But to use them effectively, companies will have to address a broad range of technical challenges. Focusing on orchestration capabilities, automating data-development programs, and improving usability will allow data and AI leaders to help their organizations move from gen AI pilots to scaling solutions that drive real value. Asin Tavakoli is a partner in McKinsey’s Düsseldorf office; Carlo Giovine is a partner in the London office; Joe Caserta and Jorge Machado are partners in the New York office, where Kayvaun Rowshankish is a senior partner; Jon Boorstein is a solutions architect in the Denver office; and Nathan Westby is a data strategist in the Chicago office. The authors wish to thank Bryan Petzold, Chett Rubenstein, Danny Siegel, Gaspard Fouilland, Henry Zhang, Jean-Baptiste Dubois, Malhar Aras, Mo Sherif, Neeraj Malhotra, Olivier Fournier, Patrick Wollner, and Ramin Ostad for their contributions to this article. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles The data dividend: Fueling generative AI Moving past gen AI’s honeymoon phase: Seven hard truths for CIOs to get from pilot to scale A generative AI reset: Rewiring to turn potential into value in 2024'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:07:57 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:07:57 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:07:57 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:07:57 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:07:57 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:07:57 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:07:58 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:07:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'667'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'195527'), (b'x-ratelimit-reset-requests', b'1m49.552s'), (b'x-ratelimit-reset-tokens', b'1.341s'), (b'x-request-id', b'req_1063ac73f661f294afa8104126ddc6e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608ca9df5c1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:07:58 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:07:58 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:07:58 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:07:58 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:07:58 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:07:58 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:07:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '667', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '195527', 'x-ratelimit-reset-requests': '1m49.552s', 'x-ratelimit-reset-tokens': '1.341s', 'x-request-id': 'req_1063ac73f661f294afa8104126ddc6e5', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608ca9df5c1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:07:58 [openai._base_client] DEBUG: request_id: req_1063ac73f661f294afa8104126ddc6e5
2024-08-20 02:07:58 [mckinsey_capabilities_digital_insights] INFO: Generated summary: Data and AI leaders face challenges scaling generative AI (gen AI) due to data management issues, including quality and integration difficulties. To overcome these, organizations can enhance data quality, utilize gen AI for better data products, and implement end-to-end automation
2024-08-20 02:07:58 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:58 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:07:59 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:59 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:07:59 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A13%3AG13 HTTP/11" 200 None
2024-08-20 02:07:59 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A13%3AG13?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:07:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-data-leaders-technical-guide-to-scaling-gen-ai>
{'title': 'A data leader’s technical guide to scaling gen AI', 'description': 'The emergence of gen AI is forcing data and AI leaders to revisit their data platforms. Companies that move now can position...', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/a-data-leaders-technical-guide-to-scaling-gen-ai', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/a%20data%20leaders%20technical%20guide%20to%20scaling%20gen%20ai/thumb-gettyimages-1746213675.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-07-08T12:00:00Z', 'article_text': 'A data leader’s technical guide to scaling gen AI Data and AI leaders have been working feverishly on generative AI (gen AI) use cases for more than a year. Their experience has provided promising glimpses of the considerable value at stake in gen AI but has also exposed a variety of challenges in getting to scale. Managing data remains one of the main barriers to value creation from gen AI. In fact, 70 percent of top performers in a recent McKinsey survey said they have experienced difficulties integrating data into AI models, ranging from issues with data quality, defining processes for data governance, and having sufficient training data. 1 “ The state of AI in early 2024: Gen AI adoption spikes and starts to generate value ,” McKinsey, May 30, 2024. About the authors This article is a collaborative effort by Asin Tavakoli , Carlo Giovine , Joe Caserta , Jorge Machado , and Kayvaun Rowshankish , with Jon Boorstein and Nathan Westby, representing views from McKinsey Digital and QuantumBlack, AI by McKinsey. In our experience, organizations have been held back by a still maturing understanding of both how to evolve data capabilities to support gen AI cases at scale and how to use gen AI to improve data practices. This article will cover three actions that data and AI leaders can consider to help them move from gen AI pilots to scaling data solutions. The first focuses on how organizations can strengthen the quality and readiness of their data for gen AI use cases. The second looks at how organizations can use gen AI to build better data products with their modernized data platforms. The third explores key data-management considerations that enable reuse and accelerate the development of data solutions. It starts at the source: Improve your data While data quality has long been an important concern for data and AI leaders, the risks and costs of feeding poor data into gen AI models cannot be overstated, ranging from poor outcomes, costly fixes, and cyber breaches to a loss of user trust in the outputs. The 2024 McKinsey survey cited above, in fact, found that 63 percent of respondents—seven percentage points more than in the 2023 survey—said that output inaccuracy was the greatest risk they saw in their organizations’ use of gen AI. 2 “ The state of AI in early 2024 ,” May 30, 2024. Traditional methods of ensuring data quality aren’t enough; leaders should consider the following ways of improving and expanding their source data. Obtain better and more-accurate source data from complex data types About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Organizations are struggling to handle the increased complexity of unstructured data sets. For example, banks might want to look at both structured financial information, such as transaction history, as well as financial statements and market analyses to determine the creditworthiness of a corporate client. But processing combinations of structured and unstructured data often increases the chance of errors because, while internal teams and subject-matter experts have the relevant knowledge, they generally struggle to codify that knowledge so that data pipeline processes can be easily replicated. Tools have evolved to handle the relationship between different types and sources of data. For example, knowledge graphs can help capture complex relationships between entities, providing meaningful context for large language models (LLMs) and their downstream data sets. These kinds of capabilities make it easier to accurately map data points from unstructured to structured data. Even when data engineers understand the relationship between data sets, they still need to assign different methods to interpret that data based on attributes, such as the data format (PDF, PowerPoint, Word, or image files, for example). This is a challenge as companies integrate formats into their systems that are becoming increasingly complex. Multimodal models are sophisticated enough now to parse more complex types of documents that feature disparate data formats, such as extracting tabular data from unstructured documents. While these models are becoming easier to use, they can still make mistakes (and, in some cases, are expensive). Accuracy issues require constant review, which is often still manual. Some data engineers, for example, spend a lot of time checking two screens of an integrated development environment to observe the differences between outputs. As concurrent use cases increase, this manual approach quickly hits its limits. Data leaders need to focus resources on implementing automated evaluation methods, mechanisms to manage versioning, and data-relevancy scoring to enhance multimodal model output accuracy and consistency. An investment firm knew it needed to improve its data access and usage to implement a virtual assistant. In order to use product information from structured and unstructured data sources, it had to build data pipelines for parsing and processing unstructured data, identify which version of each document was most recent, and adapt the length of articles for mobile users. The firm’s data engineers used multimodal model capabilities to parse tabular data from documents into structured data and build a medallion architecture (a popular design pattern for organizing data that supports modular pipeline development). Additionally, they introduced versioning and relevancy scores to improve output accuracy. As a result, the company was able to quickly start work on use cases, such as due-diligence activities, with a production-grade gen AI environment within two weeks. Creating value beyond the hype Create data when they aren’t available Some gen AI use cases are difficult to pursue because the required data are difficult to obtain and process, which is often an issue in healthcare, life sciences, or other sectors that have stringent data security regulations. To overcome these challenges, in some cases, a data engineer can manually generate a file to test the efficacy of a use case. But the process can be time-consuming and inefficient. Instead, data and AI leaders are investing in gen AI tools to generate synthetic data as test data or to produce new values based completely on the column descriptions and context of the table, allowing them to either create a new data set or make revisions to an existing one. Some companies have already used synthetic data generators to create statistically similar data sets. Use gen AI to accelerate the building of reusable data products Data products , such as a 360-degree view of individual customers, are the cornerstone of how companies use data to generate value at scale for the business. 3 Veeral Desai, Tim Fountaine, and Kayvaun Rowshankish, “ How to unlock the full value of data? Manage it like a product ,” McKinsey, June 14, 2022. But such data products can be difficult and time-consuming to develop. With better data and new gen AI tools, however, companies are finding they can accelerate development and improve outputs. For example, one hospitality company expedited the creation of customer domain data models by up to 60 percent while increasing productivity in feature engineering by 50 percent. It was able to hit those marks by focusing on automatically generating both end-to-end data transformation pipelines in PySpark and robust documentation of all the complex transformations that occurred. Shift to end-to-end creation of data products Until recently, available technology has limited the creation of data pipelines (such as a medallion architecture) to a laborious step-by-step approach. While using gen AI to perform tasks, such as generating an individual table from natural language, may make data engineers more efficient, engineers still must complete a series of other upstream and downstream steps, such as combining all the tables. Data and AI leaders instead are starting to take an end-to-end approach to building data pipelines by automating all the steps, achieving, in some cases, time savings of 80 to 90 percent and enhanced scalability for specific use cases. Writing the data pipeline code to generate data products traditionally has been one of the most time-consuming tasks for data engineers. We now are seeing the automated creation of data pipelines, written in languages such as SQL or Python, to create entire models that can solve for multiple use cases at once. Rather than looking at a modest scope of work, such as generating an individual table from a natural-language prompt, the capabilities exist to generate dozens of tables as a cohesive target data model capable of providing solutions to multiple use cases. Before an organization can begin generating these types of capabilities, however, it needs to ensure it has trustworthy, easily understandable, and available data. For companies that have been building their data estate for many years, an important element of this process is understanding their legacy code bases and existing data. Many companies struggle, however, because of poor data lineage or cataloging, leading to a limited understanding of how their data are generated. In response, some companies are employing a variety of agents (gen AI applications) across multiple LLMs to analyze legacy code bases and generate natural-language text descriptions. This approach not only improves the organization’s understanding of its code base but also facilitates the creation of data catalog features, streamlining the identification and removal of redundant code segments. The state of AI in early 2024: Gen AI adoption spikes and starts to generate value Enhance consistency with better orchestration and data management Developing gen AI applications requires a level of orchestration and modularization that enables easy reuse of specific capabilities. Traditional continuous integration/continuous delivery (CI/CD) methods are often not up to the task, because they cannot maintain the necessary consistency between gen AI programs due to the introduction of gen AI–specific activities, such as prompt engineering. In response, some data and AI leaders are using agent-based frameworks, a structure that facilitates collaboration and coordination among multiple gen AI agents. These frameworks orchestrate gen AI agents and the complexities involved with scaling their use (and reuse). Agent-based frameworks are equipped with reasoning, code execution, tool usage, and planning abilities as well as enhanced workflow management. They can help address limitations associated with LLMs, such as process-management challenges, cross-verification errors, and end-to-end workflow design constraints. By incorporating these agents into a gen AI architecture, organizations can better manage complex tasks and improve overall performance, reliability, value, and user satisfaction. Some companies are employing agent-based frameworks in consumer-facing chatbots or enterprise knowledge retrieval systems. To better manage their data products, many companies are turning to a range of tools. Some are working with off-the-shelf tools, though these often have issues with complex scenarios, such as automatically generating insights from unstructured data. Organizations that use gen AI–augmented data catalogs can facilitate real-time metadata tagging, including automatically generating metadata from structured and unstructured content and creating smart tags. This has the effect of improving data discovery and assisting in the selection of appropriate structured and unstructured data for gen AI models. Migrate and modernize data products Before beginning the process of using gen AI capabilities, such as code translation, to migrate data products and their underlying pipelines from one platform to another, companies need to first determine the right LLM for the job. While many organizations use LLMs supplied by their cloud service provider, certain LLMs may be trained more proficiently on one set of coding languages than on others. For example, one LLM may be better suited to write PySpark code for pipelines, while another is more efficient at Terraform for developing infrastructure as code. Organizations can use these LLMs to facilitate smoother migration to platforms that use PySpark or SQL, though, in some cases, depending on the coding language or framework, fine-tuning a model may still be necessary. By understanding which LLMs to use for given coding languages—and how to automate code translation across languages—companies can better migrate pipelines from mainframes and legacy-managed services already in the cloud to more-modern cloud resources. Identifying the appropriate LLM, however, may require additional testing time, which data and AI leaders should account for in their project road maps. Scale gen AI with security and coding standards Data and AI leaders face big challenges in managing and governing the rapidly expanding use of unstructured data. The proliferation of gen AI models and applications not only introduces risks but also hampers getting to scale because teams often end up using different—and sometimes conflicting—tools and approaches. By protecting data at every stage of the development process and automating the integration of coding best practices, companies can mitigate risk as well as enforce standards to scale their gen AI solutions. Protect data at each step Unstructured data such as PDFs, video, and audio files hold a wealth of information for gen AI models, but they create significant security issues and require strong data-protection controls. Traditional access controls, however, may not suffice. Unstructured data, for example, must be converted into a format that a gen AI application can analyze to understand the context and to then generate metadata that help determine access rights to the data. To mitigate security risks, some data and AI leaders are designing modularized pipelines capable of automatically securing data. For example, extracting a revenue table with notes that span multiple pages in a PDF will require implementing traditional role-based access control, including hiding related sentences in the text. Because gen AI outputs are still often inconsistent, data and AI leaders should carefully build consistent, secure access controls and guardrails at each checkpoint in the data pipeline, from ingestion to vectorization to retrieval-augmented generation (RAG) to consumption by gen AI models. Integrate coding best practices into gen AI outputs A key feature of scale is ensuring the consistent adherence to approved standards and best practices when engineering data. This can be an issue when using code sourced directly from LLMs, where the quality may not meet expectations, because, for example, the code lacks organizational context or does not fit the standard frameworks an organization uses. To help overcome these issues and improve data quality, some organizations are integrating coding best practices into all their gen AI–generated code. Another approach is to use gen AI to analyze column values, determine appropriate rules for data quality based on existing rules, and then seamlessly integrate them into the pipeline generation process. Companies generally have a common set of data quality rules for data products, often with only slight changes across use cases. Organizations that define what those rules are—with the correct parameters for adjustments to different situations—can develop gen AI solutions that allow them to automatically add the rules to their pipelines. Gen AI tools are available to accelerate the development of data products and data platforms and improve their performance. But to use them effectively, companies will have to address a broad range of technical challenges. Focusing on orchestration capabilities, automating data-development programs, and improving usability will allow data and AI leaders to help their organizations move from gen AI pilots to scaling solutions that drive real value. Asin Tavakoli is a partner in McKinsey’s Düsseldorf office; Carlo Giovine is a partner in the London office; Joe Caserta and Jorge Machado are partners in the New York office, where Kayvaun Rowshankish is a senior partner; Jon Boorstein is a solutions architect in the Denver office; and Nathan Westby is a data strategist in the Chicago office. The authors wish to thank Bryan Petzold, Chett Rubenstein, Danny Siegel, Gaspard Fouilland, Henry Zhang, Jean-Baptiste Dubois, Malhar Aras, Mo Sherif, Neeraj Malhotra, Olivier Fournier, Patrick Wollner, and Ramin Ostad for their contributions to this article. This article was edited by Barr Seitz, an editorial director in the New York office. Explore a career with us Related Articles The data dividend: Fueling generative AI Moving past gen AI’s honeymoon phase: Seven hard truths for CIOs to get from pilot to scale A generative AI reset: Rewiring to turn potential into value in 2024', 'summary': 'Data and AI leaders face challenges scaling generative AI (gen AI) due to data management issues, including quality and integration difficulties. To overcome these, organizations can enhance data quality, utilize gen AI for better data products, and implement end-to-end automation'}
2024-08-20 02:07:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/gen-ai-and-beyond-where-else-to-focus-now> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:08:00 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nGen AI and beyond: Where else to focus now Gen AI has rightly seized leaders’ attention. But is it also eclipsing lower-profile digital imperatives? On this episode of The McKinsey Podcast , McKinsey senior partners Rodney Zemmel and Kate Smaje , with global editorial director Lucia Rahilly, talk about ideas leaders risk overlooking with gen AI in the spotlight , and how to ensure your digital initiatives—including gen AI—work in tandem to drive meaningful value. This transcript has been edited for clarity and length. The McKinsey Podcast is cohosted by Roberta Fusaro and Lucia Rahilly. Where to start Lucia Rahilly: Gen AI has been the shiny new object of the business world, but as your new article suggests, it risks blinding leaders to other digital tools also vital to their organization’s success. How do you see leaders balancing that tendency to go after the glitter with the need to maintain focus on other essential business operations and strategies? Rodney Zemmel: Generative AI is a very shiny object indeed, which sounds a bit disparaging because it can and is already delivering real value. But it’s the wrong question to ask, “What’s my gen AI strategy?” You’ve got to start with where value comes from and think about how you get value from transforming a domain of your business with technology. Whether generative AI , old-fashioned AI, process digitization, or anything else, that has to be subsidiary to the question of where value is coming from. Business that’s like your brain Lucia Rahilly: Your report lays out ten “unsung ideas” on digital and AI, and today we’re going to focus on three of those. Let’s start with the idea that every company will become a neural business. What does this mean? Rodney Zemmel: There were a couple of amazing scientific breakthroughs last year in our understanding of the brain. At my old lab in Cambridge, we got our first visualization of the connectome, or how all the different neurons fit together—first in a fruit fly brain, and then from a slice of the human brain from a Google team. What we see is this incredible, intricate architecture where everything connects with everything else. And we think this is the new metaphor for business. The old metaphor for how a business is organized is a tree: hierarchical, with branches that extend from each other. But the trouble with that analogy is that it’s very hard to get connections across the boughs\xa0of the tree. To do most interesting and innovative things in business, you’ve got to get those connections working much more effectively than they do in many rigid hierarchical organizations. This isn’t a new idea. It’s a new take on it, and it speaks to the scale of the connections needed. But also, you need to make sure the overall common patterns, governance, and organizing structure is beautifully intricate and networked and enables teams across the organization to work with each other and form and reform without complete chaos. Want to subscribe to The McKinsey Podcast ? Kate Smaje: This is about enabling speed. Could I, as an organization, work at a higher metabolic rate than today? And second, this is about scale. That’s where some of these common patterns come into play, because the greater the reusability, the greater the pattern recognition, the more you’re able to do at scale, as opposed to reinventing the wheel every time. Lucia Rahilly: Teams have to function autonomously as they’re forming and reforming. Could you say a bit about what autonomy means in this context? Rodney Zemmel: One way to take this forward is in what we call a product and platform company. You have a central set of platform services and a distributed network of empowered teams that have autonomy and are aligned against a specific business goal, and they draw services from the central platform. They’re autonomous in that they’re self-contained and working toward a business goal they own. But they’re not autonomous in that they’re working within an overall company framework and set of objectives, there’s a platform team from which they’re expected to draw services, and they follow rules rather than just go create their own. What we’ve seen in this product and platform model is that it’s early days. But if we look at a set of companies that have adopted it, the top half of companies in terms of maturity had 60 percent greater total shareholder returns than the bottom half of companies. Lucia Rahilly: Could you give us an example of a company that has successfully implemented this agile neural network approach? Rodney Zemmel: One of the companies we talked about in our Rewired book , DBS Bank, known as one of the leading banks in digital banking, has really rethought of itself into horizontal cells . As soon as you use a banking example, people say, “Well, that obviously makes sense in a service industry.” But another company that’s in the book, Freeport-McMoRan, has done this in their copper mining operations. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Kate Smaje: One of the ways any company can test this is by asking a simple question: How quickly can you conceive of, build, and launch a new product and service today? Rodney Zemmel: The acid test is a good question, because it’s hard to find a company these days where a senior leader won’t say, “Yeah, of course we’re working at agile.” And often what that means is they have a technology team working in agile . But it won’t always mean that business and technology are working together properly, and frankly, it rarely means that you’ve got the control functions embedded in those agile pods in the right way. Lucia Rahilly: Speaking of control functions, what kind of operating model needs to be in place for this kind of neural business to function successfully? And what kind of oversight is necessary for these autonomous teams to function well, including limiting missteps and keeping productivity up in this model? Rodney Zemmel: Right, and how do you do it at scale? Because again, many companies can do this, but how you do it across dozens to hundreds of teams? That’s the hard part. First, a lot of it is about talent . You need to put the effort into upskilling and reskilling your talent to be able to work in this model. Then it’s about being super thoughtful on how you staff these teams and how you get your senior leadership team comfortable so they’ll set guardrails and objectives. They’ll participate in reviews at the big milestones, but every decision is not running up the chain to them. It requires a fairly evolved governance framework. Let’s take data as an example, really figuring out all the data governance rules within your organization because you can see a clear ROI on the next AI use case. If you’re not putting those data governance models and rules in place up front, then you’re going to make it impossible to work in this kind of distributed and scalable model. Kate Smaje: I ask, “Do I have a set of outcomes that empowered teams are working toward?” This is where it becomes important for management to check in and know how things are going. If you have alignment on the desired team outcomes, then you have transparency into whether we’re there yet. And if not, what’s getting in the way? How do we be better next time? Last, back to this notion of pattern recognition, how do I make sure I’m solving for reusability? How the best pull away Lucia Rahilly: Let’s move to another of these ideas, on digital and AI leaders becoming forever transformers. What are some of the new technologies or trends leaders should be on the lookout for now? Kate Smaje: In some ways, everybody has the technology they love to geek out on, and we’re as guilty of that as the next person. But for me, the magic is less about a single technology or singular trend and more about the combined power of bringing several of these technologies together. It’s only when that really happens—and, by the way, the same was true for generative AI—that you create an opportunity for a breakthrough in creating a new business model, creating a disruption that hadn’t happened before. But for me, the magic is less about a single technology or singular trend and more about the combined power of bringing several of these technologies together. Rodney Zemmel: We have an analysis called Digital Quotient or AI Quotient , where we look at how well companies have adopted different digital or AI approaches. In the past two or three years, we’ve seen that industry is no longer destiny. There’s much greater difference within an industry than there is between industries. The most advanced industrial companies are more digitized than the high-tech median, and the least advanced are less digitized than the public-sector median. What’s behind that is this notion of a forever transformer. You see companies that started on the journey are able to get ahead, keep investing, and, frankly, get further ahead. And you see increasing returns to digital leaders over time as they’re able to pull ahead of others in the industry. Lucia Rahilly: I have kind of a romantic fascination with quantum . I went through a Carlo Rovelli phase. Rodney Zemmel: He’s so good. Lucia Rahilly: He’s so good. I liked to think about quantum entanglement as a romantic construct. But our research shows that some industries stand to gain considerably by applying quantum computing very practically to specific use cases, whereas I tend to think of it as more abstract. What does quantum in practice look like? Rodney Zemmel: I’m as excited as you are about quantum. In fact, all the conversations we’re having about AI or gen AI today could be about quantum five to ten years from now. It’s important to emphasize that it is still a science experiment. While the pace of change is amazing, the number of functional qubits, which are the units you need to perform quantum work, that you can get in a quantum computer today is still really small. So it’s still in the research or maybe early development phase. But if it works, the impact could be absolutely spectacular. Industries being talked about are financial services, pharmaceuticals, chemical and agriculture, automotive, and a range of others. And, essentially, the many hard math problems that would take years to centuries to solve using traditional algorithms can go much, much faster with a quantum algorithm approach. You can solve them in an exponential rather than a linear rate. So it could affect everything from portfolio construction and performance analysis in financial services to how to design effective catalysis in agriculture—which doesn’t sound that exciting, but if you could find a more efficient way to produce ammonia-based fertilizers, the economic impact on the world would be enormous. I have a feeling that what goes first will be things that resemble real quantum physics problems. But then over time, anything that’s a complex math problem—whether how to redesign a delivery route for a logistics company or how to best build up layers of carbon fiber to develop a strong material for aerospace—will be massively tractable by quantum computing when it works. Making gen AI your superpower Lucia Rahilly: As gen AI gets better and better and employees become increasingly dependent on it for at least some parts of their portfolio, how can organizations identify which roles or tasks will benefit most from gen AI to create a more productive workforce? Kate Smaje: Our research undoubtedly says there is opportunity for major productivity gains, but they’re pretty hard to realize today. Some of that is because you must have, for any technology breakthrough, a commensurate or an equal and opposite breakthrough on the human side. How am I going to change the workflow so that I can materially free up time? What am I going to do in terms of learnings, upskilling, reskilling, new career paths that fundamentally reset what humans will do when AI superpowers sit alongside them? Rodney Zemmel: The gen AI superpower is not how to find a way to save 20 minutes in your day, but how to find a way to make using gen AI your first instinct. We’ve seen it so far in software development. If you just give the tools to a software developer and say, “Here’s the latest,” the developers will each go find the most boring part of what they do and use it to accelerate that. And you’ll get these 5 or 10 percent productivity benefits. If instead you say, let’s look at the full team and look at a week or month in the life of the software development life cycle and not just, how does developer A or B do their job on an average Tuesday? And you think about how the whole team changes their work, you train people, and you have real measurement for where it’s working better than a human or not—that’s how you build superpowers. Lucia Rahilly: How are you seeing leaders tackle that learning and training? Kate Smaje: What I see a lot of is, we’re going to train our organization on tech, on AI. We’re going to teach them what it is, we’re going to explain it, bust the myths, and so on. And that’s important, don’t get me wrong. But it’s one of those necessary but not sufficient things. The things missing are, for example, to really use well what is fundamentally an assistive technology. You have to know how to use it to get the best out of it. We certainly see investments in things like teaching how to do great prompts. So rather than teaching you about it, teaching you how to use it becomes really important. The second is, to Rodney’s point, in the day-to-day workflow. It’s about making sure you have incredible critical thinking skills to be able to parse out some of the complex risk and responsible AI usage issues, to think about how hallucination is going to run through this, and what you need to do in the pre- and post-processing of the modeling. You will probably need to have amazing EQ [emotional quotient] and relational skills, because what the human is going to do—that the tech won’t—may be more on that side. Maybe even, frankly, people will need higher cognitive capacity or curiosity to learn, to keep evolving and iterating. For me, there’s not yet enough focus on what let’s call the nontech skills the human is really going to need in a hybrid intelligence setting. Lucia Rahilly: Do you see tech professionals as equally in need of upskilling as employees outside the tech sector? Kate Smaje: It’s both. None of us is immune to the need to keep learning, not least because, in some ways, the pace of change today will never be this slow again. It’s about your ability, even as a tech professional, to understand and be open to the new technologies that will come in. How do I make sure I’m ready to learn and embrace those? How do I keep getting better at using that technology in my job? As a technologist, how am I going to help get value out of models, not just build great models? Rodney Zemmel: For the average company, a senior team is going to learn better from seeing what a leading nontech company does than a tech company. What we’ve seen work very successfully is when management teams have done what we call go-and-see visits with other companies, often in industries quite different from their own, where average companies have really applied this and really learned how to transform their businesses with digital and AI. For the average company, a senior team is going to learn better from seeing what a leading nontech company does than a tech company. Once you see a “normal” company do it, that brings the power of the technology to life much more than seeing what digital natives can do—which for the average company, is exciting but feels a bit more like a trip to the zoo than something directly relevant to their daily lives. What lies ahead Lucia Rahilly: Do you see a risk of employees becoming overly reliant on AI? And do organizations need to take steps to help ensure employees retain their human judgment? Kate Smaje: In some ways, we can see “reliance on AI” as a pejorative term or as a real positive, in that employees are using AI to do their jobs better, faster, cheaper, at lower risk. The reality is that human judgment will become more important than ever for making sure these models are built responsibly, and more important in making sure the value really comes out of them. To make sure humans are using AI responsibly, there are at least two things to consider. One is constantly questioning the technology. The second is constantly looking for the “and.” Where does one plus one equal five here, regarding bringing humans plus technology to get a breakthrough that wasn’t otherwise possible? As long as we’re still doing those two things, human judgment will become more important, not less. Rodney Zemmel: That said, it’s clear that this is going to be better than humans in many cases. I’ll give you a maybe silly example. In tennis, there’s electronic line judging. Wimbledon and the US Open have gone different routes. In Wimbledon they have electronic line judging, but they keep the humans wearing green blazers standing on the sidelines. In the US Open, they’ve gone all electronic. And most people would say the US Open version is working just as well or better. There’s less interruption of play. There’s less back and forth. There are no more obviously wrong calls. Interestingly, I’m told that the US Open employs as many people as Wimbledon does, but in different jobs. It’s people in the tech control room, and people that are deploying, setting up, and monitoring the technology. Lucia Rahilly: We recently posted an interview with Reid Hoffman for the At the Edge podcast. He suggested that AI has the potential to develop EQ and soft skills. Any thoughts on how that might affect the AI–human calculus in the workplace? Kate Smaje: We see this already. Rodney and I often joke about this very small study that was done in the United Kingdom with GPs [general practitioners], where they tested a human versus a bot to see if the patient could tell the difference. The patients pretty much could, in most cases. Then the patients were asked which they preferred. Staggeringly, most folks preferred the bot. They said, “I felt that it understood my needs better. It was more empathetic. It solved my problem faster.” We shouldn’t underestimate that the technology is already pretty darn good at the qualities we often associate with humans. Lucia Rahilly: Anything else to call out that might not be top of mind for leaders but should be? Rodney Zemmel: There’s a question about what the future of the workforce is going to look like. There was a very interesting interview with Garry Kasparov some time ago. He famously was beaten by the IBM chess computer back in the ’90s. He said, “Look, I was the first knowledge worker to lose my job to a computer. And now it’s coming for all of you.” That’s a bit exaggerated, but that view is clearly out there. There are companies that say, “OK, we no longer need junior people, analysts, people doing routine tasks. We can get away with a workforce or evolve to a workforce that has a very different pyramid shape.” There are others who say, “Maybe. But this is about the superpowers idea. It means we can make the analysts or the junior people in our company as productive in the future as our most senior people are today, because this is going to take away a lot of the routinized drudgery of what they do and really give them these incredible abilities to create more value.” There’s a view that says the value of the data scientist goes down and the value of the data engineer goes up in the future. So from a workforce planning standpoint, this is profound. Frankly, the answer doesn’t exist yet. People are going to need some real thinking time and flexibility to evolve what this means for workforce planning. Kate Smaje: I couldn’t agree more. Your point on flex has another flavor to it as well, in that so much of what we’re really talking about here is constant learning, constant experimentation. And that’s very easy to fund, resource, and allocate time to in good times. It’s much harder to do when economies or markets turn and companies have to batten down the hatches. There is a real challenge for leaders to figure out: how do I have a more through-cycle mindset for investing and learning for the future when the level of certainty, and therefore the level of ROI prediction, is more challenged? Can I have a plan here that’s flexible enough for sunny times as well as rainy ones? Lucia Rahilly is the global editorial director of McKinsey Global Publishing and is based in the New York office. Explore a career with us Related Articles Ten unsung digital and AI ideas shaping business The economic potential of generative AI: The next productivity frontier Steady progress in approaching the quantum advantage'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:08:00 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:08:00 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:08:00 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:08:00 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:08:00 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:08:00 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:08:00 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:08:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'628'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'194500'), (b'x-ratelimit-reset-requests', b'1m55.874s'), (b'x-ratelimit-reset-tokens', b'1.65s'), (b'x-request-id', b'req_6bdf12d861f18ae29bfcf27e933aefd1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608cb84a1a1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:08:00 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:08:00 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:08:00 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:08:00 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:08:00 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:08:00 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:08:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '628', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '194500', 'x-ratelimit-reset-requests': '1m55.874s', 'x-ratelimit-reset-tokens': '1.65s', 'x-request-id': 'req_6bdf12d861f18ae29bfcf27e933aefd1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608cb84a1a1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:08:00 [openai._base_client] DEBUG: request_id: req_6bdf12d861f18ae29bfcf27e933aefd1
2024-08-20 02:08:00 [mckinsey_capabilities_digital_insights] INFO: Generated summary: In a McKinsey Podcast episode, leaders discuss the importance of balancing focus on generative AI with other digital initiatives, emphasizing the need for a neural business model that fosters connections and autonomy among teams. They also highlight the necessity of upskilling,
2024-08-20 02:08:01 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:08:01 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:08:01 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:08:01 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:08:01 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A14%3AG14 HTTP/11" 200 None
2024-08-20 02:08:01 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A14%3AG14?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:08:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/gen-ai-and-beyond-where-else-to-focus-now>
{'title': 'Gen AI and beyond: Where else to focus now', 'description': 'Yes, gen AI can be dazzling. But to deliver value, leaders will have to look beyond center stage.', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/gen-ai-and-beyond-where-else-to-focus-now', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/gen%20ai%20and%20beyond%20where%20else%20to%20focus%20now/dont%20let%20gen%20ai%20outshine%20other%20business%20imperatives-1596100353-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-07-12T12:00:00Z', 'article_text': 'Gen AI and beyond: Where else to focus now Gen AI has rightly seized leaders’ attention. But is it also eclipsing lower-profile digital imperatives? On this episode of The McKinsey Podcast , McKinsey senior partners Rodney Zemmel and Kate Smaje , with global editorial director Lucia Rahilly, talk about ideas leaders risk overlooking with gen AI in the spotlight , and how to ensure your digital initiatives—including gen AI—work in tandem to drive meaningful value. This transcript has been edited for clarity and length. The McKinsey Podcast is cohosted by Roberta Fusaro and Lucia Rahilly. Where to start Lucia Rahilly: Gen AI has been the shiny new object of the business world, but as your new article suggests, it risks blinding leaders to other digital tools also vital to their organization’s success. How do you see leaders balancing that tendency to go after the glitter with the need to maintain focus on other essential business operations and strategies? Rodney Zemmel: Generative AI is a very shiny object indeed, which sounds a bit disparaging because it can and is already delivering real value. But it’s the wrong question to ask, “What’s my gen AI strategy?” You’ve got to start with where value comes from and think about how you get value from transforming a domain of your business with technology. Whether generative AI , old-fashioned AI, process digitization, or anything else, that has to be subsidiary to the question of where value is coming from. Business that’s like your brain Lucia Rahilly: Your report lays out ten “unsung ideas” on digital and AI, and today we’re going to focus on three of those. Let’s start with the idea that every company will become a neural business. What does this mean? Rodney Zemmel: There were a couple of amazing scientific breakthroughs last year in our understanding of the brain. At my old lab in Cambridge, we got our first visualization of the connectome, or how all the different neurons fit together—first in a fruit fly brain, and then from a slice of the human brain from a Google team. What we see is this incredible, intricate architecture where everything connects with everything else. And we think this is the new metaphor for business. The old metaphor for how a business is organized is a tree: hierarchical, with branches that extend from each other. But the trouble with that analogy is that it’s very hard to get connections across the boughs\xa0of the tree. To do most interesting and innovative things in business, you’ve got to get those connections working much more effectively than they do in many rigid hierarchical organizations. This isn’t a new idea. It’s a new take on it, and it speaks to the scale of the connections needed. But also, you need to make sure the overall common patterns, governance, and organizing structure is beautifully intricate and networked and enables teams across the organization to work with each other and form and reform without complete chaos. Want to subscribe to The McKinsey Podcast ? Kate Smaje: This is about enabling speed. Could I, as an organization, work at a higher metabolic rate than today? And second, this is about scale. That’s where some of these common patterns come into play, because the greater the reusability, the greater the pattern recognition, the more you’re able to do at scale, as opposed to reinventing the wheel every time. Lucia Rahilly: Teams have to function autonomously as they’re forming and reforming. Could you say a bit about what autonomy means in this context? Rodney Zemmel: One way to take this forward is in what we call a product and platform company. You have a central set of platform services and a distributed network of empowered teams that have autonomy and are aligned against a specific business goal, and they draw services from the central platform. They’re autonomous in that they’re self-contained and working toward a business goal they own. But they’re not autonomous in that they’re working within an overall company framework and set of objectives, there’s a platform team from which they’re expected to draw services, and they follow rules rather than just go create their own. What we’ve seen in this product and platform model is that it’s early days. But if we look at a set of companies that have adopted it, the top half of companies in terms of maturity had 60 percent greater total shareholder returns than the bottom half of companies. Lucia Rahilly: Could you give us an example of a company that has successfully implemented this agile neural network approach? Rodney Zemmel: One of the companies we talked about in our Rewired book , DBS Bank, known as one of the leading banks in digital banking, has really rethought of itself into horizontal cells . As soon as you use a banking example, people say, “Well, that obviously makes sense in a service industry.” But another company that’s in the book, Freeport-McMoRan, has done this in their copper mining operations. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Kate Smaje: One of the ways any company can test this is by asking a simple question: How quickly can you conceive of, build, and launch a new product and service today? Rodney Zemmel: The acid test is a good question, because it’s hard to find a company these days where a senior leader won’t say, “Yeah, of course we’re working at agile.” And often what that means is they have a technology team working in agile . But it won’t always mean that business and technology are working together properly, and frankly, it rarely means that you’ve got the control functions embedded in those agile pods in the right way. Lucia Rahilly: Speaking of control functions, what kind of operating model needs to be in place for this kind of neural business to function successfully? And what kind of oversight is necessary for these autonomous teams to function well, including limiting missteps and keeping productivity up in this model? Rodney Zemmel: Right, and how do you do it at scale? Because again, many companies can do this, but how you do it across dozens to hundreds of teams? That’s the hard part. First, a lot of it is about talent . You need to put the effort into upskilling and reskilling your talent to be able to work in this model. Then it’s about being super thoughtful on how you staff these teams and how you get your senior leadership team comfortable so they’ll set guardrails and objectives. They’ll participate in reviews at the big milestones, but every decision is not running up the chain to them. It requires a fairly evolved governance framework. Let’s take data as an example, really figuring out all the data governance rules within your organization because you can see a clear ROI on the next AI use case. If you’re not putting those data governance models and rules in place up front, then you’re going to make it impossible to work in this kind of distributed and scalable model. Kate Smaje: I ask, “Do I have a set of outcomes that empowered teams are working toward?” This is where it becomes important for management to check in and know how things are going. If you have alignment on the desired team outcomes, then you have transparency into whether we’re there yet. And if not, what’s getting in the way? How do we be better next time? Last, back to this notion of pattern recognition, how do I make sure I’m solving for reusability? How the best pull away Lucia Rahilly: Let’s move to another of these ideas, on digital and AI leaders becoming forever transformers. What are some of the new technologies or trends leaders should be on the lookout for now? Kate Smaje: In some ways, everybody has the technology they love to geek out on, and we’re as guilty of that as the next person. But for me, the magic is less about a single technology or singular trend and more about the combined power of bringing several of these technologies together. It’s only when that really happens—and, by the way, the same was true for generative AI—that you create an opportunity for a breakthrough in creating a new business model, creating a disruption that hadn’t happened before. But for me, the magic is less about a single technology or singular trend and more about the combined power of bringing several of these technologies together. Rodney Zemmel: We have an analysis called Digital Quotient or AI Quotient , where we look at how well companies have adopted different digital or AI approaches. In the past two or three years, we’ve seen that industry is no longer destiny. There’s much greater difference within an industry than there is between industries. The most advanced industrial companies are more digitized than the high-tech median, and the least advanced are less digitized than the public-sector median. What’s behind that is this notion of a forever transformer. You see companies that started on the journey are able to get ahead, keep investing, and, frankly, get further ahead. And you see increasing returns to digital leaders over time as they’re able to pull ahead of others in the industry. Lucia Rahilly: I have kind of a romantic fascination with quantum . I went through a Carlo Rovelli phase. Rodney Zemmel: He’s so good. Lucia Rahilly: He’s so good. I liked to think about quantum entanglement as a romantic construct. But our research shows that some industries stand to gain considerably by applying quantum computing very practically to specific use cases, whereas I tend to think of it as more abstract. What does quantum in practice look like? Rodney Zemmel: I’m as excited as you are about quantum. In fact, all the conversations we’re having about AI or gen AI today could be about quantum five to ten years from now. It’s important to emphasize that it is still a science experiment. While the pace of change is amazing, the number of functional qubits, which are the units you need to perform quantum work, that you can get in a quantum computer today is still really small. So it’s still in the research or maybe early development phase. But if it works, the impact could be absolutely spectacular. Industries being talked about are financial services, pharmaceuticals, chemical and agriculture, automotive, and a range of others. And, essentially, the many hard math problems that would take years to centuries to solve using traditional algorithms can go much, much faster with a quantum algorithm approach. You can solve them in an exponential rather than a linear rate. So it could affect everything from portfolio construction and performance analysis in financial services to how to design effective catalysis in agriculture—which doesn’t sound that exciting, but if you could find a more efficient way to produce ammonia-based fertilizers, the economic impact on the world would be enormous. I have a feeling that what goes first will be things that resemble real quantum physics problems. But then over time, anything that’s a complex math problem—whether how to redesign a delivery route for a logistics company or how to best build up layers of carbon fiber to develop a strong material for aerospace—will be massively tractable by quantum computing when it works. Making gen AI your superpower Lucia Rahilly: As gen AI gets better and better and employees become increasingly dependent on it for at least some parts of their portfolio, how can organizations identify which roles or tasks will benefit most from gen AI to create a more productive workforce? Kate Smaje: Our research undoubtedly says there is opportunity for major productivity gains, but they’re pretty hard to realize today. Some of that is because you must have, for any technology breakthrough, a commensurate or an equal and opposite breakthrough on the human side. How am I going to change the workflow so that I can materially free up time? What am I going to do in terms of learnings, upskilling, reskilling, new career paths that fundamentally reset what humans will do when AI superpowers sit alongside them? Rodney Zemmel: The gen AI superpower is not how to find a way to save 20 minutes in your day, but how to find a way to make using gen AI your first instinct. We’ve seen it so far in software development. If you just give the tools to a software developer and say, “Here’s the latest,” the developers will each go find the most boring part of what they do and use it to accelerate that. And you’ll get these 5 or 10 percent productivity benefits. If instead you say, let’s look at the full team and look at a week or month in the life of the software development life cycle and not just, how does developer A or B do their job on an average Tuesday? And you think about how the whole team changes their work, you train people, and you have real measurement for where it’s working better than a human or not—that’s how you build superpowers. Lucia Rahilly: How are you seeing leaders tackle that learning and training? Kate Smaje: What I see a lot of is, we’re going to train our organization on tech, on AI. We’re going to teach them what it is, we’re going to explain it, bust the myths, and so on. And that’s important, don’t get me wrong. But it’s one of those necessary but not sufficient things. The things missing are, for example, to really use well what is fundamentally an assistive technology. You have to know how to use it to get the best out of it. We certainly see investments in things like teaching how to do great prompts. So rather than teaching you about it, teaching you how to use it becomes really important. The second is, to Rodney’s point, in the day-to-day workflow. It’s about making sure you have incredible critical thinking skills to be able to parse out some of the complex risk and responsible AI usage issues, to think about how hallucination is going to run through this, and what you need to do in the pre- and post-processing of the modeling. You will probably need to have amazing EQ [emotional quotient] and relational skills, because what the human is going to do—that the tech won’t—may be more on that side. Maybe even, frankly, people will need higher cognitive capacity or curiosity to learn, to keep evolving and iterating. For me, there’s not yet enough focus on what let’s call the nontech skills the human is really going to need in a hybrid intelligence setting. Lucia Rahilly: Do you see tech professionals as equally in need of upskilling as employees outside the tech sector? Kate Smaje: It’s both. None of us is immune to the need to keep learning, not least because, in some ways, the pace of change today will never be this slow again. It’s about your ability, even as a tech professional, to understand and be open to the new technologies that will come in. How do I make sure I’m ready to learn and embrace those? How do I keep getting better at using that technology in my job? As a technologist, how am I going to help get value out of models, not just build great models? Rodney Zemmel: For the average company, a senior team is going to learn better from seeing what a leading nontech company does than a tech company. What we’ve seen work very successfully is when management teams have done what we call go-and-see visits with other companies, often in industries quite different from their own, where average companies have really applied this and really learned how to transform their businesses with digital and AI. For the average company, a senior team is going to learn better from seeing what a leading nontech company does than a tech company. Once you see a “normal” company do it, that brings the power of the technology to life much more than seeing what digital natives can do—which for the average company, is exciting but feels a bit more like a trip to the zoo than something directly relevant to their daily lives. What lies ahead Lucia Rahilly: Do you see a risk of employees becoming overly reliant on AI? And do organizations need to take steps to help ensure employees retain their human judgment? Kate Smaje: In some ways, we can see “reliance on AI” as a pejorative term or as a real positive, in that employees are using AI to do their jobs better, faster, cheaper, at lower risk. The reality is that human judgment will become more important than ever for making sure these models are built responsibly, and more important in making sure the value really comes out of them. To make sure humans are using AI responsibly, there are at least two things to consider. One is constantly questioning the technology. The second is constantly looking for the “and.” Where does one plus one equal five here, regarding bringing humans plus technology to get a breakthrough that wasn’t otherwise possible? As long as we’re still doing those two things, human judgment will become more important, not less. Rodney Zemmel: That said, it’s clear that this is going to be better than humans in many cases. I’ll give you a maybe silly example. In tennis, there’s electronic line judging. Wimbledon and the US Open have gone different routes. In Wimbledon they have electronic line judging, but they keep the humans wearing green blazers standing on the sidelines. In the US Open, they’ve gone all electronic. And most people would say the US Open version is working just as well or better. There’s less interruption of play. There’s less back and forth. There are no more obviously wrong calls. Interestingly, I’m told that the US Open employs as many people as Wimbledon does, but in different jobs. It’s people in the tech control room, and people that are deploying, setting up, and monitoring the technology. Lucia Rahilly: We recently posted an interview with Reid Hoffman for the At the Edge podcast. He suggested that AI has the potential to develop EQ and soft skills. Any thoughts on how that might affect the AI–human calculus in the workplace? Kate Smaje: We see this already. Rodney and I often joke about this very small study that was done in the United Kingdom with GPs [general practitioners], where they tested a human versus a bot to see if the patient could tell the difference. The patients pretty much could, in most cases. Then the patients were asked which they preferred. Staggeringly, most folks preferred the bot. They said, “I felt that it understood my needs better. It was more empathetic. It solved my problem faster.” We shouldn’t underestimate that the technology is already pretty darn good at the qualities we often associate with humans. Lucia Rahilly: Anything else to call out that might not be top of mind for leaders but should be? Rodney Zemmel: There’s a question about what the future of the workforce is going to look like. There was a very interesting interview with Garry Kasparov some time ago. He famously was beaten by the IBM chess computer back in the ’90s. He said, “Look, I was the first knowledge worker to lose my job to a computer. And now it’s coming for all of you.” That’s a bit exaggerated, but that view is clearly out there. There are companies that say, “OK, we no longer need junior people, analysts, people doing routine tasks. We can get away with a workforce or evolve to a workforce that has a very different pyramid shape.” There are others who say, “Maybe. But this is about the superpowers idea. It means we can make the analysts or the junior people in our company as productive in the future as our most senior people are today, because this is going to take away a lot of the routinized drudgery of what they do and really give them these incredible abilities to create more value.” There’s a view that says the value of the data scientist goes down and the value of the data engineer goes up in the future. So from a workforce planning standpoint, this is profound. Frankly, the answer doesn’t exist yet. People are going to need some real thinking time and flexibility to evolve what this means for workforce planning. Kate Smaje: I couldn’t agree more. Your point on flex has another flavor to it as well, in that so much of what we’re really talking about here is constant learning, constant experimentation. And that’s very easy to fund, resource, and allocate time to in good times. It’s much harder to do when economies or markets turn and companies have to batten down the hatches. There is a real challenge for leaders to figure out: how do I have a more through-cycle mindset for investing and learning for the future when the level of certainty, and therefore the level of ROI prediction, is more challenged? Can I have a plan here that’s flexible enough for sunny times as well as rainy ones? Lucia Rahilly is the global editorial director of McKinsey Global Publishing and is based in the New York office. Explore a career with us Related Articles Ten unsung digital and AI ideas shaping business The economic potential of generative AI: The next productivity frontier Steady progress in approaching the quantum advantage', 'summary': 'In a McKinsey Podcast episode, leaders discuss the importance of balancing focus on generative AI with other digital initiatives, emphasizing the need for a neural business model that fosters connections and autonomy among teams. They also highlight the necessity of upskilling,'}
2024-08-20 02:08:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:08:01 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nMcKinsey technology trends outlook 2024 Despite challenging overall market conditions in 2023, continuing investments in frontier technologies promise substantial future growth in enterprise adoption. Generative AI (gen AI) has been a standout trend since 2022, with the extraordinary uptick in interest and investment in this technology unlocking innovative possibilities across interconnected trends such as robotics and immersive reality. While the macroeconomic environment with elevated interest rates has affected equity capital investment and hiring, underlying indicators—including optimism, innovation, and longer-term talent needs—reflect a positive long-term trajectory in the 15 technology trends we analyzed. What’s new in this year’s analysis This year, we reflected the shifts in the technology landscape with two changes on the list of trends: digital trust and cybersecurity (integrating what we had previously described as Web3 and trust architectures) and the future of robotics. Robotics technologies’ synergy with AI is paving the way for groundbreaking innovations and operational shifts across the economic and workforce landscapes. We also deployed a survey to measure adoption levels across trends. These are among the findings in the latest McKinsey Technology Trends Outlook, in which the McKinsey Technology Council identified the most significant technology trends unfolding today. This research is intended to help executives plan ahead by developing an understanding of potential use cases, sources of value, adoption drivers, and the critical skills needed to bring these opportunities to fruition. Our analysis examines quantitative measures of interest, innovation, investment, and talent to gauge the momentum of each trend. Recognizing the long-term nature and interdependence of these trends, we also delve into the underlying technologies, uncertainties, and questions surrounding each trend. (For more about new developments in our research, please see the sidebar “What’s new in this year’s analysis”; for more about the research itself, please see the sidebar “Research methodology.”) New and notable The two trends that stood out in 2023 were gen AI and electrification and renewables. Gen AI has seen a spike of almost 700 percent in Google searches from 2022 to 2023, along with a notable jump in job postings and investments. The pace of technology innovation has been remarkable. Over the course of 2023 and 2024, the size of the prompts that large language models (LLMs) can process, known as “context windows,” spiked from 100,000 to two million tokens. This is roughly the difference between adding one research paper to a model prompt and adding about 20 novels to it. And the modalities that gen AI can process have continued to increase, from text summarization and image generation to advanced capabilities in video, images, audio, and text. This has catalyzed a surge in investments and innovation aimed at advancing more powerful and efficient computing systems. The large foundation models that power generative AI, such as LLMs, are being integrated into various enterprise software tools and are also being employed for diverse purposes such as powering customer-facing chatbots, generating ad campaigns, accelerating drug discovery, and more. We expect this expansion to continue, pushing the boundaries of AI capabilities. Senior leaders’ awareness of gen AI innovation has increased interest, investment, and innovation in AI technologies, such as robotics, which is a new addition to our trends analysis this year. Advancements in AI are ushering in a new era of more capable robots, spurring greater innovation and a wider range of deployments. Research methodology To assess the development of each technology trend, our team collected data on five tangible measures of activity: search engine queries, news publications, patents, research publications, and investment. For each measure, we used a defined set of data sources to find occurrences of keywords associated with each of the 15 trends, screened those occurrences for valid mentions of activity, and indexed the resulting numbers of mentions on a 0–1 scoring scale that is relative to the trends studied. The innovation score combines the patents and research scores; the interest score combines the news and search scores. (While we recognize that an interest score can be inflated by deliberate efforts to stimulate news and search activity, we believe that each score fairly reflects the extent of discussion and debate about a given trend.) Investment measures the flows of funding from the capital markets into companies linked with the trend. Data sources for the scores include the following: In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends: Finally, we used survey data to calculate the enterprise-wide adoption scores for each trend: Electrification and renewables was the other trend that bucked the economic headwinds, posting the highest investment and interest scores among all the trends we evaluated. Job postings for this sector also showed a modest increase. Although many trends faced declines in investment and hiring in 2023, the long-term outlook remains positive. This optimism is supported by the continued longer-term growth in job postings for the analyzed trends (up 8 percent from 2021 to 2023) and enterprises’ continued innovation and heightened interest in harnessing these technologies, particularly for future growth. In 2023, technology equity investments fell by 30 to 40 percent to approximately $570 billion due to rising financing costs and a cautious near-term growth outlook, prompting investors to favor technologies with strong revenue and margin potential. This approach aligns with the strategic perspective leading companies are adopting, in which they recognize that fully adopting and scaling cutting-edge technologies is a long-term endeavor. This recognition is evident when companies diversify their investments across a portfolio of several technologies, selectively intensifying their focus on areas most likely to push technological boundaries forward. While many technologies have maintained cautious investment profiles over the past year, gen AI saw a sevenfold increase in investments, driven by substantial advancements in text, image, and video generation. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Despite an overall downturn in private equity investment, the pace of innovation has not slowed. Innovation has accelerated in the three trends that are part of the “AI revolution” group: gen AI, applied AI, and industrializing machine learning. Gen AI creates new content from unstructured data (such as text and images), applied AI leverages machine learning models for analytical and predictive tasks, and industrializing machine learning accelerates and derisks the development of machine learning solutions. Applied AI and industrializing machine learning, boosted by the widening interest in gen AI, have seen the most significant uptick in innovation, reflected in the surge in publications and patents from 2022 to 2023. Meanwhile, electrification and renewable-energy technologies continue to capture high interest, reflected in news mentions and web searches. Their popularity is fueled by a surge in global renewable capacity, their crucial roles in global decarbonization efforts, and heightened energy security needs amid geopolitical tensions and energy crises. The talent environment largely echoed the investment picture in tech trends in 2023. The technology sector faced significant layoffs, particularly among large technology companies, with job postings related to the tech trends we studied declining by 26 percent—a steeper drop than the 17 percent decrease in global job postings overall. The greater decline in demand for tech-trends-related talent may have been fueled by technology companies’ cost reduction efforts amid decreasing revenue growth projections. Despite this reduction, the trends with robust investment and innovation, such as gen AI, not only maintained but also increased their job postings, reflecting a strong demand for new and advanced skills. Electrification and renewables was the other trend that saw positive job growth, partially due to public sector support for infrastructure spending. Even with the short-term vicissitudes in talent demand, our analysis of 4.3 million job postings across our 15 tech trends underscored a wide skills gap. Compared with the global average, fewer than half the number of potential candidates have the high-demand tech skills specified in job postings. Despite the year-on-year decreases for job postings in many trends from 2022 to 2023, the number of tech-related job postings in 2023 still represented an 8 percent increase from 2021, suggesting the potential for longer-term growth (Exhibit 1). Enterprise technology adoption momentum The trajectory of enterprise technology adoption is often described as an S-curve that traces the following pattern: technical innovation and exploration, experimenting with the technology, initial pilots in the business, scaling the impact throughout the business, and eventual fully scaled adoption (Exhibit 2). This pattern is evident in this year’s survey analysis of enterprise adoption conducted across our 15 technologies. Adoption levels vary across different industries and company sizes, as does the perceived progress toward adoption. Image description: A graph depicts the adoption curve of technology trends, scored from 1 to 5, where 1 represents frontier innovation, located at the bottom left corner of the curve; 2 is experimenting, located slightly above frontier innovation; 3 is piloting, which follows the upward trajectory of the curve; 4 is scaling, marked by a vertical ascent as adoption increases; and 5 is fully scaled, positioned at the top of the curve, indicating near-complete adoption. In 2023, the trends are positioned along the adoption curve as follows: future of space technologies and quantum technologies are at the frontier innovation stage; climate technologies beyond electrification and renewables, future of bioengineering, future of mobility, future of robotics, and immersive-reality technologies are at the experimenting stage; digital trust and cybersecurity, electrification and renewables, industrializing machine learning, and next-gen software development are at the piloting stage; and advanced connectivity, applied AI, cloud and edge computing, and generative AI are at the scaling stage. Footnote: Trend is more relevant to certain industries, resulting in lower overall adoption across industries compared with adoption within relevant industries. Source: McKinsey technology adoption survey data End of image description. We see that the technologies in the S-curve’s early stages of innovation and experimenting are either on the leading edge of progress, such as quantum technologies and robotics, or are more relevant to a specific set of industries, such as bioengineering and space. Factors that could affect the adoption of these technologies include high costs, specialized applications, and balancing the breadth of technology investments against focusing on a select few that may offer substantial first-mover advantages. As technologies gain traction and move beyond experimenting, adoption rates start accelerating, and companies invest more in piloting and scaling. We see this shift in a number of trends, such as next-generation software development and electrification. Gen AI’s rapid advancement leads among trends analyzed, about a quarter of respondents self-reporting that they are scaling its use. More mature technologies, like cloud and edge computing and advanced connectivity, continued their rapid pace of adoption, serving as enablers for the adoption of other emerging technologies as well (Exhibit 3). Image description: A segmented bar graph shows the adoption levels of tech trends in 2023 as a percentage of respondents. The trends are divided into 5 segments, comprising 100%: fully scaled, scaling, piloting, experimenting, and not investing. The trends are arranged based on the combined percentage sum of fully scaled and scaling shares. Listed from highest to lowest, these combined percentages are as follows: Source: McKinsey technology adoption survey data End of image description. The process of scaling technology adoption also requires a conducive external ecosystem where user trust and readiness, business model economics, regulatory environments, and talent availability play crucial roles. Since these ecosystem factors vary by geography and industry, we see different adoption scenarios playing out. For instance, while the leading banks in Latin America are on par with their North American counterparts in deploying gen AI use cases, the adoption of robotics in manufacturing sectors varies significantly due to differing labor costs affecting the business case for automation. As executives navigate these complexities, they should align their long-term technology adoption strategies with both their internal capacities and the external ecosystem conditions to ensure the successful integration of new technologies into their business models. Executives should monitor ecosystem conditions that can affect their prioritized use cases to make decisions about the appropriate investment levels while navigating uncertainties and budgetary constraints on the way to full adoption (see the “Adoption developments across the globe” sections within each trend or particular use cases therein that executives should monitor).  Across the board, leaders who take a long-term view—building up their talent, testing and learning where impact can be found, and reimagining the businesses for the future—can potentially break out ahead of the pack. Lareina Yee is a senior partner in McKinsey’s Bay Area office, where Michael Chui is a McKinsey Global Institute partner, Roger Roberts is a partner, and Mena Issler is an associate partner. The authors wish to thank the following McKinsey colleagues for their contributions to this research: Aakanksha Srinivasan, Ahsan Saeed, Alex Arutyunyants, Alex Singla, Alex Zhang, Alizee Acket-Goemaere, An Yan, Anass Bensrhir, Andrea Del Miglio, Andreas Breiter, Ani Kelkar, Anna Massey, Anna Orthofer, Arjit Mehta, Arjita Bhan, Asaf Somekh, Begum Ortaoglu, Benjamin Braverman, Bharat Bahl, Bharath Aiyer, Bhargs Srivathsan, Brian Constantine, Brooke Stokes, Bryan Richardson, Carlo Giovine, Celine Crenshaw, Daniel Herde, Daniel Wallance, David Harvey, Delphine Zurkiya, Diego Hernandez Diaz, Douglas Merrill, Elisa Becker-Foss, Emma Parry, Eric Hazan, Erika Stanzl, Everett Santana, Giacomo Gatto, Grace W Chen, Hamza Khan, Harshit Jain, Helen Wu, Henning Soller, Ian de Bode, Jackson Pentz, Jeffrey Caso, Jesse Klempner, Jim Boehm, Joshua Katz, Julia Perry, Julian Sevillano, Justin Greis, Kersten Heineke, Kitti Lakner, Kristen Jennings, Liz Grennan, Luke Thomas, Maria Pogosyan, Mark Patel, Martin Harrysson, Martin Wrulich, Martina Gschwendtner, Massimo Mazza, Matej Macak, Matt Higginson, Matt Linderman, Matteo Cutrera, Mellen Masea, Michiel Nivard, Mike Westover, Musa Bilal, Nicolas Bellemans, Noah Furlonge-Walker, Obi Ezekoye, Paolo Spranzi, Pepe Cafferata, Robin Riedel, Ryan Brukardt, Samuel Musmanno, Santiago Comella-Dorda, Sebastian Mayer, Shakeel Kalidas, Sharmila Bhide, Stephen Xu, Tanmay Bhatnagar, Thomas Hundertmark, Tinan Goli, Tom Brennan, Tom Levin-Reid, Tony Hansen, Vinayak HV, Yaron Haviv, Yvonne Ferrier, and Zina Cole. They also wish to thank the external members of the McKinsey Technology Council for their insights and perspectives, including Ajay Agrawal, Azeem Azhar, Ben Lorica, Benedict Evans, John Martinis, and Jordan Jacobs. Special thanks to McKinsey Global Publishing colleagues Barr Seitz, Diane Rice, Kanika Punwani, Katie Shearer, LaShon Malone, Mary Gayen, Nayomi Chibana, Richard Johnson, Stephen Landau, and Victor Cuevas for making this interactive come alive. Explore a career with us Related Articles Rewired and running ahead: Digital and AI leaders are leaving the rest behind False friends or good ends? The CIO’s four-point guide to navigating technology trends'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:08:01 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:08:01 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:08:01 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:08:01 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:08:01 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:08:01 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:08:02 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:08:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'682'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'195676'), (b'x-ratelimit-reset-requests', b'2m2.583s'), (b'x-ratelimit-reset-tokens', b'1.297s'), (b'x-request-id', b'req_01def204c91da24ad0541e1698e52619'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608cc46cbd1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:08:02 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:08:02 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:08:02 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:08:02 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:08:02 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:08:02 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:08:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '682', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '195676', 'x-ratelimit-reset-requests': '2m2.583s', 'x-ratelimit-reset-tokens': '1.297s', 'x-request-id': 'req_01def204c91da24ad0541e1698e52619', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608cc46cbd1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:08:02 [openai._base_client] DEBUG: request_id: req_01def204c91da24ad0541e1698e52619
2024-08-20 02:08:02 [mckinsey_capabilities_digital_insights] INFO: Generated summary: The McKinsey Technology Trends Outlook 2024 highlights significant growth in enterprise adoption of frontier technologies, particularly generative AI and electrification. Despite a challenging economic landscape, indicators show optimism and innovation. The report emphasizes the need for executives to understand technology
2024-08-20 02:08:03 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:08:03 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:08:03 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:08:03 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:08:03 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A15%3AG15 HTTP/11" 200 None
2024-08-20 02:08:03 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A15%3AG15?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:08:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech>
{'title': 'McKinsey technology trends outlook 2024', 'description': 'Which technology trends matter most for companies in 2024? New analysis by the McKinsey Technology Council highlights the adoption,...', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20top%20trends%20in%20tech%202024/technology-trends-outlook-2024-1463331528-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-07-16T12:00:00Z', 'article_text': 'McKinsey technology trends outlook 2024 Despite challenging overall market conditions in 2023, continuing investments in frontier technologies promise substantial future growth in enterprise adoption. Generative AI (gen AI) has been a standout trend since 2022, with the extraordinary uptick in interest and investment in this technology unlocking innovative possibilities across interconnected trends such as robotics and immersive reality. While the macroeconomic environment with elevated interest rates has affected equity capital investment and hiring, underlying indicators—including optimism, innovation, and longer-term talent needs—reflect a positive long-term trajectory in the 15 technology trends we analyzed. What’s new in this year’s analysis This year, we reflected the shifts in the technology landscape with two changes on the list of trends: digital trust and cybersecurity (integrating what we had previously described as Web3 and trust architectures) and the future of robotics. Robotics technologies’ synergy with AI is paving the way for groundbreaking innovations and operational shifts across the economic and workforce landscapes. We also deployed a survey to measure adoption levels across trends. These are among the findings in the latest McKinsey Technology Trends Outlook, in which the McKinsey Technology Council identified the most significant technology trends unfolding today. This research is intended to help executives plan ahead by developing an understanding of potential use cases, sources of value, adoption drivers, and the critical skills needed to bring these opportunities to fruition. Our analysis examines quantitative measures of interest, innovation, investment, and talent to gauge the momentum of each trend. Recognizing the long-term nature and interdependence of these trends, we also delve into the underlying technologies, uncertainties, and questions surrounding each trend. (For more about new developments in our research, please see the sidebar “What’s new in this year’s analysis”; for more about the research itself, please see the sidebar “Research methodology.”) New and notable The two trends that stood out in 2023 were gen AI and electrification and renewables. Gen AI has seen a spike of almost 700 percent in Google searches from 2022 to 2023, along with a notable jump in job postings and investments. The pace of technology innovation has been remarkable. Over the course of 2023 and 2024, the size of the prompts that large language models (LLMs) can process, known as “context windows,” spiked from 100,000 to two million tokens. This is roughly the difference between adding one research paper to a model prompt and adding about 20 novels to it. And the modalities that gen AI can process have continued to increase, from text summarization and image generation to advanced capabilities in video, images, audio, and text. This has catalyzed a surge in investments and innovation aimed at advancing more powerful and efficient computing systems. The large foundation models that power generative AI, such as LLMs, are being integrated into various enterprise software tools and are also being employed for diverse purposes such as powering customer-facing chatbots, generating ad campaigns, accelerating drug discovery, and more. We expect this expansion to continue, pushing the boundaries of AI capabilities. Senior leaders’ awareness of gen AI innovation has increased interest, investment, and innovation in AI technologies, such as robotics, which is a new addition to our trends analysis this year. Advancements in AI are ushering in a new era of more capable robots, spurring greater innovation and a wider range of deployments. Research methodology To assess the development of each technology trend, our team collected data on five tangible measures of activity: search engine queries, news publications, patents, research publications, and investment. For each measure, we used a defined set of data sources to find occurrences of keywords associated with each of the 15 trends, screened those occurrences for valid mentions of activity, and indexed the resulting numbers of mentions on a 0–1 scoring scale that is relative to the trends studied. The innovation score combines the patents and research scores; the interest score combines the news and search scores. (While we recognize that an interest score can be inflated by deliberate efforts to stimulate news and search activity, we believe that each score fairly reflects the extent of discussion and debate about a given trend.) Investment measures the flows of funding from the capital markets into companies linked with the trend. Data sources for the scores include the following: In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends: Finally, we used survey data to calculate the enterprise-wide adoption scores for each trend: Electrification and renewables was the other trend that bucked the economic headwinds, posting the highest investment and interest scores among all the trends we evaluated. Job postings for this sector also showed a modest increase. Although many trends faced declines in investment and hiring in 2023, the long-term outlook remains positive. This optimism is supported by the continued longer-term growth in job postings for the analyzed trends (up 8 percent from 2021 to 2023) and enterprises’ continued innovation and heightened interest in harnessing these technologies, particularly for future growth. In 2023, technology equity investments fell by 30 to 40 percent to approximately $570 billion due to rising financing costs and a cautious near-term growth outlook, prompting investors to favor technologies with strong revenue and margin potential. This approach aligns with the strategic perspective leading companies are adopting, in which they recognize that fully adopting and scaling cutting-edge technologies is a long-term endeavor. This recognition is evident when companies diversify their investments across a portfolio of several technologies, selectively intensifying their focus on areas most likely to push technological boundaries forward. While many technologies have maintained cautious investment profiles over the past year, gen AI saw a sevenfold increase in investments, driven by substantial advancements in text, image, and video generation. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Despite an overall downturn in private equity investment, the pace of innovation has not slowed. Innovation has accelerated in the three trends that are part of the “AI revolution” group: gen AI, applied AI, and industrializing machine learning. Gen AI creates new content from unstructured data (such as text and images), applied AI leverages machine learning models for analytical and predictive tasks, and industrializing machine learning accelerates and derisks the development of machine learning solutions. Applied AI and industrializing machine learning, boosted by the widening interest in gen AI, have seen the most significant uptick in innovation, reflected in the surge in publications and patents from 2022 to 2023. Meanwhile, electrification and renewable-energy technologies continue to capture high interest, reflected in news mentions and web searches. Their popularity is fueled by a surge in global renewable capacity, their crucial roles in global decarbonization efforts, and heightened energy security needs amid geopolitical tensions and energy crises. The talent environment largely echoed the investment picture in tech trends in 2023. The technology sector faced significant layoffs, particularly among large technology companies, with job postings related to the tech trends we studied declining by 26 percent—a steeper drop than the 17 percent decrease in global job postings overall. The greater decline in demand for tech-trends-related talent may have been fueled by technology companies’ cost reduction efforts amid decreasing revenue growth projections. Despite this reduction, the trends with robust investment and innovation, such as gen AI, not only maintained but also increased their job postings, reflecting a strong demand for new and advanced skills. Electrification and renewables was the other trend that saw positive job growth, partially due to public sector support for infrastructure spending. Even with the short-term vicissitudes in talent demand, our analysis of 4.3 million job postings across our 15 tech trends underscored a wide skills gap. Compared with the global average, fewer than half the number of potential candidates have the high-demand tech skills specified in job postings. Despite the year-on-year decreases for job postings in many trends from 2022 to 2023, the number of tech-related job postings in 2023 still represented an 8 percent increase from 2021, suggesting the potential for longer-term growth (Exhibit 1). Enterprise technology adoption momentum The trajectory of enterprise technology adoption is often described as an S-curve that traces the following pattern: technical innovation and exploration, experimenting with the technology, initial pilots in the business, scaling the impact throughout the business, and eventual fully scaled adoption (Exhibit 2). This pattern is evident in this year’s survey analysis of enterprise adoption conducted across our 15 technologies. Adoption levels vary across different industries and company sizes, as does the perceived progress toward adoption. Image description: A graph depicts the adoption curve of technology trends, scored from 1 to 5, where 1 represents frontier innovation, located at the bottom left corner of the curve; 2 is experimenting, located slightly above frontier innovation; 3 is piloting, which follows the upward trajectory of the curve; 4 is scaling, marked by a vertical ascent as adoption increases; and 5 is fully scaled, positioned at the top of the curve, indicating near-complete adoption. In 2023, the trends are positioned along the adoption curve as follows: future of space technologies and quantum technologies are at the frontier innovation stage; climate technologies beyond electrification and renewables, future of bioengineering, future of mobility, future of robotics, and immersive-reality technologies are at the experimenting stage; digital trust and cybersecurity, electrification and renewables, industrializing machine learning, and next-gen software development are at the piloting stage; and advanced connectivity, applied AI, cloud and edge computing, and generative AI are at the scaling stage. Footnote: Trend is more relevant to certain industries, resulting in lower overall adoption across industries compared with adoption within relevant industries. Source: McKinsey technology adoption survey data End of image description. We see that the technologies in the S-curve’s early stages of innovation and experimenting are either on the leading edge of progress, such as quantum technologies and robotics, or are more relevant to a specific set of industries, such as bioengineering and space. Factors that could affect the adoption of these technologies include high costs, specialized applications, and balancing the breadth of technology investments against focusing on a select few that may offer substantial first-mover advantages. As technologies gain traction and move beyond experimenting, adoption rates start accelerating, and companies invest more in piloting and scaling. We see this shift in a number of trends, such as next-generation software development and electrification. Gen AI’s rapid advancement leads among trends analyzed, about a quarter of respondents self-reporting that they are scaling its use. More mature technologies, like cloud and edge computing and advanced connectivity, continued their rapid pace of adoption, serving as enablers for the adoption of other emerging technologies as well (Exhibit 3). Image description: A segmented bar graph shows the adoption levels of tech trends in 2023 as a percentage of respondents. The trends are divided into 5 segments, comprising 100%: fully scaled, scaling, piloting, experimenting, and not investing. The trends are arranged based on the combined percentage sum of fully scaled and scaling shares. Listed from highest to lowest, these combined percentages are as follows: Source: McKinsey technology adoption survey data End of image description. The process of scaling technology adoption also requires a conducive external ecosystem where user trust and readiness, business model economics, regulatory environments, and talent availability play crucial roles. Since these ecosystem factors vary by geography and industry, we see different adoption scenarios playing out. For instance, while the leading banks in Latin America are on par with their North American counterparts in deploying gen AI use cases, the adoption of robotics in manufacturing sectors varies significantly due to differing labor costs affecting the business case for automation. As executives navigate these complexities, they should align their long-term technology adoption strategies with both their internal capacities and the external ecosystem conditions to ensure the successful integration of new technologies into their business models. Executives should monitor ecosystem conditions that can affect their prioritized use cases to make decisions about the appropriate investment levels while navigating uncertainties and budgetary constraints on the way to full adoption (see the “Adoption developments across the globe” sections within each trend or particular use cases therein that executives should monitor).  Across the board, leaders who take a long-term view—building up their talent, testing and learning where impact can be found, and reimagining the businesses for the future—can potentially break out ahead of the pack. Lareina Yee is a senior partner in McKinsey’s Bay Area office, where Michael Chui is a McKinsey Global Institute partner, Roger Roberts is a partner, and Mena Issler is an associate partner. The authors wish to thank the following McKinsey colleagues for their contributions to this research: Aakanksha Srinivasan, Ahsan Saeed, Alex Arutyunyants, Alex Singla, Alex Zhang, Alizee Acket-Goemaere, An Yan, Anass Bensrhir, Andrea Del Miglio, Andreas Breiter, Ani Kelkar, Anna Massey, Anna Orthofer, Arjit Mehta, Arjita Bhan, Asaf Somekh, Begum Ortaoglu, Benjamin Braverman, Bharat Bahl, Bharath Aiyer, Bhargs Srivathsan, Brian Constantine, Brooke Stokes, Bryan Richardson, Carlo Giovine, Celine Crenshaw, Daniel Herde, Daniel Wallance, David Harvey, Delphine Zurkiya, Diego Hernandez Diaz, Douglas Merrill, Elisa Becker-Foss, Emma Parry, Eric Hazan, Erika Stanzl, Everett Santana, Giacomo Gatto, Grace W Chen, Hamza Khan, Harshit Jain, Helen Wu, Henning Soller, Ian de Bode, Jackson Pentz, Jeffrey Caso, Jesse Klempner, Jim Boehm, Joshua Katz, Julia Perry, Julian Sevillano, Justin Greis, Kersten Heineke, Kitti Lakner, Kristen Jennings, Liz Grennan, Luke Thomas, Maria Pogosyan, Mark Patel, Martin Harrysson, Martin Wrulich, Martina Gschwendtner, Massimo Mazza, Matej Macak, Matt Higginson, Matt Linderman, Matteo Cutrera, Mellen Masea, Michiel Nivard, Mike Westover, Musa Bilal, Nicolas Bellemans, Noah Furlonge-Walker, Obi Ezekoye, Paolo Spranzi, Pepe Cafferata, Robin Riedel, Ryan Brukardt, Samuel Musmanno, Santiago Comella-Dorda, Sebastian Mayer, Shakeel Kalidas, Sharmila Bhide, Stephen Xu, Tanmay Bhatnagar, Thomas Hundertmark, Tinan Goli, Tom Brennan, Tom Levin-Reid, Tony Hansen, Vinayak HV, Yaron Haviv, Yvonne Ferrier, and Zina Cole. They also wish to thank the external members of the McKinsey Technology Council for their insights and perspectives, including Ajay Agrawal, Azeem Azhar, Ben Lorica, Benedict Evans, John Martinis, and Jordan Jacobs. Special thanks to McKinsey Global Publishing colleagues Barr Seitz, Diane Rice, Kanika Punwani, Katie Shearer, LaShon Malone, Mary Gayen, Nayomi Chibana, Richard Johnson, Stephen Landau, and Victor Cuevas for making this interactive come alive. Explore a career with us Related Articles Rewired and running ahead: Digital and AI leaders are leaving the rest behind False friends or good ends? The CIO’s four-point guide to navigating technology trends', 'summary': 'The McKinsey Technology Trends Outlook 2024 highlights significant growth in enterprise adoption of frontier technologies, particularly generative AI and electrification. Despite a challenging economic landscape, indicators show optimism and innovation. The report emphasizes the need for executives to understand technology'}
2024-08-20 02:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-key-to-accelerating-ai-development-pragmatism-plus-imagination> (referer: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights)
2024-08-20 02:08:03 [openai._base_client] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Summarize the following content in 50 words or fewer, you will only return summary, do not include extra information:\n\nThe key to accelerating AI development? Pragmatism plus imagination While AI continues to influence the way we work in exciting new ways, it is crucial for organizations to apply guardrails to keep it safe. On this episode of The McKinsey Podcast , McKinsey senior partners Alexander Sukharevsky and Lareina Yee dig into new research on AI adoption , with editorial director Roberta Fusaro. In our second segment, how do you muster the courage to talk about something uncomfortable at work? Senior partner Sherina Ebrahim has two tips. This transcript has been edited for clarity and length. The McKinsey Podcast is cohosted by Roberta Fusaro and Lucia Rahilly. AI’s time to shine Roberta Fusaro: We’re here to discuss the latest McKinsey report on the state of AI , a technology evolving at an exponential rate. When it comes to gen AI, which is just one type of AI, our latest results show that 65 percent of our respondents reported their organizations regularly use it. This is double the percentage from our previous survey, which we conducted less than 12 months ago. Why is this new number important? Lareina Yee: This number represents optimism. Even though we have a long way to go, the number shows that people are moving from curiosity to integrating it into their businesses. What’s also important to note is that the report is not just looking at generative AI. It’s looking at AI overall. This has been a trend 40 years in the making. One of the things we’re seeing is that all of this excitement about generative AI is providing oxygen and daylight to the broader set of capabilities that can really help companies advance. Alexander Sukharevsky: Yes, generative AI allows us to democratize about a 40-year AI journey because it is so in our faces that we can really see and feel what it is. We’re able to interact with it. Our clients’ kids are interacting with this technology, and it’s getting discussed over dinners. So something that used to be a niche market is suddenly part of the mainstream. On the other hand, when 75 percent of respondents say that generative AI is used in their organization, the next question should be, what exactly are they using it for? Are they using it for experimentation, familiarizing themselves with the technology, or are they actually trying to unlock true business value? Partnering for AI success Roberta Fusaro: Staying with generative AI , Alexander, about half the respondents in our research say that they are using readily available gen AI models rather than building their own. What are the pros and cons of doing that? Alexander Sukharevsky: One important fact to bear in mind if you step back is that only 11 percent of AI models end up in production, meaning they become day-to-day true business tools to unlock value. If we consider some of the cost and risk of generative AI, this number is close to a single digit when we’re speaking about the traditional enterprise and not just tech companies. Therefore, it’s important to recognize that the model itself makes up only 15 percent of the success. Now we are moving into paradigm of not just “build versus buy” but “build, partner, and buy.” There are certain open-source models with amazing community support that organizations can customize to their needs. There are some proprietary models with very high investment behind them that organizations cannot develop themselves. And there are some models that organizations will develop in partnership with third parties. Want to subscribe to The McKinsey Podcast ? At the end of the day, the enterprise of the future will have a spine brain of dozens of foundational models. Some of them will be proprietary that you buy. Some of them will be those that you develop on your own. And some of them will be open source. So the answer to this question [to buy or build] depends on the client. Lareina Yee: This is an important topic because it is a classic question to wonder about “buy versus build” in technology. But Alexander and I have been working on this in the deployment, and I think we’re in a different paradigm. Being part of a partnership is a really important point that Alexander is raising. It is hard to build all of this on your own. It is also not feasible to buy all of this on your own. What you’re finding is that you have to partner across the stack. That’s kind of a traditional tech term. What that means is you’re going to partner with large language model providers. There are lots of choices. So the point of all this is to drive and unlock some business value that you weren’t able to access before. We’re seeing a lot of companies build a constellation of partnerships in order to deliver the promise of gen AI solutions. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Alexander Sukharevsky: But to power the models, you also need the compute power. You will need certain partners that will allow you to get this compute power. And even if you are the most powerful and well-resourced organization in the world, you cannot make it yourself. Lareina Yee: The number-one question to ask yourself is, “What is the business use case that I’m trying to achieve?” And based off that, “What are the sets of providers that are going to help me most?” That might be a combination of a very large language model provider that’s very enterprise focused. It could be someone who has stronger strengths in video but is doing something around text. And so, even though this is a fast space, I think it always comes back to, “What is the business objective? What’s the people objective?” And then, just being far more open in your mindset of how you bring in different technology providers and different combinations of partners to achieve that quickly. The future is still human Roberta Fusaro: Talent is a huge question and issue for everyone. I’m curious about what the research showed, or if there are different talent imperatives for executives who are trying to get ahead on gen AI. Lareina Yee: Talent is always top of mind. You have to get really practical and match the talent to, for example, a gen AI, AI, or machine learning solution. Those have different use cases. But in all cases, there are sets of capabilities that are going to be really important for your team. And the number-one thing we see in the report, and we see in our own experiences with clients, is data capabilities. So how you think about data and the type of talent you have is important. That’s just one example of the type of talent you need to implement these solutions. When we’re asked, “What’s going on with talent,” the question is typically more about jobs gained/jobs lost. And that’s\xa0more of an economic question. And for that, we know these technologies do change the fabric of jobs. But one of the optimistic things we see is they also create new jobs. So what we see in terms of talent is there are many different aspects of it. There’s the talent and capabilities you’re going to need as a company to develop and scale these solutions. There’s also an overall talent question in terms of how they change the fabric of jobs. Alexander Sukharevsky: One of Lareina’s favorite quotes is, “On every dollar of technology we need to invest three to five in human beings,” because human beings are very expensive and difficult to change. So the real questions are: “Beyond having an amazing technology department, who’s able to help you to operate and build the tools? How do you convince the rest of the organization to really use these tools, to embrace them, to manage risk vis-à-vis any other third party?” These are the difficult questions where you take colleagues who are coming completely outside of technology to learn technology and to trust technology. That’s quite a journey, be it around change management or be it around capabilities. Lareina Yee: We spend so much time on the technology. But in fact, that’s the easy part. The harder part is the human change. And we also sometimes lose the plot here. The purpose is not generative AI as a technology. The purpose is generative AI as a tool to help humanity. People are at the center of this. And that change is hard.  There’s that level of micro change. The purpose is not generative AI as a technology. The purpose is generative AI as a tool to help humanity. People are at the center of this. And that change is hard. There’s also the macro change, “Do I trust how I interact with a machine differently? How do I feel about potentially leaving actions to a machine?” We’re starting to see the rise of agentic capabilities, which is where these systems can take an action. There are a whole host of questions, and us getting more comfortable with that is a journey, and changing the fundamental business processes that we use—that’s the hard stuff. Use cases and applications Roberta Fusaro: I’m curious if in the new research we’re seeing different sorts of applications of generative AI. Are there parts of the organization where we’re seeing it more or less? Lareina Yee: Looking at the report, the most common domains we see are marketing and sales. We also see enormous amounts of work in product development and software engineering. These arenas are expected because these are where the types of knowledge work are most applicable to the capabilities of the technology today, especially when the vast majority of what we’re looking at is more the summarization and concision of text. We also see a difference by industry. It’s not surprising that we see the technology sector, the energy sector, and financial services sector being the sectors that are probably the furthest along in experimenting and beginning to deploy these capabilities at scale. Alexander Sukharevsky: The way to look at this is that generative AI, essentially, is the most convenient human interface to apply other AI techniques. And therefore, it’s all about interface; be it interface with a database, be it interface with other algorithms, be it even interface between different generative AI applications. I think if you fast-forward, to Lareina’s point, you will see more and more autonomous virtual agents communicating with each other to solve different tasks under strict human supervision to properly manage risk as well as to ensure that the quality of deliverables is going to be up to the standards that we’re looking for. Therefore, while currently we’re seeing mostly interaction that is human versus machine, as we develop, we’re going to see more and more machine-to-machine interactions to solve different tasks. Now we’re not talking about superintelligence or AGI [artificial general intelligence]; we are years away from that moment. At the same time, we’ll see very sophisticated, very niche assistants that will help us to do our job better, faster, and more precisely. Limiting the risks of AI Roberta Fusaro: There’s lots of opportunity, clearly, given our conversation so far. But according to our report, two of the top risks most often cited by organizations when it comes to their use of gen AI are inaccuracy and IP [intellectual property] infringement. Have organizations started to mitigate some of these risks? And if so, how? Lareina Yee: So when we look at the risks, there are a lot of risks. And one of the things both Alexander and I remind our clients about is that these are the early innings of the technology. Inaccuracy is one of the risks that people are most concerned about, but there’s also intellectual property infringement, cybersecurity, individual privacy, regulatory compliance, explainability, fairness, and amplification of bias. For those that are developing these large language models, they are working really quickly on many of these risks. Explainability is another one. There’s also the reduction of hallucinations, which is something that you’ve seen has gotten better over the course of the year. It’s not down to zero, but there’s been a lot of work on the provider side to make sure that it’s better. And that’s going to improve the inaccuracy issue. On the other side of this is companies’ implementation. How they develop, train, and test these systems is incredibly important before they let them out. Alexander Sukharevsky: The most important part to really understand is, “What are the risks?” Because if you look at our report, the majority of respondents believe there are risks, yet they cannot articulate what these risks are. There are ways of solving these risks . Number one is clearly having a human in the loop. And that’s why I don’t like to speak about artificial intelligence. I rather prefer “hybrid intelligence,” where we bring the best of humans and machines working together to overcome the challenges and the risks and unlock the opportunities. The most important part to really understand is, ‘What are the risks?’ Because if you look at our report, the majority of respondents believe there are risks, yet they cannot articulate what these risks are. On the other hand, should we think that technology can’t help us solve some of these issues? For example, as to IP or traceability, you could apply technology to track the IP, to protect IP. At the same time, while we believe that we all focus on very short-term risks, I do believe that we, as humanity, should step back and think, “What’s the bigger picture? What does this thing do for us, for future generations? Where should or shouldn’t we apply it—be it from a humanitarian point of view, a social point of view, or an environmental point of view? What type of future are we shaping by applying AI as a technology?” And those are significantly bigger questions that we should spend more time with, within the boardrooms as well as the machine rooms, to ensure that we understand exactly where we are heading. Lareina Yee: I think there are some incredibly long-term questions, Alexander, and some of them are very philosophical in terms of our relationship with machines. I also think one of them is the human capacity for adaptability and creativity. And let me take a simple example, something that any parent, any student, any teacher might relate to, which is the very practical concern of plagiarism. This has come up a lot—that concern that students might use ChatGPT or Claude to plagiarize. That’s a real concern and not a risk of the system. That’s actually in the usage. There is an incredibly practical hack that some teachers are using, which is that the exams are written in the classroom. We have this old technology called handwriting and pencils and paper that we can use to show that we have mastered the information. And it’s a very simple example, but what it shows is that there are some incredibly important ethical, very large questions that introducing these capabilities into our day-to-day lives brings. Responsible AI governance Roberta Fusaro: Lareina, you’ve written a bit in the report about AI governance, and that seems related here to the risks and making sure that we don’t go too far. How can companies begin to put some teeth into their AI governance? Lareina Yee: As Alexander and I talk to companies, we start by saying, “Responsible AI starts day one.” So in a traditional world and with previous generations, the way that we may have thought of this is you develop a solution, and then you make sure to catch the risks and have a compliance function. We absolutely need all that strength in our compliance, but we also have to move upstream and bring responsible AI on day one. So what does that mean? It means at a governance level, you’ve got someone with responsible AI capability and expertise that’s at the table making the decisions. That might be at your C-suite level, having someone help have that discussion. It also means that, as you’re developing these solutions, you are testing and integrating how you develop these solutions to ward against things like bias and inaccuracy. So how we think about responsible AI isn’t a moment. It’s embedded in the way in which we develop our business plans, in the way in which we build, configure, and test the solutions, and the way in which we implement it and continue to get feedback, and the way we have strong compliance on the back end if there was a mistake made. Steps for realizing value Roberta Fusaro: What are some first steps for organizations that want to make sure that they’re starting to realize value from their investments in gen AI? Lareina Yee: I think the first step starts with having the success metrics. What are you trying to achieve with this? Deploying generative AI just to say you’ve done it, just to create a conceptual demo or gizmo, that’s not going to lead to business value. At the very onset, it’s important to say, “What are the success metrics? What will I see quarter over quarter?” And then, “How are we doing against that?” So that might be that you expect 20 percent more productivity, and you’re going to use that extra capacity to reach more customers. Alexander Sukharevsky: This step-back moment is extremely important. And once you identify what you’re looking for, you should go back to the recipe that we discussed before in terms of, “What does it take to scale and embed AI within the organization?” Lareina Yee: Alexander, I love your point on scale because sometimes people ask, “What does it mean to scale?” If you only have ten engineers using the solution, that’s not scale. Scale is when you have the vast majority of the engineers using the solution and actually showing results out of it. Arguably the harder and the longer step is the adoption curve of users, and everybody using it, and changing work. That takes real time. So you may have the solution out in 12 weeks, but do you have the adoption and the usage out in 12 weeks? No. You must continue to work on that quarter over quarter, where over the course of a year or 18 months, you’ve gotten the type of business results that you aspire to have. The future is bright Roberta Fusaro: What are your final thoughts about where we’re heading with gen AI? Lareina Yee: The technology and its capabilities are unbelievably exciting. In order to capture it, we need to bring back that sense of pragmatic decision making. What are the cases that are going to make a difference in our business? How do we start to invest fully? How do we invest in these cases? How do we bring them to life? And how do we create that value for our businesses? I think we’re headed into an era of important pragmatism. Alexander Sukharevsky: I agree with Lareina with the caveat that we are still at the pre-awareness phase because the technology is so new. In less than a year, ten million developers got access to these tools. So what we are seeing now is just the beginning, and I believe it’s therefore the era of creativity and imagination. Though we kind of understand what it might do, we haven’t had enough time to figure out how to reinvent our business models and the way we work today. Together with the pragmatism that Lareina was talking about, and the imagination I mentioned, I think in the next 12 to 18 months we will see breakthrough pragmatic solutions, where you apply technology not just to entertain yourself but to unlock true value, be it for business or more important, for humanity. What to do when you’re not being heard Lucia Rahilly: Next up, McKinsey senior partner Sherina Ebrahim shares two tips to help anyone confronting their manager’s irritating behavior. Sherina Ebrahim: The first time I returned from parental leave, I was a manager, and I had come back to work part time. Back then, working part time was a well-established policy, but it was not as widespread as it is today, particularly for the manager role. When I came back, I took off one day a week. The first week, the partner that I worked with had a meeting scheduled for my day off. I did the meeting anyway. The second week, the same thing happened, and I did the meeting. Then the third week, the same thing happened: we had an internal team meeting scheduled, and again I didn’t say anything. But at this point, I thought I needed to say something. So I said to the partner, “You know, I am working part time and tomorrow is my day off, and we’ve now scheduled, for the third time, a meeting on my day off.” And honestly, the partner was mortified. He had just completely forgot. He fully apologized and we changed the meeting, moved on, and the rest of the engagement was perfectly fine in terms of how we made it work. The learning for me from that was two things. The first was assume positive intent. It really was one of those, “I’m not used to it, just moving from one thing to another, just wasn’t thinking about it” type of things. The second is stand up for yourself. When you see something that doesn’t quite work for you, at least bring it up and have a conversation. I think that helped me for the rest of my career because of course, things aren’t always perfect. There are going to be times when you’re working part time, and if you don’t actually have the conversation and engage, you don’t know what your manager is thinking, they don’t know what you are thinking, and it actually doesn’t lead to a positive outcome. Alexander Sukharevsky is a senior partner in McKinsey’s London office, Lareina Yee is a senior partner in the Bay Area office, and Sherina Ebrahim is a senior partner in the New Jersey office. Lucia Rahilly is the global editorial director of McKinsey Global Publishing and is based in the New York office, and Roberta Fusaro is an editorial director in the Boston office. Explore a career with us Related Articles McKinsey technology trends outlook 2024 Gen AI and beyond: Where else to focus now Moving past gen AI’s honeymoon phase: Seven hard truths for CIOs to get from pilot to scale'}], 'model': 'gpt-4o-mini', 'max_tokens': 50, 'service_tier': 'default', 'stream': False, 'temperature': 0.7}}
2024-08-20 02:08:03 [openai._base_client] DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-08-20 02:08:03 [httpcore.http11] DEBUG: send_request_headers.started request=<Request [b'POST']>
2024-08-20 02:08:03 [httpcore.http11] DEBUG: send_request_headers.complete
2024-08-20 02:08:03 [httpcore.http11] DEBUG: send_request_body.started request=<Request [b'POST']>
2024-08-20 02:08:03 [httpcore.http11] DEBUG: send_request_body.complete
2024-08-20 02:08:03 [httpcore.http11] DEBUG: receive_response_headers.started request=<Request [b'POST']>
2024-08-20 02:08:05 [httpcore.http11] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 Aug 2024 07:08:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-zdyom7q4bmlbujea2gl0pk3n'), (b'openai-processing-ms', b'903'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'194263'), (b'x-ratelimit-reset-requests', b'2m9.109s'), (b'x-ratelimit-reset-tokens', b'1.72s'), (b'x-request-id', b'req_3df1f569b65866706046a14ef06b7234'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8b608cd0bdde1131-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-08-20 02:08:05 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-08-20 02:08:05 [httpcore.http11] DEBUG: receive_response_body.started request=<Request [b'POST']>
2024-08-20 02:08:05 [httpcore.http11] DEBUG: receive_response_body.complete
2024-08-20 02:08:05 [httpcore.http11] DEBUG: response_closed.started
2024-08-20 02:08:05 [httpcore.http11] DEBUG: response_closed.complete
2024-08-20 02:08:05 [openai._base_client] DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 20 Aug 2024 07:08:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-zdyom7q4bmlbujea2gl0pk3n', 'openai-processing-ms': '903', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '194263', 'x-ratelimit-reset-requests': '2m9.109s', 'x-ratelimit-reset-tokens': '1.72s', 'x-request-id': 'req_3df1f569b65866706046a14ef06b7234', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8b608cd0bdde1131-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-08-20 02:08:05 [openai._base_client] DEBUG: request_id: req_3df1f569b65866706046a14ef06b7234
2024-08-20 02:08:05 [mckinsey_capabilities_digital_insights] INFO: Generated summary: The McKinsey Podcast discusses AI development, emphasizing the importance of pragmatism and imagination. Recent research shows increased generative AI adoption, with organizations needing to address risks and foster talent. Key points include responsible AI governance, successful implementation, and the
2024-08-20 02:08:05 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:08:05 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3A1 HTTP/11" 200 None
2024-08-20 02:08:05 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:08:05 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A1%3AA?valueRenderOption=FORMATTED_VALUE&majorDimension=COLUMNS HTTP/11" 200 None
2024-08-20 02:08:05 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "GET /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A16%3AG16 HTTP/11" 200 None
2024-08-20 02:08:06 [urllib3.connectionpool] DEBUG: https://sheets.googleapis.com:443 "PUT /v4/spreadsheets/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4/values/%27mckinsey_capabilities_digital_insights_Data%27%21A16%3AG16?valueInputOption=RAW HTTP/11" 200 None
2024-08-20 02:08:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-key-to-accelerating-ai-development-pragmatism-plus-imagination>
{'title': 'The key to accelerating AI development? Pragmatism plus imagination', 'description': 'Leaders are treating generative AI as less of a curiosity and more an integral part of business. McKinsey research sheds light...', 'url': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-key-to-accelerating-ai-development-pragmatism-plus-imagination', 'image_url': 'https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20key%20to%20accelerating%20ai%20development%20pragmatism%20plus/practical%20imagination%20is%20what%20the%20development%20of%20ai%20needs%20now-1453825854-thumb-1536x1536.jpg?cq=50&mw=767&car=16:9&cpy=Center', 'date': '2024-08-08T12:00:00Z', 'article_text': 'The key to accelerating AI development? Pragmatism plus imagination While AI continues to influence the way we work in exciting new ways, it is crucial for organizations to apply guardrails to keep it safe. On this episode of The McKinsey Podcast , McKinsey senior partners Alexander Sukharevsky and Lareina Yee dig into new research on AI adoption , with editorial director Roberta Fusaro. In our second segment, how do you muster the courage to talk about something uncomfortable at work? Senior partner Sherina Ebrahim has two tips. This transcript has been edited for clarity and length. The McKinsey Podcast is cohosted by Roberta Fusaro and Lucia Rahilly. AI’s time to shine Roberta Fusaro: We’re here to discuss the latest McKinsey report on the state of AI , a technology evolving at an exponential rate. When it comes to gen AI, which is just one type of AI, our latest results show that 65 percent of our respondents reported their organizations regularly use it. This is double the percentage from our previous survey, which we conducted less than 12 months ago. Why is this new number important? Lareina Yee: This number represents optimism. Even though we have a long way to go, the number shows that people are moving from curiosity to integrating it into their businesses. What’s also important to note is that the report is not just looking at generative AI. It’s looking at AI overall. This has been a trend 40 years in the making. One of the things we’re seeing is that all of this excitement about generative AI is providing oxygen and daylight to the broader set of capabilities that can really help companies advance. Alexander Sukharevsky: Yes, generative AI allows us to democratize about a 40-year AI journey because it is so in our faces that we can really see and feel what it is. We’re able to interact with it. Our clients’ kids are interacting with this technology, and it’s getting discussed over dinners. So something that used to be a niche market is suddenly part of the mainstream. On the other hand, when 75 percent of respondents say that generative AI is used in their organization, the next question should be, what exactly are they using it for? Are they using it for experimentation, familiarizing themselves with the technology, or are they actually trying to unlock true business value? Partnering for AI success Roberta Fusaro: Staying with generative AI , Alexander, about half the respondents in our research say that they are using readily available gen AI models rather than building their own. What are the pros and cons of doing that? Alexander Sukharevsky: One important fact to bear in mind if you step back is that only 11 percent of AI models end up in production, meaning they become day-to-day true business tools to unlock value. If we consider some of the cost and risk of generative AI, this number is close to a single digit when we’re speaking about the traditional enterprise and not just tech companies. Therefore, it’s important to recognize that the model itself makes up only 15 percent of the success. Now we are moving into paradigm of not just “build versus buy” but “build, partner, and buy.” There are certain open-source models with amazing community support that organizations can customize to their needs. There are some proprietary models with very high investment behind them that organizations cannot develop themselves. And there are some models that organizations will develop in partnership with third parties. Want to subscribe to The McKinsey Podcast ? At the end of the day, the enterprise of the future will have a spine brain of dozens of foundational models. Some of them will be proprietary that you buy. Some of them will be those that you develop on your own. And some of them will be open source. So the answer to this question [to buy or build] depends on the client. Lareina Yee: This is an important topic because it is a classic question to wonder about “buy versus build” in technology. But Alexander and I have been working on this in the deployment, and I think we’re in a different paradigm. Being part of a partnership is a really important point that Alexander is raising. It is hard to build all of this on your own. It is also not feasible to buy all of this on your own. What you’re finding is that you have to partner across the stack. That’s kind of a traditional tech term. What that means is you’re going to partner with large language model providers. There are lots of choices. So the point of all this is to drive and unlock some business value that you weren’t able to access before. We’re seeing a lot of companies build a constellation of partnerships in order to deliver the promise of gen AI solutions. About QuantumBlack, AI by McKinsey QuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe. Alexander Sukharevsky: But to power the models, you also need the compute power. You will need certain partners that will allow you to get this compute power. And even if you are the most powerful and well-resourced organization in the world, you cannot make it yourself. Lareina Yee: The number-one question to ask yourself is, “What is the business use case that I’m trying to achieve?” And based off that, “What are the sets of providers that are going to help me most?” That might be a combination of a very large language model provider that’s very enterprise focused. It could be someone who has stronger strengths in video but is doing something around text. And so, even though this is a fast space, I think it always comes back to, “What is the business objective? What’s the people objective?” And then, just being far more open in your mindset of how you bring in different technology providers and different combinations of partners to achieve that quickly. The future is still human Roberta Fusaro: Talent is a huge question and issue for everyone. I’m curious about what the research showed, or if there are different talent imperatives for executives who are trying to get ahead on gen AI. Lareina Yee: Talent is always top of mind. You have to get really practical and match the talent to, for example, a gen AI, AI, or machine learning solution. Those have different use cases. But in all cases, there are sets of capabilities that are going to be really important for your team. And the number-one thing we see in the report, and we see in our own experiences with clients, is data capabilities. So how you think about data and the type of talent you have is important. That’s just one example of the type of talent you need to implement these solutions. When we’re asked, “What’s going on with talent,” the question is typically more about jobs gained/jobs lost. And that’s\xa0more of an economic question. And for that, we know these technologies do change the fabric of jobs. But one of the optimistic things we see is they also create new jobs. So what we see in terms of talent is there are many different aspects of it. There’s the talent and capabilities you’re going to need as a company to develop and scale these solutions. There’s also an overall talent question in terms of how they change the fabric of jobs. Alexander Sukharevsky: One of Lareina’s favorite quotes is, “On every dollar of technology we need to invest three to five in human beings,” because human beings are very expensive and difficult to change. So the real questions are: “Beyond having an amazing technology department, who’s able to help you to operate and build the tools? How do you convince the rest of the organization to really use these tools, to embrace them, to manage risk vis-à-vis any other third party?” These are the difficult questions where you take colleagues who are coming completely outside of technology to learn technology and to trust technology. That’s quite a journey, be it around change management or be it around capabilities. Lareina Yee: We spend so much time on the technology. But in fact, that’s the easy part. The harder part is the human change. And we also sometimes lose the plot here. The purpose is not generative AI as a technology. The purpose is generative AI as a tool to help humanity. People are at the center of this. And that change is hard.  There’s that level of micro change. The purpose is not generative AI as a technology. The purpose is generative AI as a tool to help humanity. People are at the center of this. And that change is hard. There’s also the macro change, “Do I trust how I interact with a machine differently? How do I feel about potentially leaving actions to a machine?” We’re starting to see the rise of agentic capabilities, which is where these systems can take an action. There are a whole host of questions, and us getting more comfortable with that is a journey, and changing the fundamental business processes that we use—that’s the hard stuff. Use cases and applications Roberta Fusaro: I’m curious if in the new research we’re seeing different sorts of applications of generative AI. Are there parts of the organization where we’re seeing it more or less? Lareina Yee: Looking at the report, the most common domains we see are marketing and sales. We also see enormous amounts of work in product development and software engineering. These arenas are expected because these are where the types of knowledge work are most applicable to the capabilities of the technology today, especially when the vast majority of what we’re looking at is more the summarization and concision of text. We also see a difference by industry. It’s not surprising that we see the technology sector, the energy sector, and financial services sector being the sectors that are probably the furthest along in experimenting and beginning to deploy these capabilities at scale. Alexander Sukharevsky: The way to look at this is that generative AI, essentially, is the most convenient human interface to apply other AI techniques. And therefore, it’s all about interface; be it interface with a database, be it interface with other algorithms, be it even interface between different generative AI applications. I think if you fast-forward, to Lareina’s point, you will see more and more autonomous virtual agents communicating with each other to solve different tasks under strict human supervision to properly manage risk as well as to ensure that the quality of deliverables is going to be up to the standards that we’re looking for. Therefore, while currently we’re seeing mostly interaction that is human versus machine, as we develop, we’re going to see more and more machine-to-machine interactions to solve different tasks. Now we’re not talking about superintelligence or AGI [artificial general intelligence]; we are years away from that moment. At the same time, we’ll see very sophisticated, very niche assistants that will help us to do our job better, faster, and more precisely. Limiting the risks of AI Roberta Fusaro: There’s lots of opportunity, clearly, given our conversation so far. But according to our report, two of the top risks most often cited by organizations when it comes to their use of gen AI are inaccuracy and IP [intellectual property] infringement. Have organizations started to mitigate some of these risks? And if so, how? Lareina Yee: So when we look at the risks, there are a lot of risks. And one of the things both Alexander and I remind our clients about is that these are the early innings of the technology. Inaccuracy is one of the risks that people are most concerned about, but there’s also intellectual property infringement, cybersecurity, individual privacy, regulatory compliance, explainability, fairness, and amplification of bias. For those that are developing these large language models, they are working really quickly on many of these risks. Explainability is another one. There’s also the reduction of hallucinations, which is something that you’ve seen has gotten better over the course of the year. It’s not down to zero, but there’s been a lot of work on the provider side to make sure that it’s better. And that’s going to improve the inaccuracy issue. On the other side of this is companies’ implementation. How they develop, train, and test these systems is incredibly important before they let them out. Alexander Sukharevsky: The most important part to really understand is, “What are the risks?” Because if you look at our report, the majority of respondents believe there are risks, yet they cannot articulate what these risks are. There are ways of solving these risks . Number one is clearly having a human in the loop. And that’s why I don’t like to speak about artificial intelligence. I rather prefer “hybrid intelligence,” where we bring the best of humans and machines working together to overcome the challenges and the risks and unlock the opportunities. The most important part to really understand is, ‘What are the risks?’ Because if you look at our report, the majority of respondents believe there are risks, yet they cannot articulate what these risks are. On the other hand, should we think that technology can’t help us solve some of these issues? For example, as to IP or traceability, you could apply technology to track the IP, to protect IP. At the same time, while we believe that we all focus on very short-term risks, I do believe that we, as humanity, should step back and think, “What’s the bigger picture? What does this thing do for us, for future generations? Where should or shouldn’t we apply it—be it from a humanitarian point of view, a social point of view, or an environmental point of view? What type of future are we shaping by applying AI as a technology?” And those are significantly bigger questions that we should spend more time with, within the boardrooms as well as the machine rooms, to ensure that we understand exactly where we are heading. Lareina Yee: I think there are some incredibly long-term questions, Alexander, and some of them are very philosophical in terms of our relationship with machines. I also think one of them is the human capacity for adaptability and creativity. And let me take a simple example, something that any parent, any student, any teacher might relate to, which is the very practical concern of plagiarism. This has come up a lot—that concern that students might use ChatGPT or Claude to plagiarize. That’s a real concern and not a risk of the system. That’s actually in the usage. There is an incredibly practical hack that some teachers are using, which is that the exams are written in the classroom. We have this old technology called handwriting and pencils and paper that we can use to show that we have mastered the information. And it’s a very simple example, but what it shows is that there are some incredibly important ethical, very large questions that introducing these capabilities into our day-to-day lives brings. Responsible AI governance Roberta Fusaro: Lareina, you’ve written a bit in the report about AI governance, and that seems related here to the risks and making sure that we don’t go too far. How can companies begin to put some teeth into their AI governance? Lareina Yee: As Alexander and I talk to companies, we start by saying, “Responsible AI starts day one.” So in a traditional world and with previous generations, the way that we may have thought of this is you develop a solution, and then you make sure to catch the risks and have a compliance function. We absolutely need all that strength in our compliance, but we also have to move upstream and bring responsible AI on day one. So what does that mean? It means at a governance level, you’ve got someone with responsible AI capability and expertise that’s at the table making the decisions. That might be at your C-suite level, having someone help have that discussion. It also means that, as you’re developing these solutions, you are testing and integrating how you develop these solutions to ward against things like bias and inaccuracy. So how we think about responsible AI isn’t a moment. It’s embedded in the way in which we develop our business plans, in the way in which we build, configure, and test the solutions, and the way in which we implement it and continue to get feedback, and the way we have strong compliance on the back end if there was a mistake made. Steps for realizing value Roberta Fusaro: What are some first steps for organizations that want to make sure that they’re starting to realize value from their investments in gen AI? Lareina Yee: I think the first step starts with having the success metrics. What are you trying to achieve with this? Deploying generative AI just to say you’ve done it, just to create a conceptual demo or gizmo, that’s not going to lead to business value. At the very onset, it’s important to say, “What are the success metrics? What will I see quarter over quarter?” And then, “How are we doing against that?” So that might be that you expect 20 percent more productivity, and you’re going to use that extra capacity to reach more customers. Alexander Sukharevsky: This step-back moment is extremely important. And once you identify what you’re looking for, you should go back to the recipe that we discussed before in terms of, “What does it take to scale and embed AI within the organization?” Lareina Yee: Alexander, I love your point on scale because sometimes people ask, “What does it mean to scale?” If you only have ten engineers using the solution, that’s not scale. Scale is when you have the vast majority of the engineers using the solution and actually showing results out of it. Arguably the harder and the longer step is the adoption curve of users, and everybody using it, and changing work. That takes real time. So you may have the solution out in 12 weeks, but do you have the adoption and the usage out in 12 weeks? No. You must continue to work on that quarter over quarter, where over the course of a year or 18 months, you’ve gotten the type of business results that you aspire to have. The future is bright Roberta Fusaro: What are your final thoughts about where we’re heading with gen AI? Lareina Yee: The technology and its capabilities are unbelievably exciting. In order to capture it, we need to bring back that sense of pragmatic decision making. What are the cases that are going to make a difference in our business? How do we start to invest fully? How do we invest in these cases? How do we bring them to life? And how do we create that value for our businesses? I think we’re headed into an era of important pragmatism. Alexander Sukharevsky: I agree with Lareina with the caveat that we are still at the pre-awareness phase because the technology is so new. In less than a year, ten million developers got access to these tools. So what we are seeing now is just the beginning, and I believe it’s therefore the era of creativity and imagination. Though we kind of understand what it might do, we haven’t had enough time to figure out how to reinvent our business models and the way we work today. Together with the pragmatism that Lareina was talking about, and the imagination I mentioned, I think in the next 12 to 18 months we will see breakthrough pragmatic solutions, where you apply technology not just to entertain yourself but to unlock true value, be it for business or more important, for humanity. What to do when you’re not being heard Lucia Rahilly: Next up, McKinsey senior partner Sherina Ebrahim shares two tips to help anyone confronting their manager’s irritating behavior. Sherina Ebrahim: The first time I returned from parental leave, I was a manager, and I had come back to work part time. Back then, working part time was a well-established policy, but it was not as widespread as it is today, particularly for the manager role. When I came back, I took off one day a week. The first week, the partner that I worked with had a meeting scheduled for my day off. I did the meeting anyway. The second week, the same thing happened, and I did the meeting. Then the third week, the same thing happened: we had an internal team meeting scheduled, and again I didn’t say anything. But at this point, I thought I needed to say something. So I said to the partner, “You know, I am working part time and tomorrow is my day off, and we’ve now scheduled, for the third time, a meeting on my day off.” And honestly, the partner was mortified. He had just completely forgot. He fully apologized and we changed the meeting, moved on, and the rest of the engagement was perfectly fine in terms of how we made it work. The learning for me from that was two things. The first was assume positive intent. It really was one of those, “I’m not used to it, just moving from one thing to another, just wasn’t thinking about it” type of things. The second is stand up for yourself. When you see something that doesn’t quite work for you, at least bring it up and have a conversation. I think that helped me for the rest of my career because of course, things aren’t always perfect. There are going to be times when you’re working part time, and if you don’t actually have the conversation and engage, you don’t know what your manager is thinking, they don’t know what you are thinking, and it actually doesn’t lead to a positive outcome. Alexander Sukharevsky is a senior partner in McKinsey’s London office, Lareina Yee is a senior partner in the Bay Area office, and Sherina Ebrahim is a senior partner in the New Jersey office. Lucia Rahilly is the global editorial director of McKinsey Global Publishing and is based in the New York office, and Roberta Fusaro is an editorial director in the Boston office. Explore a career with us Related Articles McKinsey technology trends outlook 2024 Gen AI and beyond: Where else to focus now Moving past gen AI’s honeymoon phase: Seven hard truths for CIOs to get from pilot to scale', 'summary': 'The McKinsey Podcast discusses AI development, emphasizing the importance of pragmatism and imagination. Recent research shows increased generative AI adoption, with organizations needing to address risks and foster talent. Key points include responsible AI governance, successful implementation, and the'}
2024-08-20 02:08:06 [scrapy.core.engine] INFO: Closing spider (finished)
2024-08-20 02:08:06 [mckinsey_capabilities_digital_insights] INFO: ExportPipeline closed the files.
2024-08-20 02:08:06 [mckinsey_capabilities_digital_insights] INFO: GoogleSheetsPipeline finished processing and saved data to https://docs.google.com/spreadsheets/d/1qmPXhTIHutHWUto37O97aKG-vW2A1fCzD6WqbqJu9v4
2024-08-20 02:08:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 24280,
 'downloader/request_count': 17,
 'downloader/request_method_count/GET': 17,
 'downloader/response_bytes': 827328,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'elapsed_time_seconds': 109.069893,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 8, 20, 7, 8, 6, 746015, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 3674185,
 'httpcompression/response_count': 17,
 'item_scraped_count': 15,
 'log_count/DEBUG': 403,
 'log_count/ERROR': 1,
 'log_count/INFO': 45,
 'log_count/WARNING': 7,
 'request_depth_max': 1,
 'response_received_count': 17,
 'scheduler/dequeued': 17,
 'scheduler/dequeued/memory': 17,
 'scheduler/enqueued': 17,
 'scheduler/enqueued/memory': 17,
 'start_time': datetime.datetime(2024, 8, 20, 7, 6, 17, 676122, tzinfo=datetime.timezone.utc)}
2024-08-20 02:08:06 [scrapy.core.engine] INFO: Spider closed (finished)
